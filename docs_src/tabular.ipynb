{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from fastai.gen_doc.nbdoc import *\n",
    "from fastai.tabular import * \n",
    "from fastai import *\n",
    "from fastai.docs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `tabular` module contains all the necessary classes to deal with tabular data. In `tabular.transform`, we define the `TabularTransform` class to help with preprocessing. In `tabular.data`, we define the `TabularDataset` that handles that data, as well as the methods to quickly get a `DataBunch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tabular data usually comes in the form of a csv file containing variables of different kinds: texts, numbers, and some missing values. The example we'll work with in this section is a sample of the [adult dataset](https://archive.ics.uci.edu/ml/datasets/adult) which gives a certain amount of data on individuals to train a model to predict wether their salary is greater than \\$50k or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>&gt;=50k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>101320</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>1902</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>236746</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>10520</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>96185</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>112847</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>82297</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt     education  education-num  \\\n",
       "0   49            Private  101320    Assoc-acdm           12.0   \n",
       "1   44            Private  236746       Masters           14.0   \n",
       "2   38            Private   96185       HS-grad            NaN   \n",
       "3   38       Self-emp-inc  112847   Prof-school           15.0   \n",
       "4   42   Self-emp-not-inc   82297       7th-8th            NaN   \n",
       "\n",
       "        marital-status        occupation    relationship                 race  \\\n",
       "0   Married-civ-spouse               NaN            Wife                White   \n",
       "1             Divorced   Exec-managerial   Not-in-family                White   \n",
       "2             Divorced               NaN       Unmarried                Black   \n",
       "3   Married-civ-spouse    Prof-specialty         Husband   Asian-Pac-Islander   \n",
       "4   Married-civ-spouse     Other-service            Wife                Black   \n",
       "\n",
       "       sex  capital-gain  capital-loss  hours-per-week  native-country  >=50k  \n",
       "0   Female             0          1902              40   United-States      1  \n",
       "1     Male         10520             0              45   United-States      1  \n",
       "2   Female             0             0              32   United-States      0  \n",
       "3     Male             0             0              40   United-States      1  \n",
       "4   Female             0             0              50   United-States      0  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untar_adult()\n",
    "ADULT_PATH = DATA_PATH / 'adult_sample'\n",
    "df = pd.read_csv(ADULT_PATH/'adult.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here all the information that will form our input is in the 14 first columns, and the dependant variable is the last column. We will split our input between two types of variables: categoricals and continuous.\n",
    "- Categorical variables will be replaced by a category, a unique id that identifies them, before passing through an embedding layer.\n",
    "- Continuous variables will be normalized then directly fed to the model.\n",
    "\n",
    "Another thing we need to handle are the missing values: our model isn't going to like receiving NaNs so we should remove them in a smart way. All of this preprocessing is done by `TabularTransform` objects and `TabularDataset`.\n",
    "\n",
    "First let's split our variables between categoricals and continuous (we can ignore the dependant variable at this stage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can define a bunch of Transforms that will be applied to those variables. Here we transform all the variables in the `cat_names` list into categories, and we replace missing values for the ones in `cont_names` by the median of the corresponding column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [FillMissing, Categorify]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = df[:800].copy(),df[800:].copy()\n",
    "data = tabular_data_from_df(ADULT_PATH, train_df, valid_df, '>=50k', tfms=tfms, cat_names=cat_names, cont_names=cont_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 4, 13,  2,  4,  1,  5,  2, 28,  2],\n",
       "         [ 2, 15,  2,  0,  1,  3,  2, 28,  1],\n",
       "         [ 1, 15,  4,  1,  4,  5,  2, 28,  1],\n",
       "         [ 4, 10,  4,  0,  2,  5,  2, 28,  1],\n",
       "         [ 4, 12,  1,  3,  2,  5,  2, 28,  2],\n",
       "         [ 7,  9,  2, 11,  1,  5,  2, 28,  2],\n",
       "         [ 4, 15,  4,  6,  4,  5,  2, 28,  2],\n",
       "         [ 4, 12,  4,  0,  2,  5,  2, 28,  1],\n",
       "         [ 4,  1,  2, 14,  1,  5,  2, 28,  2],\n",
       "         [ 3, 15,  6,  0,  2,  5,  1, 28,  2]], device='cuda:0'),\n",
       " tensor([[ 1.6002, -0.7512, -0.1152, -0.1364, -0.2289,  0.3617],\n",
       "         [ 0.5984,  1.1684, -0.1152, -0.1364, -0.2289, -0.0503],\n",
       "         [-1.4823, -0.2425, -0.1152, -0.1364, -0.2289, -0.0503],\n",
       "         [-0.7117, -0.6892,  1.5310, -0.1364, -0.2289, -0.0503],\n",
       "         [ 0.1360, -0.8950, -0.1152, -0.1364, -0.2289,  0.3617],\n",
       "         [-0.5575,  0.5824, -0.1152, -0.1364, -0.2289, -0.2151],\n",
       "         [-1.2511, -0.8314, -0.1152, -0.1364, -0.2289, -1.6982],\n",
       "         [-0.6346, -0.7895, -0.6640, -0.1364,  4.0259,  0.1145],\n",
       "         [ 1.6772, -0.9276, -0.1152, -0.1364, -0.2289, -0.0503],\n",
       "         [ 2.4478, -0.1643, -0.1152, -0.1364, -0.2289, -1.9454]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = x,y = next(iter(data.train_dl))\n",
    "x[0][:10], x[1][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After being processed in `TabularDataset`, the categorical variables are replaced by ids and the continuous variables are normalized. The codes corresponding to categorical variables are all put together, as are all the continuous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our data ready in a `DataBunch`, we just need to create a model to then define a `Learner` and start training. The fastai library has a default `TabularModel` in `models.tabular`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.models.tabular import TabularModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use that function, we just need to specify the embedding sizes for each of our categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9, 5), (16, 8), (7, 4), (15, 8), (7, 4), (6, 3), (3, 2), (30, 15), (3, 2)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_szs = [len(train_df[n].cat.categories)+1 for n in cat_names]\n",
    "emb_szs = [(c, min(50, (c+1)//2)) for c in cat_szs]\n",
    "emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabularModel(emb_szs, len(cont_names), out_sz=1, layers=[1000,500], drops=[0.001,0.01], emb_drop=0.04)\n",
    "learner = Learner(data, model, loss_fn = F.binary_cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=1), HTML(value='0.00% [0/1 00:00<00:00]'))), HTML(valueâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 00:01\n",
      "epoch  train loss  valid loss\n",
      "0      0.655111    0.685396    (00:01)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(1,1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
