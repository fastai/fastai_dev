{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.layers import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp tabular.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular model\n",
    "\n",
    "> A basic model that can be used on tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_sz_rule(n_cat): \n",
    "    \"Rule of thumb to pick embedding size corresponding to `n_cat`\"\n",
    "    return min(600, round(1.6 * n_cat**0.56))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _one_emb_sz(classes, n, sz_dict=None):\n",
    "    \"Pick an embedding size for `n` depending on `classes` if not given in `sz_dict`.\"\n",
    "    sz_dict = ifnone(sz_dict, {})\n",
    "    n_cat = len(classes[n])\n",
    "    sz = sz_dict.get(n, int(emb_sz_rule(n_cat)))  # rule of thumb\n",
    "    return n_cat,sz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emb_sz(proc, sz_dict=None):\n",
    "    \"Get default embedding size from `TabularPreprocessor` `proc` or the ones in `sz_dict`\"\n",
    "    return [_one_emb_sz(proc.classes, n, sz_dict) for n in proc.cat_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularModel(Module):\n",
    "    \"Basic model for tabular data.\"\n",
    "    def __init__(self, emb_szs, n_cont, out_sz, layers, ps=None, embed_p=0., y_range=None, use_bn=True, bn_final=False):\n",
    "        ps = ifnone(ps, [0]*len(layers))\n",
    "        if not is_listy(ps): ps = [ps]*len(layers)\n",
    "        self.embeds = nn.ModuleList([Embedding(ni, nf) for ni,nf in emb_szs])\n",
    "        self.emb_drop = nn.Dropout(embed_p)\n",
    "        self.bn_cont = nn.BatchNorm1d(n_cont)\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeds)\n",
    "        self.n_emb,self.n_cont,self.y_range = n_emb,n_cont,y_range\n",
    "        sizes = [n_emb + n_cont] + layers + [out_sz]\n",
    "        actns = [nn.ReLU(inplace=True) for _ in range(len(sizes)-2)] + [None]\n",
    "        _layers = [BnDropLin(sizes[i], sizes[i+1], bn=use_bn and i!=0, p=p, act=a)\n",
    "                       for i,(p,a) in enumerate(zip([0.]+ps,actns))]\n",
    "        if bn_final: _layers.append(nn.BatchNorm1d(sizes[-1]))\n",
    "        self.layers = nn.Sequential(*_layers)\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        x_cat, x_cont = inp\n",
    "        if self.n_emb != 0:\n",
    "            x = [e(x_cat[:,i]) for i,e in enumerate(self.embeds)]\n",
    "            x = torch.cat(x, 1)\n",
    "            x = self.emb_drop(x)\n",
    "        if self.n_cont != 0:\n",
    "            x_cont = self.bn_cont(x_cont)\n",
    "            x = torch.cat([x, x_cont], 1) if self.n_emb != 0 else x_cont\n",
    "        x = self.layers(x)\n",
    "        if self.y_range is not None:\n",
    "            x = (self.y_range[1]-self.y_range[0]) * torch.sigmoid(x) + self.y_range[0]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration example with training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.data.all import *\n",
    "from local.tabular.core import *\n",
    "from local.optimizer import *\n",
    "from local.learner import *\n",
    "from local.metrics import *\n",
    "from local.callback.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.ADULT_SAMPLE)\n",
    "df = pd.read_csv(path/'adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_names = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race']\n",
    "cont_names = ['age', 'fnlwgt', 'education-num']\n",
    "procs = [Categorify, FillMissing, Normalize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = RandomSplitter()(range_of(df))\n",
    "df1,proc = process_df(df, splits, procs=procs, cat_names=cat_names, cont_names=cont_names, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc = DataSource(df1.itertuples(), filts=splits, type_tfms=[\n",
    "    [ReadTabLine(proc, df1.columns)],\n",
    "    [attrgetter(\"salary\"), Categorize()]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbch = dsrc.databunch(bs=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabularModel(get_emb_sz(proc), len(proc.cont_names), 2, [200,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_func = partial(Adam, wd=0.01, eps=1e-5)\n",
    "learn = Learner(model, dbch, CrossEntropyLossFlat(), opt_func=opt_func, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.413437</td>\n",
       "      <td>0.380523</td>\n",
       "      <td>0.819871</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.368627</td>\n",
       "      <td>0.364678</td>\n",
       "      <td>0.839373</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.362460</td>\n",
       "      <td>0.353146</td>\n",
       "      <td>0.838452</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.354099</td>\n",
       "      <td>0.350457</td>\n",
       "      <td>0.841830</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.349438</td>\n",
       "      <td>0.348879</td>\n",
       "      <td>0.843520</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 01a_dataloader.ipynb.\n",
      "Converted 01a_script.ipynb.\n",
      "Converted 02_transforms.ipynb.\n",
      "Converted 03_pipeline.ipynb.\n",
      "Converted 04_data_external.ipynb.\n",
      "Converted 05_data_core.ipynb.\n",
      "Converted 06_data_source.ipynb.\n",
      "Converted 07_vision_core.ipynb.\n",
      "Converted 08_pets_tutorial.ipynb.\n",
      "Converted 09_vision_augment.ipynb.\n",
      "Converted 09a_rect_augment.ipynb.\n",
      "Converted 10_data_block.ipynb.\n",
      "Converted 11_layers.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_learner.ipynb.\n",
      "Converted 14_callback_schedule.ipynb.\n",
      "Converted 15_callback_hook.ipynb.\n",
      "Converted 16_callback_progress.ipynb.\n",
      "Converted 17_callback_tracker.ipynb.\n",
      "Converted 18_callback_fp16.ipynb.\n",
      "Converted 19_callback_mixup.ipynb.\n",
      "Converted 20_metrics.ipynb.\n",
      "Converted 21_tutorial_imagenette.ipynb.\n",
      "Converted 30_text_core.ipynb.\n",
      "Converted 31_text_data.ipynb.\n",
      "Converted 32_text_models_awdlstm.ipynb.\n",
      "Converted 33_test_models_core.ipynb.\n",
      "Converted 34_callback_rnn.ipynb.\n",
      "Converted 35_tutorial_wikitext.ipynb.\n",
      "Converted 36_text_models_qrnn.ipynb.\n",
      "Converted 40_tabular_core.ipynb.\n",
      "Converted 41_tabular_model.ipynb.\n",
      "Converted 60_vision_models_xresnet.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n",
      "Converted 95_synth_learner.ipynb.\n",
      "Converted notebook2jekyll.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
