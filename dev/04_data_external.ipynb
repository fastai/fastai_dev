{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "04_data_external.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1hvsVrsPmLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#default_exp data.external"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPmsmfowPmLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "from local.imports import *\n",
        "from local.test import *\n",
        "from local.core import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQGPpBZwPmLn",
        "colab_type": "text"
      },
      "source": [
        "# External data\n",
        "> Helper functions to download the fastai datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvJemeO8PmLn",
        "colab_type": "text"
      },
      "source": [
        "## Download things"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtsVncRCPmLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "def download_url(url, dest, overwrite=False, pbar=None, show_progress=True, chunk_size=1024*1024,\n",
        "                 timeout=4, retries=5):\n",
        "    \"Download `url` to `dest` unless it exists and not `overwrite`\"\n",
        "    if os.path.exists(dest) and not overwrite: return\n",
        "    \n",
        "    s = requests.Session()\n",
        "    s.mount('http://',requests.adapters.HTTPAdapter(max_retries=retries))\n",
        "    u = s.get(url, stream=True, timeout=timeout)\n",
        "    try: file_size = int(u.headers[\"Content-Length\"])\n",
        "    except: show_progress = False\n",
        "    \n",
        "    with open(dest, 'wb') as f:\n",
        "        nbytes = 0\n",
        "        if show_progress: \n",
        "            pbar = progress_bar(range(file_size), auto_update=False, leave=False, parent=pbar)\n",
        "        try:\n",
        "            for chunk in u.iter_content(chunk_size=chunk_size):\n",
        "                nbytes += len(chunk)\n",
        "                if show_progress: pbar.update(nbytes)\n",
        "                f.write(chunk)\n",
        "        except requests.exceptions.ConnectionError as e:\n",
        "            fname = url.split('/')[-1]\n",
        "            from fastai.datasets import Config\n",
        "            data_dir = dest.parent\n",
        "            print(f'\\n Download of {url} has failed after {retries} retries\\n'\n",
        "                  f' Fix the download manually:\\n'\n",
        "                  f'$ mkdir -p {data_dir}\\n'\n",
        "                  f'$ cd {data_dir}\\n'\n",
        "                  f'$ wget -c {url}\\n'\n",
        "                  f'$ tar -zxvf {fname}\\n'\n",
        "                  f' And re-run your code once the download is successful\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKVUPiHAPmLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url, fname = 'http://files.fast.ai/data/examples/mnist_tiny.tgz', Path('mnist_tiny.tgz')\n",
        "download_url(url, fname)\n",
        "assert fname.exists()\n",
        "t = os.path.getmtime(fname)\n",
        "#Launching the function again doesn't trigger a download since the file is already there.\n",
        "download_url(url, fname)\n",
        "test_eq(t, os.path.getmtime(fname))\n",
        "#But with the overwrite option, we download it again.\n",
        "download_url(url, fname, overwrite=True)\n",
        "test_ne(t, os.path.getmtime(fname))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4anmPdUbPmLz",
        "colab_type": "text"
      },
      "source": [
        "Base urls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgUMb4UNPmL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "class URLs():\n",
        "    \"Global constants for dataset and model URLs.\"\n",
        "    LOCAL_PATH = Path.cwd()\n",
        "    URL = 'http://files.fast.ai/data/examples/'\n",
        "    MDL = 'http://files.fast.ai/models/'\n",
        "    S3 = 'https://s3.amazonaws.com/fast-ai-'\n",
        "\n",
        "    S3_IMAGE    = f'{S3}imageclas/'\n",
        "    S3_IMAGELOC = f'{S3}imagelocal/'\n",
        "    S3_NLP      = f'{S3}nlp/'\n",
        "    S3_COCO     = f'{S3}coco/'\n",
        "    S3_MODEL    = f'{S3}modelzoo/'\n",
        "\n",
        "    # main datasets\n",
        "    ADULT_SAMPLE        = f'{URL}adult_sample.tgz'\n",
        "    BIWI_SAMPLE         = f'{URL}biwi_sample.tgz'\n",
        "    CIFAR               = f'{URL}cifar10.tgz'\n",
        "    COCO_SAMPLE         = f'{S3_COCO}coco_sample.tgz'\n",
        "    COCO_TINY           = f'{URL}coco_tiny.tgz'\n",
        "    HUMAN_NUMBERS       = f'{URL}human_numbers.tgz'\n",
        "    IMDB                = f'{S3_NLP}imdb.tgz'\n",
        "    IMDB_SAMPLE         = f'{URL}imdb_sample.tgz'\n",
        "    ML_SAMPLE           = f'{URL}movie_lens_sample.tgz'\n",
        "    MNIST_SAMPLE        = f'{URL}mnist_sample.tgz'\n",
        "    MNIST_TINY          = f'{URL}mnist_tiny.tgz'\n",
        "    MNIST_VAR_SIZE_TINY = f'{S3_IMAGE}mnist_var_size_tiny.tgz'\n",
        "    PLANET_SAMPLE       = f'{URL}planet_sample.tgz'\n",
        "    PLANET_TINY         = f'{URL}planet_tiny.tgz'\n",
        "    IMAGENETTE          = f'{S3_IMAGE}imagenette.tgz'\n",
        "    IMAGENETTE_160      = f'{S3_IMAGE}imagenette-160.tgz'\n",
        "    IMAGENETTE_320      = f'{S3_IMAGE}imagenette-320.tgz'\n",
        "    IMAGEWOOF           = f'{S3_IMAGE}imagewoof.tgz'\n",
        "    IMAGEWOOF_160       = f'{S3_IMAGE}imagewoof-160.tgz'\n",
        "    IMAGEWOOF_320       = f'{S3_IMAGE}imagewoof-320.tgz'\n",
        "\n",
        "    # kaggle competitions download dogs-vs-cats -p {DOGS.absolute()}\n",
        "    DOGS = f'{URL}dogscats.tgz'\n",
        "\n",
        "    # image classification datasets\n",
        "    CALTECH_101  = f'{S3_IMAGE}caltech_101.tgz'\n",
        "    CARS         = f'{S3_IMAGE}stanford-cars.tgz'\n",
        "    CIFAR_100    = f'{S3_IMAGE}cifar100.tgz'\n",
        "    CUB_200_2011 = f'{S3_IMAGE}CUB_200_2011.tgz'\n",
        "    FLOWERS      = f'{S3_IMAGE}oxford-102-flowers.tgz'\n",
        "    FOOD         = f'{S3_IMAGE}food-101.tgz'\n",
        "    MNIST        = f'{S3_IMAGE}mnist_png.tgz'\n",
        "    PETS         = f'{S3_IMAGE}oxford-iiit-pet.tgz'\n",
        "\n",
        "    # NLP datasets\n",
        "    AG_NEWS                 = f'{S3_NLP}ag_news_csv.tgz'\n",
        "    AMAZON_REVIEWS          = f'{S3_NLP}amazon_review_full_csv.tgz'\n",
        "    AMAZON_REVIEWS_POLARITY = f'{S3_NLP}amazon_review_polarity_csv.tgz'\n",
        "    DBPEDIA                 = f'{S3_NLP}dbpedia_csv.tgz'\n",
        "    MT_ENG_FRA              = f'{S3_NLP}giga-fren.tgz'\n",
        "    SOGOU_NEWS              = f'{S3_NLP}sogou_news_csv.tgz'\n",
        "    WIKITEXT                = f'{S3_NLP}wikitext-103.tgz'\n",
        "    WIKITEXT_TINY           = f'{S3_NLP}wikitext-2.tgz'\n",
        "    YAHOO_ANSWERS           = f'{S3_NLP}yahoo_answers_csv.tgz'\n",
        "    YELP_REVIEWS            = f'{S3_NLP}yelp_review_full_csv.tgz'\n",
        "    YELP_REVIEWS_POLARITY   = f'{S3_NLP}yelp_review_polarity_csv.tgz'\n",
        "\n",
        "    # Image localization datasets\n",
        "    BIWI_HEAD_POSE     = f\"{S3_IMAGELOC}biwi_head_pose.tgz\"\n",
        "    CAMVID             = f'{S3_IMAGELOC}camvid.tgz'\n",
        "    CAMVID_TINY        = f'{URL}camvid_tiny.tgz'\n",
        "    LSUN_BEDROOMS      = f'{S3_IMAGE}bedroom.tgz'\n",
        "    PASCAL_2007        = f'{S3_IMAGELOC}pascal_2007.tgz'\n",
        "    PASCAL_2012        = f'{S3_IMAGELOC}pascal_2012.tgz'\n",
        "\n",
        "    #Pretrained models\n",
        "    OPENAI_TRANSFORMER = f'{S3_MODEL}transformer.tgz'\n",
        "    WT103_FWD          = f'{S3_MODEL}wt103-fwd'\n",
        "    WT103_BWD          = f'{S3_MODEL}wt103-bwd'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fgNX6pCPmL7",
        "colab_type": "text"
      },
      "source": [
        "## Config file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9MQnyyZPmL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "def _get_config():\n",
        "    config_path = Path(os.getenv('FASTAI_HOME', '~/.fastai')).expanduser()\n",
        "    if not config_path.exists(): os.mkdir(config_path)\n",
        "    config_file = config_path/'config.yml'\n",
        "    if config_file.exists(): \n",
        "        with open(config_file, 'r') as yaml_file: \n",
        "            config = yaml.safe_load(yaml_file)\n",
        "            if 'version' in config and config['version'] == 1: return config\n",
        "    else: config = {}\n",
        "    #File inexistent or wrong version -> going to default\n",
        "    config = {'data_path':    str(config_path/'data'),\n",
        "              'archive_path': str(config_path/'archive'),\n",
        "              'model_path':   str(config_path/'models'),\n",
        "              'version':      1} \n",
        "    with open(config_file, 'w+') as yaml_file: \n",
        "        yaml.dump(config, yaml_file, default_flow_style=False)\n",
        "    return config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yllBciNfPmMD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This cell is just to make the config file compatible with current fastai\n",
        "config = _get_config()\n",
        "if 'data_archive_path' not in config: config['data_archive_path'] = config['data_path']\n",
        "config_path = Path(os.getenv('FASTAI_HOME', '~/.fastai')).expanduser()\n",
        "config_file,config_bak = config_path/'config.yml',config_path/'config.yml.bak'\n",
        "with open(config_file, 'w') as yaml_file: \n",
        "    yaml.dump(config, yaml_file, default_flow_style=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnMrd4TxPmMH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config_path = Path(os.getenv('FASTAI_HOME', '~/.fastai')).expanduser()\n",
        "config_file,config_bak = config_path/'config.yml',config_path/'config.yml.bak'\n",
        "if config_file.exists(): shutil.move(config_file, config_bak)\n",
        "#Test default config\n",
        "config = _get_config()\n",
        "assert (config_path/'config.yml').exists()\n",
        "test_eq(config, {\n",
        "        'data_path':    str(config_path/'data'),\n",
        "        'archive_path': str(config_path/'archive'),\n",
        "        'model_path':   str(config_path/'models'),\n",
        "        'version':      1\n",
        "    })\n",
        "\n",
        "#Test change in config\n",
        "config['archive_path'] = '.'\n",
        "with open(config_path/'config.yml', 'w') as yaml_file: \n",
        "    yaml.dump(config, yaml_file, default_flow_style=False)\n",
        "config = _get_config()\n",
        "test_eq(config, {\n",
        "        'data_path':    str(config_path/'data'),\n",
        "        'archive_path': '.',\n",
        "        'model_path':   str(config_path/'models'),\n",
        "        'version':      1\n",
        "    })\n",
        "\n",
        "if config_bak.exists(): shutil.move(config_bak, config_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BT4T_p3fPmMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "ConfigKey = Enum('ConfigKey', 'Data Archive Model')\n",
        "\n",
        "def get_path(c_key=ConfigKey.Data):\n",
        "    return Path(_get_config()[f\"{c_key.name.lower()}_path\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEKEVbXVPmMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = _get_config()\n",
        "test_eq(Path(config['data_path']),    get_path(ConfigKey.Data))\n",
        "test_eq(Path(config['archive_path']), get_path(ConfigKey.Archive))\n",
        "test_eq(Path(config['model_path']),   get_path(ConfigKey.Model))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMSi3Po7PmMV",
        "colab_type": "text"
      },
      "source": [
        "### Download in the right place"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zj7IH8w1PmMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def _url2path(url, c_key=ConfigKey.Archive):\n",
        "    fname = url.split('/')[-1]\n",
        "    local_path = URLs.LOCAL_PATH/('models' if c_key==ConfigKey.Model else 'data')/fname\n",
        "    if local_path.exists(): return local_path\n",
        "    return get_path(c_key)/fname"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APoOS5HZPmMY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#hide\n",
        "path,path_bak = URLs.LOCAL_PATH/'data',URLs.LOCAL_PATH/'data1'\n",
        "if path.exists(): shutil.move(path, path_bak)\n",
        "test_eq(_url2path(URLs.MNIST_TINY), get_path(ConfigKey.Archive)/'mnist_tiny.tgz')\n",
        "test_eq(_url2path(URLs.MNIST_TINY.replace('tgz', 'tar')), get_path(ConfigKey.Archive)/'mnist_tiny.tar')\n",
        "test_eq(_url2path(URLs.MNIST_TINY,c_key=ConfigKey.Model), get_path(ConfigKey.Model)/'mnist_tiny.tgz')\n",
        "if path_bak.exists(): shutil.move(path_bak, path)\n",
        "\n",
        "os.makedirs('data', exist_ok=True)\n",
        "download_url(f\"{URLs.MNIST_TINY}.tgz\", 'data/mnist_tiny.tgz')\n",
        "test_eq(_url2path(URLs.MNIST_TINY), Path.cwd()/'data'/'mnist_tiny.tgz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wNDHa08PmMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# export\n",
        "def download_data(url, fname=None, c_key=ConfigKey.Archive, force_download=False):\n",
        "    \"Download `url` to `fname`.\"\n",
        "    fname = Path(fname or _url2path(url, c_key=c_key))\n",
        "    fname.parent.mkdir(parents=True, exist_ok=True)\n",
        "    if not fname.exists() or force_download:\n",
        "        print(f'Downloading {url}')\n",
        "        download_url(url, fname, overwrite=force_download)\n",
        "    return fname"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yPkG2k0PmMb",
        "colab_type": "text"
      },
      "source": [
        "If `fname` is None, it will default to the archive folder you have in your config file (or data, model if you specify a different `c_key`) followed by the last part of the url: for instance `URLs.MNIST_SAMPLE` is `http://files.fast.ai/data/examples/mnist_sample.tgz` and the default value for `fname` will be `~/.fastai/archive/mnist_sample.tgz`.\n",
        "\n",
        "If `force_download=True`, the file is alwayd downloaded. Otherwise, it's only when the file doesn't exists that the download is triggered."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIy3EWCZPmMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_eq(download_data(URLs.MNIST_SAMPLE), get_path(ConfigKey.Archive)/'mnist_sample.tgz')\n",
        "test_eq(download_data(URLs.MNIST_TINY, fname=Path('mnist.tgz')), Path('mnist.tgz'))\n",
        "os.remove(Path('mnist.tgz'))\n",
        "\n",
        "tst_model = get_path(ConfigKey.Model)/'mnist_tiny.tgz'\n",
        "test_eq(download_data(URLs.MNIST_TINY, c_key=ConfigKey.Model), tst_model)\n",
        "os.remove(tst_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg2ADapCPmMh",
        "colab_type": "text"
      },
      "source": [
        "### Check datasets -"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMCsrRXHPmMi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#hide\n",
        "#Tricking jupyter notebook to have a __file__ attribute. All _file_ will be replaced by __file__\n",
        "_file_ = Path('local').absolute()/'data'/'external.py'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghygK0R3PmMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def _get_check(url):\n",
        "    checks = json.load(open(Path(_file_).parent/'checks.txt', 'r'))\n",
        "    return checks.get(url, None)\n",
        "\n",
        "def _check_file(fname):\n",
        "    size = os.path.getsize(fname)\n",
        "    with open(fname, \"rb\") as f:\n",
        "        hash_nb = hashlib.md5(f.read(2**20)).hexdigest()\n",
        "    return [size,hash_nb]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CS5Gw2qrPmMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#hide\n",
        "test_eq(_get_check(URLs.MNIST_SAMPLE), _check_file(_url2path(URLs.MNIST_SAMPLE)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HelnHjHpPmMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def _add_check(url, fname):\n",
        "    \"Internal function to update the internal check file with `url` and check on `fname`.\"\n",
        "    checks = json.load(open(Path(_file_).parent/'checks.txt', 'r'))\n",
        "    checks[url] = _check_file(fname)\n",
        "    json.dump(checks, open(Path(_file_).parent/'checks.txt', 'w'), indent=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MN7-3jsNPmMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#export\n",
        "def untar_data(url, fname=None, dest=None, c_key=ConfigKey.Data, force_download=False):\n",
        "    \"Download `url` to `fname` if `dest` doesn't exist, and un-tgz to folder `dest`.\"\n",
        "    default_dest = _url2path(url, c_key=c_key).with_suffix('')\n",
        "    dest = default_dest if dest is None else Path(dest)/default_dest.name\n",
        "    fname = Path(fname or _url2path(url))\n",
        "    if fname.exists() and _get_check(url) and _check_file(fname) != _get_check(url):\n",
        "        print(\"A new version of this is available, downloading...\")\n",
        "        force_download = True\n",
        "    if force_download:\n",
        "        if fname.exists(): os.remove(fname)\n",
        "        if dest.exists(): shutil.rmtree(dest)\n",
        "    if not dest.exists():\n",
        "        fname = download_data(url, fname=fname, c_key=c_key)\n",
        "        if _get_check(url) and _check_file(fname) != _get_check(url):\n",
        "            print(f\"File downloaded is broken. Remove {fname} and try again.\")\n",
        "        tarfile.open(fname, 'r:gz').extractall(dest.parent)\n",
        "    return dest"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGZdX4fAPmMy",
        "colab_type": "text"
      },
      "source": [
        "`untar_data` is a convenience function for the fastai datasets, intended to work with the urls in `URLs`. You can use it with another url only if it ends with `.tgz` (otherwise the function can download it but not decompress it). For other extensions, you should use `download_data` then the necessary decompress function.\n",
        "\n",
        "If `fname` is specified, the data will be downloaded to that destination, otherwise it will default to the archive path in your config file (default `~/.fastai/archive/`) followed by the last part of your url. For instance `URLs.MNIST_SAMPLE` is `http://files.fast.ai/data/examples/mnist_sample.tgz` and the default value for `fname` will be `~/.fastai/archive/mnist_sample.tgz`.\n",
        "\n",
        "If `dest` is specified, the data will be decompressed to that folder. Otherwise, it will default to the data path (or model/archive if you specify a different `c_key`) in your config file (default `~/.fastai/data/`) followed by the last part of your url without extension. For instance `URLs.MNIST_SAMPLE` is `http://files.fast.ai/data/examples/mnist_sample.tgz` and the default value for `dest` will be `~/.fastai/data/mnist_sample`.\n",
        "\n",
        "`force_download=True` will retrigger a download, otherwise the behavior is to:\n",
        "- not do anything when `dest` exists\n",
        "- otherwise decompress `fname` to `dest` if `fname` exists\n",
        "- otherwise download then decompress `fname` to `dest`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd-xyiGaPmMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_eq(untar_data(URLs.MNIST_SAMPLE), get_path()/'mnist_sample')\n",
        "\n",
        "#Test specific fname\n",
        "untar_data(URLs.MNIST_TINY, fname='mnist_tiny.tgz', force_download=True)\n",
        "p = Path('mnist_tiny.tgz')\n",
        "assert p.exists()\n",
        "p.unlink()\n",
        "os.remove(Path('mnist_sample.tgz'))\n",
        "if p.exists(): p.unlink()\n",
        "    \n",
        "#Test specific dest\n",
        "test_eq(untar_data(URLs.MNIST_TINY, dest='.'), Path('mnist_tiny'))\n",
        "assert Path('mnist_tiny').exists()\n",
        "shutil.rmtree(Path('mnist_tiny'))\n",
        "\n",
        "#Test c_key\n",
        "tst_model = get_path(ConfigKey.Model)/'mnist_sample'\n",
        "test_eq(untar_data(URLs.MNIST_SAMPLE, c_key=ConfigKey.Model), tst_model)\n",
        "assert not tst_model.with_suffix('.tgz').exists() #Archive wasn't downloaded in the models path\n",
        "assert (get_path(ConfigKey.Archive)/'mnist_sample.tgz').exists() #Archive was downloaded there\n",
        "shutil.rmtree(tst_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5LQZRbXPmM0",
        "colab_type": "text"
      },
      "source": [
        "## Export -"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzkstfsIPmM3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "9f8efe08-f222-44c5-9c28-0d39a89bdcc8"
      },
      "source": [
        "#hide\n",
        "! ./notebook2script.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/utils/traitlets.py:5: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
            "  warn(\"IPython.utils.traitlets has moved to a top-level traitlets package.\")\n",
            "Converted 00_test.ipynb.\n",
            "Converted 01_core.ipynb.\n",
            "Converted 01a_dataloader.ipynb.\n",
            "Converted 01a_script.ipynb.\n",
            "Converted 02_transforms.ipynb.\n",
            "Converted 03_pipeline.ipynb.\n",
            "Converted 04_data_external.ipynb.\n",
            "Converted 05_data_core.ipynb.\n",
            "Converted 06_data_source.ipynb.\n",
            "Converted 07_vision_core.ipynb.\n",
            "Converted 08_pets_tutorial.ipynb.\n",
            "Converted 09_vision_augment.ipynb.\n",
            "Converted 11_layers.ipynb.\n",
            "Converted 12_optimizer.ipynb.\n",
            "Converted 13_learner.ipynb.\n",
            "Converted 14_callback_schedule.ipynb.\n",
            "Converted 15_callback_hook.ipynb.\n",
            "Converted 16_callback_progress.ipynb.\n",
            "Converted 17_callback_tracker.ipynb.\n",
            "Converted 18_callback_fp16.ipynb.\n",
            "Converted 19_callback_mixup.ipynb.\n",
            "Converted 20_metrics.ipynb.\n",
            "Converted 21_tutorial_imagenette.ipynb.\n",
            "Converted 30_text_core.ipynb.\n",
            "Converted 31_text_data.ipynb.\n",
            "Converted 32_text_models_awdlstm.ipynb.\n",
            "Converted 33_test_models_core.ipynb.\n",
            "Converted 34_callback_rnn.ipynb.\n",
            "Converted 35_tutorial_wikitext.ipynb.\n",
            "Converted 36_text_models_qrnn.ipynb.\n",
            "Converted 40_tabular_core.ipynb.\n",
            "Converted 41_tabular_model.ipynb.\n",
            "Converted 50_data_block.ipynb.\n",
            "Converted 60_vision_models_xresnet.ipynb.\n",
            "Converted 90_notebook_core.ipynb.\n",
            "Converted 91_notebook_export.ipynb.\n",
            "Converted 92_notebook_showdoc.ipynb.\n",
            "Converted 93_notebook_export2html.ipynb.\n",
            "Converted 94_index.ipynb.\n",
            "Converted 95_synth_learner.ipynb.\n",
            "Converted notebook2jekyll.ipynb.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqyZO3c8PmM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}