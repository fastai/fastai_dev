{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.torch_basics import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.data.all import *\n",
    "from local.text.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from local.notebook.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp text.data\n",
    "#default_cls_lvl 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text data\n",
    "\n",
    "> Functions and transforms to help gather text data in a `DataSource`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numericalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_vocab(count, min_freq=3, max_vocab=60000):\n",
    "    \"Create a vocab of `max_vocab` size from `Counter` `count` with items present more than `min_freq`\"\n",
    "    vocab = [o for o,c in count.most_common(max_vocab) if c >= min_freq]\n",
    "    for o in reversed(defaults.text_spec_tok): #Make sure all special tokens are in the vocab\n",
    "        if o in vocab: vocab.remove(o)\n",
    "        vocab.insert(0, o)\n",
    "    vocab = vocab[:max_vocab]\n",
    "    return vocab + [f'xxfake' for i in range(0, 8-len(vocab)%8)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = Counter(['a', 'a', 'a', 'a', 'b', 'b', 'c', 'c', 'd'])\n",
    "test_eq(set([x for x in make_vocab(count) if not x.startswith('xxfake')]), \n",
    "        set(defaults.text_spec_tok + 'a'.split()))\n",
    "test_eq(len(make_vocab(count))%8, 0)\n",
    "test_eq(set([x for x in make_vocab(count, min_freq=1) if not x.startswith('xxfake')]), \n",
    "        set(defaults.text_spec_tok + 'a b c d'.split()))\n",
    "test_eq(set([x for x in make_vocab(count,max_vocab=12, min_freq=1) if not x.startswith('xxfake')]), \n",
    "        set(defaults.text_spec_tok + 'a b c'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TensorText(TensorBase):   pass\n",
    "class LMTensorText(TensorText): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Numericalize(Transform):\n",
    "    \"Reversible transform of tokenized texts to numericalized ids\"\n",
    "    def __init__(self, vocab=None, min_freq=3, max_vocab=60000, sep=' '):\n",
    "        self.vocab,self.min_freq,self.max_vocab,self.sep = vocab,min_freq,max_vocab,sep\n",
    "        self.o2i = None if vocab is None else defaultdict(int, {v:k for k,v in enumerate(vocab)})\n",
    "\n",
    "    def setup(self, dsrc):\n",
    "        if dsrc is None: return\n",
    "        if self.vocab is None:\n",
    "            count = Counter(p for o in dsrc for p in o)\n",
    "            self.vocab = make_vocab(count, min_freq=self.min_freq, max_vocab=self.max_vocab)\n",
    "            self.o2i = defaultdict(int, {v:k for k,v in enumerate(self.vocab) if v != 'xxfake'})\n",
    "\n",
    "    def encodes(self, o): return TensorText(tensor([self.o2i  [o_] for o_ in o]))\n",
    "    def decodes(self, o): return Str(self.sep.join([self.vocab[o_] for o_ in o if self.vocab[o_] != PAD]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = Numericalize(min_freq=1, sep=' ')\n",
    "num.setup(L('This is an example of text'.split(), 'this is another text'.split()))\n",
    "test_eq(set([x for x in num.vocab if not x.startswith('xxfake')]), \n",
    "        set(defaults.text_spec_tok + 'This is an example of text this another'.split()))\n",
    "test_eq(len(num.vocab)%8, 0)\n",
    "start = 'This is an example of text'\n",
    "t = num(start.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(t, tensor([11, 9, 12, 13, 14, 10]))\n",
    "test_eq(num.decode(t), start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = Numericalize(min_freq=2, sep=' ')\n",
    "num.setup(L('This is an example of text'.split(), 'this is another text'.split()))\n",
    "test_eq(set([x for x in num.vocab if not x.startswith('xxfake')]), \n",
    "        set(defaults.text_spec_tok + 'is text'.split()))\n",
    "test_eq(len(num.vocab)%8, 0)\n",
    "t = num(start.split())\n",
    "test_eq(t, tensor([0, 9, 0, 0, 0, 10]))\n",
    "test_eq(num.decode(t), f'{UNK} is {UNK} {UNK} {UNK} text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LM_DataLoader -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "#TODO: add backward\n",
    "@delegates()\n",
    "class LMDataLoader(TfmdDL):\n",
    "    def __init__(self, dataset, lens=None, cache=2, bs=64, seq_len=72, num_workers=0, **kwargs):\n",
    "        super().__init__(dataset=dataset, bs=bs, num_workers=num_workers, **kwargs)\n",
    "        self.items = ReindexCollection([(o[0] if isinstance(o, tuple) else o)\n",
    "                                          for o in dataset], cache=cache)\n",
    "        self.seq_len = seq_len\n",
    "        if lens is None: lens = [len(o) for o in self.items]\n",
    "        self.lens = ReindexCollection(lens, idxs=self.items.idxs)\n",
    "        # The \"-1\" is to allow for final label\n",
    "        self.m = round_multiple(sum(lens)-1, bs*seq_len, round_down=True)\n",
    "        self.n = self.m//(seq_len)\n",
    "        self.spb = self.n//bs\n",
    "        self.make_chunks()\n",
    "\n",
    "    def make_chunks(self): self.chunks = Chunks(self.items, self.lens)\n",
    "    def shuffle_fn(self,idxs):\n",
    "        self.items.shuffle()\n",
    "        self.make_chunks()\n",
    "        return idxs\n",
    "\n",
    "    def create_item(self, seq):\n",
    "        if seq>=self.n: raise IndexError\n",
    "        st = ((seq%self.bs)*self.spb + (seq//self.bs)) * self.seq_len\n",
    "        txt = self.chunks[st : st+self.seq_len+1]\n",
    "        return LMTensorText(txt[:-1]),txt[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs,sl = 4,3\n",
    "ints = L([0,1,2,3,4],[5,6,7,8,9,10],[11,12,13,14,15,16,17,18],[19,20],[21,22,23],[24]).map(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = LMDataLoader(ints, bs=bs, seq_len=sl)\n",
    "test_eq(list(dl),\n",
    "    [[tensor([[0, 1, 2], [6, 7, 8], [12, 13, 14], [18, 19, 20]]),\n",
    "      tensor([[1, 2, 3], [7, 8, 9], [13, 14, 15], [19, 20, 21]])],\n",
    "     [tensor([[3, 4, 5], [ 9, 10, 11], [15, 16, 17], [21, 22, 23]]),\n",
    "      tensor([[4, 5, 6], [10, 11, 12], [16, 17, 18], [22, 23, 24]])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Check lens work\n",
    "dl = LMDataLoader(ints, lens=ints.map(len), bs=bs, seq_len=sl)\n",
    "test_eq(list(dl),\n",
    "    [[tensor([[0, 1, 2], [6, 7, 8], [12, 13, 14], [18, 19, 20]]),\n",
    "      tensor([[1, 2, 3], [7, 8, 9], [13, 14, 15], [19, 20, 21]])],\n",
    "     [tensor([[3, 4, 5], [ 9, 10, 11], [15, 16, 17], [21, 22, 23]]),\n",
    "      tensor([[4, 5, 6], [10, 11, 12], [16, 17, 18], [22, 23, 24]])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = LMDataLoader(ints, bs=bs, seq_len=sl, shuffle=True)\n",
    "for x,y in dl: test_eq(x[:,1:], y[:,:-1])\n",
    "((x0,y0), (x1,y1)) = tuple(dl)\n",
    "#Second batch begins where first batch ended\n",
    "test_eq(y0[:,-1], x1[:,0]) \n",
    "test_eq(type(x0), LMTensorText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_batch(x: TensorText, y, samples, ctxs=None, max_n=10, **kwargs):\n",
    "    if ctxs is None: ctxs = get_empty_df(min(len(samples), max_n))\n",
    "    ctxs = show_batch[object](x, y, samples, max_n=max_n, ctxs=ctxs, **kwargs)\n",
    "    display_df(pd.DataFrame(ctxs))\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@typedispatch\n",
    "def show_batch(x: LMTensorText, y, samples, ctxs=None, max_n=10, **kwargs):\n",
    "    return show_batch[TensorText](x, None, samples, ctxs=ctxs, max_n=max_n, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.&lt;br /&gt;&lt;br /&gt;But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is som...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  \\\n",
       "0  negative   \n",
       "1  positive   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \\\n",
       "0                                                                                                                                                                                                    Un-bleeping-believable! Meg Ryan doesn't even look her usual pert lovable self in this, which normally makes me forgive her shallow ticky acting schtick. Hard to believe she was the producer on this dog. Plus Kevin Kline: what kind of suicide trip has his career been on? Whoosh... Banzai!!! Finally this was directed by the guy who did Big Chill? Must be a replay of Jonestown - hollywood style. Wooofff!   \n",
       "1  This is a extremely well-made film. The acting, script and camera-work are all first-rate. The music is good, too, though it is mostly early in the film, when things are still relatively cheery. There are no really superstars in the cast, though several faces will be familiar. The entire cast does an excellent job with the script.<br /><br />But it is hard to watch, because there is no good end to a situation like the one presented. It is now fashionable to blame the British for setting Hindus and Muslims against each other, and then cruelly separating them into two countries. There is som...   \n",
       "\n",
       "   is_valid  \n",
       "0     False  \n",
       "1     False  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "df = pd.read_csv(path/'texts.csv')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>False</td>\n",
       "      <td>[xxbos, xxmaj, un, -, bleeping, -, believable, !, xxmaj, meg, xxmaj, ryan, does, n't, even, look, her, usual, pert, lovable, self, in, this, ,, which, normally, makes, me, forgive, her, shallow, ticky, acting, schtick, ., xxmaj, hard, to, believe, she, was, the, producer, on, this, dog, ., xxmaj, plus, xxmaj, kevin, xxmaj, kline, :, what, kind, of, suicide, trip, has, his, career, been, on, ?, xxmaj, whoosh, …, xxmaj, banzai, xxrep, 3, !, xxmaj, finally, this, was, directed, by, the, guy, who, did, xxmaj, big, xxmaj, chill, ?, xxmaj, must, be, a, replay, of, xxmaj, jonestown, -, hollywood,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>False</td>\n",
       "      <td>[xxbos, xxmaj, this, is, a, extremely, well, -, made, film, ., xxmaj, the, acting, ,, script, and, camera, -, work, are, all, first, -, rate, ., xxmaj, the, music, is, good, ,, too, ,, though, it, is, mostly, early, in, the, film, ,, when, things, are, still, relatively, cheery, ., xxmaj, there, are, no, really, superstars, in, the, cast, ,, though, several, faces, will, be, familiar, ., xxmaj, the, entire, cast, does, an, excellent, job, with, the, script, ., \\n\\n, xxmaj, but, it, is, hard, to, watch, ,, because, there, is, no, good, end, to, a, situation, like, the, one, ...]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  is_valid  \\\n",
       "0  negative     False   \n",
       "1  positive     False   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text  \n",
       "0  [xxbos, xxmaj, un, -, bleeping, -, believable, !, xxmaj, meg, xxmaj, ryan, does, n't, even, look, her, usual, pert, lovable, self, in, this, ,, which, normally, makes, me, forgive, her, shallow, ticky, acting, schtick, ., xxmaj, hard, to, believe, she, was, the, producer, on, this, dog, ., xxmaj, plus, xxmaj, kevin, xxmaj, kline, :, what, kind, of, suicide, trip, has, his, career, been, on, ?, xxmaj, whoosh, …, xxmaj, banzai, xxrep, 3, !, xxmaj, finally, this, was, directed, by, the, guy, who, did, xxmaj, big, xxmaj, chill, ?, xxmaj, must, be, a, replay, of, xxmaj, jonestown, -, hollywood,...  \n",
       "1                 [xxbos, xxmaj, this, is, a, extremely, well, -, made, film, ., xxmaj, the, acting, ,, script, and, camera, -, work, are, all, first, -, rate, ., xxmaj, the, music, is, good, ,, too, ,, though, it, is, mostly, early, in, the, film, ,, when, things, are, still, relatively, cheery, ., xxmaj, there, are, no, really, superstars, in, the, cast, ,, though, several, faces, will, be, familiar, ., xxmaj, the, entire, cast, does, an, excellent, job, with, the, script, ., \\n\\n, xxmaj, but, it, is, hard, to, watch, ,, because, there, is, no, good, end, to, a, situation, like, the, one, ...]  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tok,count = tokenize_df(df, 'text')\n",
    "df_tok.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = RandomSplitter()(range_of((df_tok)))\n",
    "tfm = Numericalize(make_vocab(count))\n",
    "dsrc = DataSource(df_tok, [[attrgetter('text'), tfm]], splits=splits, dl_type=LMDataLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos xxmaj this was a terrible film . xxmaj there was no story line whatsoever . xxmaj to top it all off , when they could n't explain the blood and gore ( the only good part ) … they threw in a few aliens ! i hate when directors ( or whatever ) run out of ideas and then blame the aliens ! xxmaj watch this film if you like . xxmaj but do n't say i did n't warn you . xxmaj two things : xxmaj how could xxmaj xxunk say \" welcome \" when he did n't have a tongue ? xxmaj its a pity xxmaj mr xxmaj jones did n't have a bigger role . xxmaj second thing that xxunk me , why were we shown xxmaj xxunk xxmaj jones ' boils and him cutting them off and putting them into blue liquid , then these have no further role . xxmaj why not ? i do n't like to be shown something and that has nothing to do with the story line whatsoever . xxmaj in short . xxmaj bad story . i would n't waste my time - wish xxmaj i 'd have watched xxmaj xxunk instead .\n"
     ]
    }
   ],
   "source": [
    "show_at(dsrc.train, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbunch = dsrc.databunch(bs=16, seq_len=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxmaj predictable , told a thousand times story with the usual drama in between , a couple of pretty xxunk sex scenes xxunk with some character paranoia , 70 's style incidental violin horror music that is comical at times , i could n't help xxunk to myself . \\n\\n i usually like xxmaj xxunk , and it has to be said that the acting is not all that bad ,</td>\n",
       "      <td>xxmaj predictable , told a thousand times story with the usual drama in between , a couple of pretty xxunk sex scenes xxunk with some character paranoia , 70 's style incidental violin horror music that is comical at times , i could n't help xxunk to myself . \\n\\n i usually like xxmaj xxunk , and it has to be said that the acting is not all that bad , the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>can - be performances in quite some time . xxmaj while xxmaj dawson is seen in some good supporting performances in some great - to - bad films , she proves here she has what it takes to deliver some emotionally sweeping and moving performances , xxunk and xxunk . \\n\\n xxmaj one of the best films of its year ( and 2007 was a strong one ) - had this underrated</td>\n",
       "      <td>- be performances in quite some time . xxmaj while xxmaj dawson is seen in some good supporting performances in some great - to - bad films , she proves here she has what it takes to deliver some emotionally sweeping and moving performances , xxunk and xxunk . \\n\\n xxmaj one of the best films of its year ( and 2007 was a strong one ) - had this underrated and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>more of those brilliant young men who went all out and xxunk to make a teen romance film ( can i actually call it xxunk it would xxunk the devil out of its xxunk a xxunk budget but packed with such taste , xxunk and maturity . xxmaj peter xxmaj xxunk you deserve more admiration and xxunk once again for xxunk to the powers that be in the \" industry \" that</td>\n",
       "      <td>of those brilliant young men who went all out and xxunk to make a teen romance film ( can i actually call it xxunk it would xxunk the devil out of its xxunk a xxunk budget but packed with such taste , xxunk and maturity . xxmaj peter xxmaj xxunk you deserve more admiration and xxunk once again for xxunk to the powers that be in the \" industry \" that stereotypes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>it is all about letting someone else , other than xxmaj allen , get the girl , she does n't get anyone . xxmaj jackman , the man she 's been making love to , is a man who murdered a prostitute . xxmaj nice , xxmaj woody . xxmaj nice way to xxunk your heroine for being beyond your grasp . \\n\\n xxmaj in a xxunk aggressive touch , xxmaj allen</td>\n",
       "      <td>is all about letting someone else , other than xxmaj allen , get the girl , she does n't get anyone . xxmaj jackman , the man she 's been making love to , is a man who murdered a prostitute . xxmaj nice , xxmaj woody . xxmaj nice way to xxunk your heroine for being beyond your grasp . \\n\\n xxmaj in a xxunk aggressive touch , xxmaj allen xxunk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\n xxmaj also , xxmaj black xxmaj mask is really the kind of film that takes a genre 's conventions and pushes them to xxunk , simply because the conventions themselves are wholly unrealistic . xxmaj after decades of watching people get shot without any noticeable open wounds , many people were xxunk to see xxmaj xxunk and xxmaj xxunk and the xxunk of the xxmaj wild xxmaj bunch xxunk blood all</td>\n",
       "      <td>xxmaj also , xxmaj black xxmaj mask is really the kind of film that takes a genre 's conventions and pushes them to xxunk , simply because the conventions themselves are wholly unrealistic . xxmaj after decades of watching people get shot without any noticeable open wounds , many people were xxunk to see xxmaj xxunk and xxmaj xxunk and the xxunk of the xxmaj wild xxmaj bunch xxunk blood all over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>miller 's xxup crossing whilst the subtext of guilt and redemption can be summed up by xxmaj xxunk and xxmaj xxunk 's gangster epics . xxmaj despite having a seen it all before feel this should n't be taken as a heavy criticism of xxmaj sam xxmaj mendes film which i repeat is haunting and beautiful and the only flaws that work against it is a very slow opening twenty minutes and</td>\n",
       "      <td>'s xxup crossing whilst the subtext of guilt and redemption can be summed up by xxmaj xxunk and xxmaj xxunk 's gangster epics . xxmaj despite having a seen it all before feel this should n't be taken as a heavy criticism of xxmaj sam xxmaj mendes film which i repeat is haunting and beautiful and the only flaws that work against it is a very slow opening twenty minutes and i</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbunch.show_batch(max_n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = dbunch.one_batch()\n",
    "test_eq(type(x), LMTensorText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(dbunch.valid_ds[0][0]), dbunch.valid_dl.lens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def pad_input(samples, pad_idx=1, pad_fields=0, pad_first=False, backwards=False):\n",
    "    \"Function that collect samples and adds padding. Flips token order if needed\"\n",
    "    pad_fields = L(pad_fields)\n",
    "    max_len_l = pad_fields.map(lambda f: max([len(s[f]) for s in samples]))\n",
    "    if backwards: pad_first = not pad_first\n",
    "    def _f(field_idx, x):\n",
    "        if field_idx not in pad_fields: return x\n",
    "        idx = pad_fields.items.index(field_idx) #TODO: remove items if L.index is fixed\n",
    "        sl = slice(-len(x), sys.maxsize) if pad_first else slice(0, len(x))\n",
    "        pad =  x.new_zeros(max_len_l[idx]-x.shape[0])+pad_idx\n",
    "        x1 = torch.cat([pad, x] if pad_first else [x, pad])\n",
    "        if backwards: x1 = x1.flip(0)\n",
    "        return retain_type(x1, x)\n",
    "    return [tuple(map(lambda idxx: _f(*idxx), enumerate(s))) for s in samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(pad_input([(tensor([1,2,3]),1), (tensor([4,5]), 2), (tensor([6]), 3)], pad_idx=0), \n",
    "        [(tensor([1,2,3]),1), (tensor([4,5,0]),2), (tensor([6,0,0]), 3)])\n",
    "test_eq(pad_input([(tensor([1,2,3]), (tensor([6]))), (tensor([4,5]), tensor([4,5])), (tensor([6]), (tensor([1,2,3])))], pad_idx=0, pad_fields=1), \n",
    "        [(tensor([1,2,3]),(tensor([6,0,0]))), (tensor([4,5]),tensor([4,5,0])), ((tensor([6]),tensor([1, 2, 3])))])\n",
    "test_eq(pad_input([(tensor([1,2,3]),1), (tensor([4,5]), 2), (tensor([6]), 3)], pad_idx=0, pad_first=True), \n",
    "        [(tensor([1,2,3]),1), (tensor([0,4,5]),2), (tensor([0,0,6]), 3)])\n",
    "test_eq(pad_input([(tensor([1,2,3]),1), (tensor([4,5]), 2), (tensor([6]), 3)], pad_idx=0, backwards=True), \n",
    "        [(tensor([3,2,1]),1), (tensor([5,4,0]),2), (tensor([6,0,0]), 3)])\n",
    "x = test_eq(pad_input([(tensor([1,2,3]),1), (tensor([4,5]), 2), (tensor([6]), 3)], pad_idx=0, backwards=True), \n",
    "        [(tensor([3,2,1]),1), (tensor([5,4,0]),2), (tensor([6,0,0]), 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Check retain type\n",
    "x = [(TensorText([1,2,3]),1), (TensorText([4,5]), 2), (TensorText([6]), 3)]\n",
    "y = pad_input(x, pad_idx=0)\n",
    "for s in y: test_eq(type(s[0]), TensorText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _default_sort(x): return len(x[0])\n",
    "\n",
    "@delegates(TfmdDL)\n",
    "class SortedDL(TfmdDL):\n",
    "    def __init__(self, dataset, sort_func=None, res=None, **kwargs):\n",
    "        super().__init__(dataset, **kwargs)\n",
    "        self.sort_func = _default_sort if sort_func is None else sort_func\n",
    "        self.res = [self.sort_func(self.do_item(i)) for i in range_of(self.dataset)] if res is None else res\n",
    "        self.idx_max = np.argmax(self.res)\n",
    "\n",
    "    def get_idxs(self):\n",
    "        idxs = super().get_idxs()\n",
    "        if self.shuffle: return idxs\n",
    "        return sorted(idxs, key=lambda i: self.res[i], reverse=True)\n",
    "\n",
    "    def shuffle_fn(self,idxs):\n",
    "        idxs = np.random.permutation(len(self.dataset))\n",
    "        idx_max = np.extract(idxs==self.idx_max, idxs)[0]\n",
    "        idxs[0],idxs[idx_max] = idxs[idx_max],idxs[0]\n",
    "        sz = self.bs*50\n",
    "        chunks = [idxs[i:i+sz] for i in range(0, len(idxs), sz)]\n",
    "        chunks = [sorted(s, key=lambda i: self.res[i], reverse=True) for s in chunks]\n",
    "        sort_idx = np.concatenate(chunks)\n",
    "\n",
    "        sz = self.bs\n",
    "        batches = [sort_idx[i:i+sz] for i in range(0, len(sort_idx), sz)]\n",
    "        sort_idx = np.concatenate(np.random.permutation(batches[1:-1])) if len(batches) > 2 else np.array([],dtype=np.int)\n",
    "        sort_idx = np.concatenate((batches[0], sort_idx) if len(batches)==1 else (batches[0], sort_idx, batches[-1]))\n",
    "        return iter(sort_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [(tensor([1,2]),1), (tensor([3,4,5,6]),2), (tensor([7]),3), (tensor([8,9,10]),4)]\n",
    "dl = SortedDL(ds, bs=2, before_batch=partial(pad_input, pad_idx=0))\n",
    "test_eq(list(dl), [(tensor([[ 3,  4,  5,  6], [ 8,  9, 10,  0]]), tensor([2, 4])), \n",
    "                   (tensor([[1, 2], [7, 0]]), tensor([1, 3]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = [(tensor(range(random.randint(1,10))),i) for i in range(101)]\n",
    "dl = SortedDL(ds, bs=2, create_batch=partial(pad_input, pad_idx=-1), shuffle=True, num_workers=0)\n",
    "batches = list(dl)\n",
    "max_len = len(batches[0][0])\n",
    "for b in batches: \n",
    "    assert(len(b[0])) <= max_len \n",
    "    test_ne(b[0][-1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = RandomSplitter()(range_of(df_tok))\n",
    "dsrc = DataSource(df_tok, splits=splits, tfms=[\n",
    "    [attrgetter(\"text\"), Numericalize(make_vocab(count))],\n",
    "    [attrgetter(\"label\"), Categorize()]], dl_type=SortedDL)\n",
    "dbch = dsrc.databunch(before_batch=pad_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxbos xxup the xxup shop xxup around xxup the xxup corner is one of the xxunk and most feel - good romantic comedies ever made . xxmaj there 's just no getting around that , and it 's hard to actually put one 's feeling for this film into words . xxmaj it 's not one of those films that tries too hard , nor does it come up with the xxunk possible scenarios to get the two protagonists together in the end . xxmaj in fact , all its charm is xxunk , contained within the characters and the setting and the plot … which is highly believable to xxunk . xxmaj it 's easy to think that such a love story , as beautiful as any other ever told , * could * happen to you … a feeling you do n't often get from other romantic comedies , however sweet and heart - warming they may be . \\n\\n xxmaj alfred xxmaj kralik ( james xxmaj stewart ) and xxmaj clara xxmaj xxunk ( margaret xxmaj xxunk ) do n't have the most xxunk of first xxunk when she arrives in the shop ( matuschek &amp; xxmaj co. ) he 's been working in for the past nine years , asking for a job . xxmaj they clash from the very beginning , mostly over a cigarette box that plays music when it 's opened -- he thinks it 's a ludicrous idea ; she makes one big sell of it and gets hired . xxmaj their bickering takes them through the next six months , even as they both ( xxunk , of course ! ) fall in love with each other when they share their souls and minds in letters passed through xxup xxunk xxmaj box xxunk . xxmaj this would be a pretty thin xxunk to base an entire film on , except that xxup the xxup shop xxup around xxup the xxup corner is xxunk xxunk - out with a brilliant supporting cast made up of entirely engaging characters , from the xxunk but lonely xxmaj hugo xxmaj matuschek ( frank xxmaj morgan ) himself , who learns that his shop really is his home ; xxmaj xxunk ( felix xxmaj xxunk ) , xxmaj kralik 's sidekick and friend who always xxunk out of the room when faced with the possibility of being asked for his honest opinion ; xxunk pimp - du - xxunk xxmaj xxunk ( joseph xxmaj xxunk ) who ultimately gets his comeuppance from a xxunk righteous xxmaj kralik ; and ambitious xxunk boy xxmaj xxunk xxmaj xxunk ( william xxmaj tracy ) who wants nothing more than to be promoted to the position of xxunk for xxmaj matuschek &amp; xxmaj co. xxmaj the xxunk love story between ' dear xxmaj friends ' is played out in this little shop in xxmaj budapest , xxmaj hungary , in which xxmaj kralik 's xxunk xxunk and subsequent xxunk to shop manager help the two xxunk - to - be along . xxmaj it 's nice that everyone gets a story in this film ; the supporting characters are well - developed , and xxmaj matuschek 's own journey in life is almost as touching as the one xxmaj alfred and xxmaj clara share . xxmaj his xxunk to new xxunk boy xxmaj xxunk ( charles xxmaj smith ) for xxmaj christmas xxmaj eve dinner , made in the xxunk , beautiful snow of a xxmaj hungarian winter , makes the audience glad that he is not alone ; we come to care even for the characters whose love story it is n't this film 's business to tell . \\n\\n xxmaj aside from the love story , i must say that xxmaj james xxmaj stewart is truly one of the best things about this film . xxmaj he does n't play the full - xxunk xxmaj jimmy xxmaj stewart persona in this film ( c / f ' mr xxmaj smith xxmaj goes xxmaj to xxmaj washington ' for that ) ; in fact xxmaj alfred xxmaj kralik is xxunk and abrupt and not particularly kind . xxmaj he 's rather a xxunk man , in fact , with little hint ( until , perhaps , the very end ) of the xxunk - xxunk down - home xxunk charm xxmaj stewart would soon come to xxunk . xxmaj when he finds out before xxmaj clara that they have been xxunk in secret , in fact , xxmaj kralik does n't ' xxunk up -- he xxunk it out to see how far he can take the xxunk , especially since he quickly realises ( given his stormy relationship with xxmaj clara as boss and xxunk ) that loving the person he knows through the xxunk letters might not xxunk with loving the person herself . xxmaj his description to xxmaj clara of the fictional xxmaj xxunk xxmaj xxunk ( what a name ! ) who was to become her xxunk is hilarious in the extreme , but also his way of proving that the letters do n't reveal all there is to a man , just as her letters do n't reveal all there is to her . xxmaj stewart plays this role perfectly -- he keeps his face perfectly controlled whenever xxmaj clara insults xxmaj mr . xxmaj kralik , as she is often wo nt to do , even ( and especially ) to his face . xxmaj and yet one believes , underneath the xxunk and xxunk , that he * could * reveal his identity with as much xxunk and xxunk and sheer * hope * as he eventually does . \\n\\n xxmaj special mention must be given to the other members of the cast as well . xxmaj margaret xxmaj xxunk xxunk rather less well in the first half of the film , but she really comes into her own in the closing - shop scene on xxmaj christmas xxmaj eve , when she almost gets her heart broken again by xxmaj alfred 's most vivid description of her xxunk xxunk . xxmaj frank xxmaj morgan turns in a great performance as the jealous xxmaj hugo xxmaj matuschek driven to nervous breakdown , the man who has to xxunk his meaning in life when he realises that his wife of 22 years does not want to ' grow old with him ' . xxmaj and xxmaj felix xxmaj xxunk plays the role of the meek but xxunk xxmaj xxunk wonderfully ( a xxmaj lubitsch regular , since he appears as a hilarious xxmaj russian xxunk in xxunk particular note is the scene in which he helps his good friend xxmaj alfred get the xxmaj christmas present the latter * really * wants … a wallet instead of that ludicrous cigarette box xxmaj clara is so hung up on . \\n\\n xxmaj xxunk xxmaj lubitsch really does himself proud with this film -- for example , the famously xxunk and xxunk care given to detail in the creation of the xxmaj matuschek shop is well worth the effort , right down to the xxmaj hungarian names on the door , the xxunk and the cash xxunk and so on . xxmaj but even though xxmaj lubitsch chose to have the story set in xxmaj hungary , the setting is actually universal : it could happen anywhere ; it could happen to you . xxmaj xxunk lies the charm of this simple story , these believable characters who really * are * people . xxmaj the snow on xxmaj christmas xxmaj eve is real as well , or at least as real as xxmaj lubitsch could make it ( he had snow machines brought in at great expense ) . xxmaj it is this desire to make everything appear as real as possible that helps make the story even more believable , that gives this entire film a dreamy realism that can not be xxunk . ( no , not even in a remake like xxup you 've xxup got xxup mail . ) \\n\\n * this * is really the xxmaj jimmy xxmaj stewart xxmaj christmas film that people are missing out on when they talk about xxup it 's a xxup wonderful xxup life . xxmaj not to xxunk from the merits of that other film , but there 'd be no harm , and in fact a lot of good , done in watching xxup the xxup shop xxup around xxup the xxup corner this xxmaj christmas instead . xxmaj it 's sweet , funny , charming , and xxmaj stewart is xxunk in his role . xxmaj we should all be so lucky as to have the romance depicted in this film ; the best thing about this film is that we come away from it feeling that we very possibly could .</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxbos xxmaj now that xxmaj che(2008 ) has finished its relatively short xxmaj australian cinema run ( extremely limited xxunk screen in xxmaj xxunk , after xxunk ) , i can xxunk join both xxunk of \" at xxmaj the xxmaj movies \" in taking xxmaj steven xxmaj soderbergh to task . \\n\\n xxmaj it 's usually satisfying to watch a film director change his style / subject , but xxmaj soderbergh 's most recent stinker , xxmaj the xxmaj girlfriend xxmaj xxunk ) , was also missing a story , so narrative ( and editing ? ) seem to suddenly be xxmaj soderbergh 's main challenge . xxmaj strange , after xxunk years in the business . xxmaj he was probably never much good at narrative , just xxunk it well inside \" edgy \" projects . \\n\\n xxmaj none of this excuses him this present , almost diabolical failure . xxmaj as xxmaj david xxmaj stratton xxunk , \" two parts of xxmaj che do n't ( even ) make a whole \" . \\n\\n xxmaj epic xxunk in name only , xxmaj che(2008 ) barely qualifies as a feature film ! xxmaj it certainly has no legs , xxunk as except for its xxunk ultimate resolution forced upon it by history , xxmaj soderbergh 's xxunk - long xxunk just goes nowhere . \\n\\n xxmaj even xxmaj margaret xxmaj xxunk , the more xxunk of xxmaj australia 's xxmaj at xxmaj the xxmaj movies duo , noted about xxmaj soderbergh 's xxunk waste of ( xxunk digital xxunk ) : \" you 're in the woods … you 're in the woods … you 're in the woods … \" . i too am surprised xxmaj soderbergh did n't give us another xxunk of xxup that somewhere between his xxunk two xxmaj parts , because he still left out massive xxunk of xxmaj che 's \" xxunk \" life ! \\n\\n xxmaj for a xxunk of an important but infamous historical figure , xxmaj soderbergh xxunk xxunk , if not deliberately insults , his audiences by \\n\\n 1 . never providing most of xxmaj che 's story ; \\n\\n 2 . xxunk xxunk film xxunk with mere xxunk xxunk ; \\n\\n 3 . xxunk both true hindsight and a narrative of events ; \\n\\n 4 . barely developing an idea , or a character ; \\n\\n 5 . remaining xxunk episodic ; \\n\\n 6 . xxunk proper context for scenes xxrep 3 - whatever we do get is xxunk in xxunk xxunk ; \\n\\n 7 . xxunk xxunk all audiences ( even xxmaj spanish - xxunk will be confused by the xxunk xxunk in xxmaj english ) ; and \\n\\n 8 . xxunk xxunk his main subject into one dimension . xxmaj why , at xxup this late stage ? xxmaj the xxmaj t - shirt franchise has been a success ! \\n\\n xxmaj our sense of xxunk is surely due to xxmaj peter xxmaj xxunk and xxmaj benjamin xxunk xxmaj xxunk xxunk their screenplay solely on xxmaj xxunk 's memoirs . xxmaj so , like a poor student who has read only xxup one of his xxunk xxunk for his xxunk , xxmaj soderbergh 's product is xxunk limited in perspective . \\n\\n xxmaj the audience is held captive within the same xxunk knowledge , scenery and circumstances of the \" revolutionaries \" , but that does n't xxunk our sympathy . xxmaj instead , it xxunk on us that \" ah , xxmaj soderbergh 's trying to xxunk his audiences the same as the xxmaj latino peasants were at the time \" . xxmaj but these are the xxup same illiterate xxmaj latino peasants who sold out the good doctor to his enemies . xxmaj why does xxmaj soderbergh feel the need to xxunk us with them , and keep us equally mentally captive ? xxmaj such audience xxunk must have a purpose . \\n\\n xxmaj part2 is more xxunk than xxmaj part1 , but it 's literally mind - numbing with its repetitive bush - bashing , misery of outlook , and lack of variety or character xxunk . deltoro 's xxmaj che has no opportunity to grow as a person while he struggles to xxunk his own ill - xxunk troops . xxmaj the only xxunk is the humour as xxmaj che deals with his sometimes deeply ignorant \" revolutionaries \" , some of whom xxunk lack self - control around local peasants or food . xxmaj we certainly get no insight into what caused the conditions , nor any xxunk xxunk of their xxunk xxunk , such as it was . \\n\\n xxmaj part2 's excruciating xxunk remains xxunk episodic : again , nothing is telegraphed or xxunk . xxmaj thus even the scenes with xxmaj xxunk xxmaj xxunk ( xxunk xxmaj xxunk ) are unexpected and disconcerting . xxmaj any xxunk events are portrayed xxunk and xxmaj latino - xxunk , with xxmaj part1 's interviews replaced by time - xxunk xxunk between the corrupt xxmaj xxunk president ( xxunk de xxmaj xxunk ) and xxup us xxmaj government xxunk promising xxup cia xxunk ( ! ) . \\n\\n xxmaj the rest of xxmaj part2 's \" woods \" and day - for - night blue xxunk just xxunk the audience until they 're xxunk the xxunk . \\n\\n xxmaj perhaps deltoro felt too xxunk the frustration of many non - american xxmaj latinos about never getting a truthful , xxunk history of xxmaj che 's exploits within their own countries . xxmaj when foreign xxunk still wo n't deliver a free press to their people -- for whatever reason -- then one can see how a popular xxmaj american indie producer might set out to entice the not - so - well - read ( \" i may not be able to read or write , but xxmaj i 'm xxup not xxunk xxmaj inspector xxmaj xxunk ) ) out to their own local cinemas . xxmaj the film 's obvious xxunk and gross over - xxunk hint very strongly that it 's aiming only at the xxunk of the less - informed xxup who xxup still xxup speak xxup little xxmaj english . xxmaj if they did , they 'd have read xxunk on the subject already , and xxunk the relevant social issues amongst themselves -- learning the lessons of history as they should . \\n\\n xxmaj such insights are precisely what societies still need -- and not just the remaining illiterate xxmaj latinos of xxmaj central and xxmaj south xxmaj america -- yet it 's what xxmaj che(2008 ) xxunk fails to deliver . xxmaj soderbergh xxunk his lead because he 's weak on narrative . i am xxunk why xxmaj xxunk deltoro deliberately chose xxmaj soderbergh for this project if he knew this . xxmaj it 's been xxunk , hindsight about xxmaj xxunk was xxunk wanted : it 's what i went to see this film for , but the director xxunk robs us of that . \\n\\n xxmaj david xxmaj stratton , writing in xxmaj the xxmaj australian ( xxunk ) observed that while xxmaj part1 was \" uneven \" , xxmaj part2 actually \" goes rapidly downhill \" from there , \" xxunk xxmaj che 's final campaign in xxmaj xxunk in excruciating detail \" , which \" … feels almost unbearably slow and turgid \" . \\n\\n che : the xxmaj xxunk aka xxmaj part2 is certainly no xxunk for xxmaj xxunk , painting it a picture of misery and xxunk . xxmaj the entire second half is only redeemed by the aforementioned humour , and the dramatic -- yet tragic -- capture and execution of the film 's subject . \\n\\n xxmaj the rest of this xxunk cinema xxunk is just confusing , irritating misery -- xxunk , for a xxmaj soderbergh film , to be avoided at all costs . xxmaj it is bound to break the hearts of all who know even just a xxunk about the xxunk / 10 )</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbch.show_batch(max_n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TransformBlock for text -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def TextBlock(vocab=None, is_lm=False):\n",
    "    return TransformBlock(type_tfms=Numericalize(vocab), dl_type=LMDataLoader if is_lm else SortedDL, \n",
    "                          dbunch_kwargs={} if is_lm else {'before_batch': pad_input})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core_foundation.ipynb.\n",
      "Converted 01a_core_utils.ipynb.\n",
      "Converted 01b_core_dispatch.ipynb.\n",
      "Converted 01c_core_transform.ipynb.\n",
      "Converted 02_core_script.ipynb.\n",
      "Converted 03_torchcore.ipynb.\n",
      "Converted 03a_layers.ipynb.\n",
      "Converted 04_data_load.ipynb.\n",
      "Converted 05_data_core.ipynb.\n",
      "Converted 06_data_transforms.ipynb.\n",
      "Converted 07_data_block.ipynb.\n",
      "Converted 08_vision_core.ipynb.\n",
      "Converted 09_vision_augment.ipynb.\n",
      "Converted 09a_vision_data.ipynb.\n",
      "Converted 09b_vision_utils.ipynb.\n",
      "Converted 10_pets_tutorial.ipynb.\n",
      "Converted 11_vision_models_xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_learner.ipynb.\n",
      "Converted 13a_metrics.ipynb.\n",
      "Converted 14_callback_schedule.ipynb.\n",
      "Converted 14a_callback_data.ipynb.\n",
      "Converted 15_callback_hook.ipynb.\n",
      "Converted 15a_vision_models_unet.ipynb.\n",
      "Converted 16_callback_progress.ipynb.\n",
      "Converted 17_callback_tracker.ipynb.\n",
      "Converted 18_callback_fp16.ipynb.\n",
      "Converted 19_callback_mixup.ipynb.\n",
      "Converted 20_interpret.ipynb.\n",
      "Converted 20a_distributed.ipynb.\n",
      "Converted 21_vision_learner.ipynb.\n",
      "Converted 22_tutorial_imagenette.ipynb.\n",
      "Converted 23_tutorial_transfer_learning.ipynb.\n",
      "Converted 30_text_core.ipynb.\n",
      "Converted 31_text_data.ipynb.\n",
      "Converted 32_text_models_awdlstm.ipynb.\n",
      "Converted 33_text_models_core.ipynb.\n",
      "Converted 34_callback_rnn.ipynb.\n",
      "Converted 35_tutorial_wikitext.ipynb.\n",
      "Converted 36_text_models_qrnn.ipynb.\n",
      "Converted 37_text_learner.ipynb.\n",
      "Converted 38_tutorial_ulmfit.ipynb.\n",
      "Converted 40_tabular_core.ipynb.\n",
      "Converted 41_tabular_model.ipynb.\n",
      "Converted 42_tabular_rapids.ipynb.\n",
      "Converted 50_data_block_examples.ipynb.\n",
      "Converted 60_medical_imaging.ipynb.\n",
      "Converted 65_medical_text.ipynb.\n",
      "Converted 70_callback_wandb.ipynb.\n",
      "Converted 71_callback_tensorboard.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_notebook_test.ipynb.\n",
      "Converted 95_index.ipynb.\n",
      "Converted 96_data_external.ipynb.\n",
      "Converted 97_utils_test.ipynb.\n",
      "Converted notebook2jekyll.ipynb.\n",
      "Converted xse_resnext.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
