{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp torch_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.test import *\n",
    "from local.imports import *\n",
    "from local.torch_imports import *\n",
    "from local.core import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "if torch.cuda.is_available(): torch.cuda.set_device(int(os.environ.get('DEFAULT_GPU') or 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Core\n",
    "\n",
    "> Basic pytorch functions used in the fastai library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def __array_eq__(self:Tensor,b):\n",
    "    return torch.equal(self,b) if self.dim() else self==b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def tensor(x, *rest, **kwargs):\n",
    "    \"Like `torch.as_tensor`, but handle lists too, and can pass multiple vector elements directly.\"\n",
    "    if len(rest): x = (x,)+rest\n",
    "    # Pytorch bug in dataloader using num_workers>0\n",
    "    if isinstance(x, (tuple,list)) and len(x)==0: return tensor(0)\n",
    "    res = (torch.tensor(x, **kwargs) if isinstance(x, (tuple,list))\n",
    "           else as_tensor(x, **kwargs) if hasattr(x, '__array__')\n",
    "           else as_tensor(x, **kwargs) if is_listy(x)\n",
    "           else as_tensor(x, **kwargs) if is_iter(x)\n",
    "           else None)\n",
    "    if res is None:\n",
    "        res = as_tensor(array(x), **kwargs)\n",
    "        if res.dtype is torch.float64: return res.float()\n",
    "    if res.dtype is torch.int32:\n",
    "        warn('Tensor is int32: upgrading to int64; for better performance use int64 input')\n",
    "        return res.long()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tensor(array([1,2,3])), torch.tensor([1,2,3]))\n",
    "test_eq(tensor(1,2,3), torch.tensor([1,2,3]))\n",
    "test_eq_type(tensor(1.0), torch.tensor(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def set_seed(s):\n",
    "    \"Set random seed for `random`, `torch`, and `numpy` (where available)\"\n",
    "    try: torch.manual_seed(s)\n",
    "    except NameError: pass\n",
    "    try: np.random.seed(s%(2**32-1))\n",
    "    except NameError: pass\n",
    "    random.seed(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(2*33)\n",
    "a1 = np.random.random()\n",
    "a2 = torch.rand(())\n",
    "a3 = random.random()\n",
    "set_seed(2*33)\n",
    "b1 = np.random.random()\n",
    "b2 = torch.rand(())\n",
    "b3 = random.random()\n",
    "test_eq(a1,b1)\n",
    "test_eq(a2,b2)\n",
    "test_eq(a3,b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _fa_rebuild_tensor (cls, *args, **kwargs): return cls(torch._utils._rebuild_tensor_v2(*args, **kwargs))\n",
    "def _fa_rebuild_qtensor(cls, *args, **kwargs): return cls(torch._utils._rebuild_qtensor  (*args, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TensorBase(Tensor, metaclass=BypassNewMeta):\n",
    "    def _new_meta(self, *args, **kwargs): return tensor(self)\n",
    "\n",
    "    def __reduce_ex__(self,proto):\n",
    "        torch.utils.hooks.warn_if_has_hooks(self)\n",
    "        args = (type(self), self.storage(), self.storage_offset(), tuple(self.size()), self.stride())\n",
    "        if self.is_quantized: args = args + (self.q_scale(), self.q_zero_point())\n",
    "        f = _fa_rebuild_qtensor if self.is_quantized else  _fa_rebuild_tensor\n",
    "        return (f, args + (self.requires_grad, OrderedDict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _patch_tb():\n",
    "    def get_f(fn):\n",
    "        def _f(self, *args, **kwargs):\n",
    "            cls = self.__class__\n",
    "            res = getattr(super(TensorBase, self), fn)(*args, **kwargs)\n",
    "            return cls(res) if isinstance(res,Tensor) else res\n",
    "        return _f\n",
    "\n",
    "    t = tensor([1])\n",
    "    skips = '__class__ __deepcopy__ __delattr__ __dir__ __doc__ __getattribute__ __hash__ __init__ \\\n",
    "        __init_subclass__ __new__ __reduce__ __reduce_ex__ __module__ __setstate__'.split()\n",
    "\n",
    "    for fn in dir(t):\n",
    "        if fn in skips: continue\n",
    "        f = getattr(t, fn)\n",
    "        if isinstance(f, (MethodWrapperType, BuiltinFunctionType, BuiltinMethodType, MethodType, FunctionType)):\n",
    "            setattr(TensorBase, fn, get_f(fn))\n",
    "\n",
    "_patch_tb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _T(TensorBase): pass\n",
    "\n",
    "t = _T(range(5))\n",
    "test_eq_type(t[0], _T(0))\n",
    "test_eq_type(t[:2], _T([0,1]))\n",
    "test_eq_type(t+1, _T(range(1,6)))\n",
    "\n",
    "test_eq(type(pickle.loads(pickle.dumps(t))), _T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def tensored(self:L):\n",
    "    \"`mapped(tensor)`\"\n",
    "    return self.mapped(tensor)\n",
    "@patch\n",
    "def stack(self:L, dim=0):\n",
    "    \"Same as `torch.stack`\"\n",
    "    return torch.stack(list(self.tensored()), dim=dim)\n",
    "@patch\n",
    "def cat  (self:L, dim=0):\n",
    "    \"Same as `torch.cat`\"\n",
    "    return torch.cat  (list(self.tensored()), dim=dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.tensored\" class=\"doc_header\"><code>L.tensored</code><a href=\"https://github.com/fastai/fastai_dev/tree/master/dev/__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>L.tensored</code>()\n",
       "\n",
       "`mapped(tensor)`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.tensored)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are shortcuts for `torch.stack` and `torch.cat` if your `L` contains tensors or something convertible. You can manually convert with `tensored`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = L(([1,2],[3,4]))\n",
    "test_eq(t.tensored(), [tensor(1,2),tensor(3,4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.stack\" class=\"doc_header\"><code>L.stack</code><a href=\"https://github.com/fastai/fastai_dev/tree/master/dev/__main__.py#L6\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>L.stack</code>(**`dim`**=*`0`*)\n",
       "\n",
       "Same as `torch.stack`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(t.stack(), tensor([[1,2],[3,4]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"L.cat\" class=\"doc_header\"><code>L.cat</code><a href=\"https://github.com/fastai/fastai_dev/tree/master/dev/__main__.py#L10\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>L.cat</code>(**`dim`**=*`0`*)\n",
       "\n",
       "Same as `torch.cat`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(L.cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(t.cat(), tensor([1,2,3,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def concat(*ls):\n",
    "    \"Concatenate tensors, arrays, lists, or tuples\"\n",
    "    if not len(ls): return []\n",
    "    it = ls[0]\n",
    "    if isinstance(it,torch.Tensor): res = torch.cat(ls)\n",
    "    elif isinstance(it,ndarray): res = np.concatenate(ls)\n",
    "    else:\n",
    "        res = [o for x in ls for o in L(x)]\n",
    "        if isinstance(it,(tuple,list)): res = type(it)(res)\n",
    "        else: res = L(res)\n",
    "    return retain_type(res, it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c = [1],[1,2],[1,1,2]\n",
    "test_eq(concat(a,b), c)\n",
    "test_eq_type(concat(tuple (a),tuple (b)), tuple (c))\n",
    "test_eq_type(concat(array (a),array (b)), array (c))\n",
    "test_eq_type(concat(tensor(a),tensor(b)), tensor(c))\n",
    "test_eq_type(concat(TensorBase(a),TensorBase(b)), TensorBase(c))\n",
    "test_eq_type(concat([1,1],1), [1,1,1])\n",
    "test_eq_type(concat(1,1,1), L(1,1,1))\n",
    "test_eq_type(concat(L(1,2),1), L(1,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Chunks:\n",
    "    \"Slice and int indexing into a list of lists\"\n",
    "    def __init__(self, chunks, lens=None):\n",
    "        self.chunks = chunks\n",
    "        self.lens = L(map(len,self.chunks) if lens is None else lens)\n",
    "        self.cumlens = np.cumsum(0+self.lens)\n",
    "        self.totlen = self.cumlens[-1]\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        if isinstance(i,slice): return self.getslice(i)\n",
    "        di,idx = self.doc_idx(i)\n",
    "        return self.chunks[di][idx]\n",
    "\n",
    "    def getslice(self, i):\n",
    "        st_d,st_i = self.doc_idx(ifnone(i.start,0))\n",
    "        en_d,en_i = self.doc_idx(ifnone(i.stop,self.totlen+1))\n",
    "        res = [self.chunks[st_d][st_i:(en_i if st_d==en_d else sys.maxsize)]]\n",
    "        for b in range(st_d+1,en_d): res.append(self.chunks[b])\n",
    "        if st_d!=en_d and en_d<len(self.chunks): res.append(self.chunks[en_d][:en_i])\n",
    "        return concat(*res)\n",
    "\n",
    "    def doc_idx(self, i):\n",
    "        if i<0: i=self.totlen+i # count from end\n",
    "        docidx = np.searchsorted(self.cumlens, i+1)-1\n",
    "        cl = self.cumlens[docidx]\n",
    "        return docidx,i-cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = L(list(string.ascii_lowercase[a:b]) for a,b in ((0,3),(3,7),(7,8),(8,16),(16,24),(24,26)))\n",
    "\n",
    "b = Chunks(docs)\n",
    "test_eq([b[ o] for o in range(0,5)], ['a','b','c','d','e'])\n",
    "test_eq([b[-o] for o in range(1,6)], ['z','y','x','w','v'])\n",
    "test_eq(b[6:13], 'g,h,i,j,k,l,m'.split(','))\n",
    "test_eq(b[20:77], 'u,v,w,x,y,z'.split(','))\n",
    "test_eq(b[:5], 'a,b,c,d,e'.split(','))\n",
    "test_eq(b[:2], 'a,b'.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.arange(26)\n",
    "docs = L(t[a:b] for a,b in ((0,3),(3,7),(7,8),(8,16),(16,24),(24,26)))\n",
    "b = Chunks(docs)\n",
    "test_eq([b[ o] for o in range(0,5)], range(0,5))\n",
    "test_eq([b[-o] for o in range(1,6)], [25,24,23,22,21])\n",
    "test_eq(b[6:13], torch.arange(6,13))\n",
    "test_eq(b[20:77], torch.arange(20,26))\n",
    "test_eq(b[:5], torch.arange(5))\n",
    "test_eq(b[:2], torch.arange(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = L(TensorBase(t[a:b]) for a,b in ((0,3),(3,7),(7,8),(8,16),(16,24),(24,26)))\n",
    "b = Chunks(docs)\n",
    "test_eq_type(b[:2], TensorBase(range(2)))\n",
    "test_eq_type(b[:5], TensorBase(range(5)))\n",
    "test_eq_type(b[9:13], TensorBase(range(9,13)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def apply(func, x, *args, **kwargs):\n",
    "    \"Apply `func` recursively to `x`, passing on args\"\n",
    "    if is_listy(x): return type(x)([apply(func, o, *args, **kwargs) for o in x])\n",
    "    if isinstance(x,dict):  return {k: apply(func, v, *args, **kwargs) for k,v in x.items()}\n",
    "    res = func(x, *args, **kwargs)\n",
    "    return res if x is None else retain_type(res, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def to_detach(b, cpu=True):\n",
    "    \"Recursively detach lists of tensors in `b `; put them on the CPU if `cpu=True`.\"\n",
    "    def _inner(x, cpu=True):\n",
    "        if not isinstance(x,Tensor): return x\n",
    "        x = x.detach()\n",
    "        return x.cpu() if cpu else x\n",
    "    return apply(_inner, b, cpu=cpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def to_half(b):\n",
    "    \"Recursively map lists of tensors in `b ` to FP16.\"\n",
    "    return apply(lambda x: x.half() if torch.is_floating_point(x) else x, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def to_float(b):\n",
    "    \"Recursively map lists of int tensors in `b ` to float.\"\n",
    "    return apply(lambda x: x.float() if torch.is_floating_point(x) else x, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# None: True if available; True: error if not availabe; False: use CPU\n",
    "defaults.use_cuda = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def default_device(use_cuda=-1):\n",
    "    \"Return or set default device; `use_cuda`: None - CUDA if available; True - error if not availabe; False - CPU\"\n",
    "    if use_cuda != -1: defaults.use_cuda=use_cuda\n",
    "    use = defaults.use_cuda or (torch.cuda.is_available() and defaults.use_cuda is None)\n",
    "    assert torch.cuda.is_available() or not use\n",
    "    return torch.device(torch.cuda.current_device()) if use else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cuda\n",
    "_td = torch.device(torch.cuda.current_device())\n",
    "test_eq(default_device(None), _td)\n",
    "test_eq(default_device(True), _td)\n",
    "test_eq(default_device(False), torch.device('cpu'))\n",
    "default_device(None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def to_device(b, device=None):\n",
    "    \"Recursively put `b` on `device`.\"\n",
    "    if device is None: device=default_device()\n",
    "    def _inner(o): return o.to(device, non_blocking=True) if isinstance(o,Tensor) else o\n",
    "    return apply(_inner, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = to_device((3,(tensor(3),tensor(2))))\n",
    "t1,(t2,t3) = t\n",
    "test_eq_type(t,(3,(tensor(3).cuda(),tensor(2).cuda())))\n",
    "test_eq(t2.type(), \"torch.cuda.LongTensor\")\n",
    "test_eq(t3.type(), \"torch.cuda.LongTensor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def to_cpu(b):\n",
    "    \"Recursively map lists of tensors in `b ` to the cpu.\"\n",
    "    return to_device(b,'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = to_cpu(t3)\n",
    "test_eq(t3.type(), \"torch.LongTensor\")\n",
    "test_eq(t3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #export\n",
    "# def to_np(x):\n",
    "#     \"Convert a tensor to a numpy array.\"\n",
    "#     return apply(Self.detach().cpu().numpy(), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def to_np(x):\n",
    "    \"Convert a tensor to a numpy array.\"\n",
    "    return apply(lambda o: o.data.cpu().numpy(), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = to_np(t3)\n",
    "test_eq(type(t3), np.ndarray)\n",
    "test_eq(t3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def item_find(x, idx=0):\n",
    "    \"Recursively takes the `idx`-th element of `x`\"\n",
    "    if is_listy(x): return item_find(x[idx])\n",
    "    if isinstance(x,dict):\n",
    "        key = list(x.keys())[idx] if isinstance(idx, int) else idx\n",
    "        return item_find(x[key])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def find_device(b):\n",
    "    \"Recursively search the device of `b`.\"\n",
    "    return item_find(b).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = default_device()\n",
    "test_eq(find_device(t2), dev)\n",
    "test_eq(find_device([t2,t2]), dev)\n",
    "test_eq(find_device({'a':t2,'b':t2}), dev)\n",
    "test_eq(find_device({'a':[[t2],[t2]],'b':t2}), dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def find_bs(b):\n",
    "    \"Recursively search the batch size of `b`.\"\n",
    "    return item_find(b).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4,5)\n",
    "test_eq(find_bs(x), 4)\n",
    "test_eq(find_bs([x, x]), 4)\n",
    "test_eq(find_bs({'a':x,'b':x}), 4)\n",
    "test_eq(find_bs({'a':[[x],[x]],'b':x}), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_func(f):\n",
    "    \"Convert a function taking and returning numpy arrays to one taking and returning tensors\"\n",
    "    def _inner(*args, **kwargs):\n",
    "        nargs = [to_np(arg) if isinstance(arg,Tensor) else arg for arg in args]\n",
    "        return tensor(f(*nargs, **kwargs))\n",
    "    functools.update_wrapper(_inner, f)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This decorator is particularly useful for using numpy functions as fastai metrics, for instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "@np_func\n",
    "def f1(inp,targ): return f1_score(targ, inp)\n",
    "\n",
    "a1,a2 = array([0,1,1]),array([1,0,1])\n",
    "t = f1(tensor(a1),tensor(a2))\n",
    "test_eq(f1_score(a1,a2), t)\n",
    "assert isinstance(t,Tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Module(nn.Module, metaclass=PrePostInitMeta):\n",
    "    \"Same as `nn.Module`, but no need for subclasses to call `super().__init__`\"\n",
    "    def __pre_init__(self): super().__init__()\n",
    "    def __init__(self): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"Module\" class=\"doc_header\"><code>class</code> <code>Module</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>Module</code>() :: [`Module`](/layers.html#Module)\n",
       "\n",
       "Same as `nn.Module`, but no need for subclasses to call `super().__init__`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Module, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0893], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class _T(Module):\n",
    "    def __init__(self): self.f = nn.Linear(1,1)\n",
    "    def forward(self,x): return self.f(x)\n",
    "\n",
    "t = _T()\n",
    "t(tensor([1.]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def one_hot(x, c):\n",
    "    \"One-hot encode `x` with `c` classes.\"\n",
    "    res = torch.zeros(c, dtype=torch.uint8)\n",
    "    res[L(x)] = 1.\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(one_hot([1,4], 5), tensor(0,1,0,0,1).byte())\n",
    "test_eq(one_hot([], 5), tensor(0,0,0,0,0).byte())\n",
    "test_eq(one_hot(2, 5), tensor(0,0,1,0,0).byte())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def one_hot_decode(x, vocab=None):\n",
    "    return L(vocab[i] if vocab else i for i,x_ in enumerate(x) if x_==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(one_hot_decode(tensor(0,1,0,0,1)), [1,4])\n",
    "test_eq(one_hot_decode(tensor(0,0,0,0,0)), [   ])\n",
    "test_eq(one_hot_decode(tensor(0,0,1,0,0)), [2  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def trainable_params(m):\n",
    "    \"Return all trainable parameters of `m`\"\n",
    "    return [p for p in m.parameters() if p.requires_grad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn.Linear(4,5)\n",
    "test_eq(trainable_params(m), [m.weight, m.bias])\n",
    "m.weight.requires_grad_(False)\n",
    "test_eq(trainable_params(m), [m.bias])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def bn_bias_params(m, with_bias=True):\n",
    "    \"Return all bias and BatchNorm parameters\"\n",
    "    if isinstance(m, (nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d)): return list(m.parameters())\n",
    "    res = sum([bn_bias_params(c, with_bias) for c in m.children()], [])\n",
    "    if with_bias and hasattr(m, 'bias'): res.append(m.bias)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(10,20), nn.BatchNorm1d(20), nn.Conv1d(3,4, 3))\n",
    "test_eq(bn_bias_params(model), [model[0].bias, model[1].weight, model[1].bias, model[2].bias])\n",
    "model = nn.ModuleList([nn.Linear(10,20), nn.Sequential(nn.BatchNorm1d(20), nn.Conv1d(3,4, 3))])\n",
    "test_eq(bn_bias_params(model), [model[0].bias, model[1][0].weight, model[1][0].bias, model[1][1].bias])\n",
    "model = nn.ModuleList([nn.Linear(10,20), nn.Sequential(nn.BatchNorm1d(20), nn.Conv1d(3,4, 3))])\n",
    "test_eq(bn_bias_params(model, with_bias=False), [model[1][0].weight, model[1][0].bias])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_cross_image(bw=True):\n",
    "    \"Create a tensor containing a cross image, either `bw` (True) or color\"\n",
    "    if bw:\n",
    "        im = torch.zeros(5,5)\n",
    "        im[2,:] = 1.\n",
    "        im[:,2] = 1.\n",
    "    else:\n",
    "        im = torch.zeros(3,5,5)\n",
    "        im[0,2,:] = 1.\n",
    "        im[1,:,2] = 1.\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(make_cross_image(), cmap=\"Greys\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(make_cross_image(False).permute(1,2,0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_title(o, ax=None, ctx=None, label=None, **kwargs):\n",
    "    \"Set title of `ax` to `o`, or print `o` if `ax` is `None`\"\n",
    "    ax = ifnone(ax,ctx)\n",
    "    if ax is None: print(o)\n",
    "    elif hasattr(ax, 'set_title'): ax.set_title(o)\n",
    "    elif isinstance(ax, pd.Series):\n",
    "        while label in ax: label += '_'\n",
    "        ax = ax.append(pd.Series({label: o}))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stdout(lambda: show_title(\"title\"), \"title\")\n",
    "# ensure that col names are unique when showing to a pandas series\n",
    "assert show_title(\"title\", ctx=pd.Series(dict(a=1)), label='a').equals(pd.Series(dict(a=1,a_='title')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_image(im, ax=None, figsize=None, title=None, ctx=None, **kwargs):\n",
    "    \"Show a PIL or PyTorch image on `ax`.\"\n",
    "    ax = ifnone(ax,ctx)\n",
    "    if ax is None: _,ax = plt.subplots(figsize=figsize)\n",
    "    # Handle pytorch axis order\n",
    "    if isinstance(im,Tensor):\n",
    "        im = to_cpu(im)\n",
    "        if im.shape[0]<5: im=im.permute(1,2,0)\n",
    "    elif not isinstance(im,np.ndarray): im=array(im)\n",
    "    # Handle 1-channel images\n",
    "    if im.shape[-1]==1: im=im[...,0]\n",
    "    ax.imshow(im, **kwargs)\n",
    "    if title is not None: ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`show_image` can show b&w images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAB7CAYAAABUx/9/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAABZUlEQVR4nO3dSQrDMBAAwSjk/19WXpDxJQtKV10NxqjRQWBGa+99o+H+6w/ge8QOETtE7BCxQ8QOeVw8P+pcttZ6+zsPPJq+XAQ7O0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxtmln5gFeprT1mCatWpnh4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CHjD4enXRTusvSZnR0idojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIWKHiB0idojYIeufZnMys7NDxA4RO0TsELFDxA55Ao0DE/UW4fj8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im = make_cross_image()\n",
    "ax = show_image(im, cmap=\"Greys\", figsize=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and color images with standard `c*h*w` dim order..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAB7CAYAAABUx/9/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAABYUlEQVR4nO3dQQrCMBBAUSPe/8rjCYwbUyn/vW2hDHxmUSjJmpkHDc9/D8B1xA4RO0TsELFDxA557R6ute71XXZi2nXgnQfNzMeJbXaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih2zPLr3XwaV8Y7NDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TskP1l6VdNwc/sfhK12SFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdsmZciV5hs0PEDhE7ROwQsUPEDnkD1tcN9ECq4WMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im2 = make_cross_image(False)\n",
    "ax = show_image(im2, figsize=(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and color images with `h*w*c` dim order..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAAB7CAYAAABUx/9/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAABYUlEQVR4nO3dQQrCMBBAUSPe/8rjCYwbUyn/vW2hDHxmUSjJmpkHDc9/D8B1xA4RO0TsELFDxA557R6ute71XXZi2nXgnQfNzMeJbXaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih2zPLr3XwaV8Y7NDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TsELFDxA4RO0TskP1l6VdNwc/sfhK12SFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdInaI2CFih4gdsmZciV5hs0PEDhE7ROwQsUPEDnkD1tcN9ECq4WMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "im3 = im2.permute(1,2,0)\n",
    "ax = show_image(im3, figsize=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fefbc2d6be0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHsAAACLCAYAAABBVeZmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAADqUlEQVR4nO3dvUtVcRzH8fe3B3RrqIgMNFqChmgJLFzCxsgWl6KmxobSoSCVagiiRYL6C6QaggqKwFVCqP6AggqlsuhBKi0Lq2/DOUNI3sD03k6fzwvOcO/5ncs9932eLsq5kZmYhmWNfgNWP44txLGFOLYQxxbi2EIcW0ilY0fE/oh4EBHTEfEyIu5EREej39e/qrKxI6IHGATOAuuAVuAS0PWbsSvq++7+UZlZuQlYBUwD3fPMPwVcA4aAj8BhoIli45gop0GgqRy/BrgFvAcmgRFgWTnvOPACmAIeAZ2NXv+FTlXd4ncAzcD1GmO6gG7gEEXok0A7sA1I4CbQB/QDvcBzYG25bDuQEbEZOAJsz8yJiNgILF/kdambqh7GVwNvM/NbjTGjmXkjM39k5gxwADiTma8z8w1wGjhYjp0F1gNtmTmbmSNZ7NbfKTaULRGxMjPHMvPJ0q3W0qpq7HfAmj+ci5/NedwCjP/yeLx8DuA88BgYjoinEXECIDMfA0cpTguvI+JqRLRQUVWNPQp8BfbVGDP3z3kTQNsvj1vL58jMqczszcxNwF6gJyI6y3mXM7OjXDaBc4uzCvVXyXN2Zn6IiAHgYkR8A4YpDsW7gV3A598sdgXoi4j7FNEGKC7giIg9wEPgCfCB4vD9ozxnbwDuAl+AGSp8zm74FeJfXpUfAB4An4BXwG1gJ8Vhd2jO2GbgAvCynC4AzeW8Y8BY+TrPgf7y+a3APYor8UmKK/aWRq/3QqcoV8oEVPWcbQvg2EIcW4hjC3FsIX/6nl2pS/WIWPTXrOC3lXk/BO/ZQhxbiGMLcWwhji3EsYU4thDHFuLYQhxbiGMLcWwhji3EsYU4thDHFuLYQhxbiGMLcWwhji3EsYU4thDHFuLYQhxbiGMLcWwhji3EsYU4thDHFuLYQhxbiGMLcWwhji3EsYU4thDHFuLYQhxbiGMLqXnv0qW4F2jVVO0zqHWvVe/ZQhxbiGMLcWwhji3EsYU4thDHFuLYQhxbiGMLcWwhji3EsYU4thDHFuLYQhxbiGMLcWwhNf/hsGo/FO4fS6/Ne7YQxxbi2EIcW4hjC3FsIY4txLGFOLYQxxbi2EIcW4hjC3FsIY4txLGFOLYQxxbi2EIcW4hjC3FsIY4txLGFOLYQxxbi2EIcW4hjC3FsIY4txLGFOLYQxxbi2EIcW4hjC3FsIY4txLGFOLYQxxbi2ELif7o3p9XmPVuIYwtxbCGOLcSxhTi2kJ/uJf8plvGvcAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = show_image(im, cmap=\"Greys\", figsize=(2,2))\n",
    "show_title(\"Cross\", ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_titled_image(o, **kwargs):\n",
    "    \"Call `show_image` destructuring `o` to `(img,title)`\"\n",
    "    show_image(o[0], title=str(o[1]), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def show_image_batch(b, show=show_titled_image, items=9, cols=3, figsize=None, **kwargs):\n",
    "    \"Display batch `b` in a grid of size `items` with `cols` width\"\n",
    "    rows = (items+cols-1) // cols\n",
    "    if figsize is None: figsize = (cols*3, rows*3)\n",
    "    fig,axs = plt.subplots(rows, cols, figsize=figsize)\n",
    "    for *o,ax in zip(*to_cpu(b), axs.flatten()): show(o, ax=ax, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgQAAACyCAYAAAA9DtfXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAGKUlEQVR4nO3dT8hlZR3A8e/PDIqyhQjV1GiR2i6G7B8IWlRYRBGERQTholYFQdSqFi2KQlqFu4qohSRCBLUxN06WhVLYH4swq2liksoiRIsonxb32gyS+k7ovU7z+WzmnHvmcp4z78Mz33vmvO/MWisA4Ox2zr4HAADsnyAAAAQBACAIAIAEAQCQIAAAEgQHMjO/mZk37Hsc8ESYmWtm5jv7HgcchPV3dwQBACAIAABBcDpeOTM/m5m/zMyXZuYZM3N0Zt5RNTOXz8yambds918/M3fud8ic7Wbm8Mx8bWb+ODP3zcx1pxz77HY+/3pm3rx97XUz85NTfs/NM3PHKfu3zszbd3sV0JGZ+fHM/HVmbjjd9Xdm3j8zP5+Z+7fr+Mv3dSFPZYLg4N5TXVW9pLq0+nh1tHrt9viV1a+qK07ZP7rbIcJJM/O06pvVsepF1Quqr24Pv7r6RXVBdW31xZmZ6vvVJTNzwcw8vXpZdWhmzpuZZ1avqG7d6YVAvbN6U/XiNnPymg64/s7M1dUnqvdWz6neVt23k1GfYQTBwV231jq+1vpz9anq3W0m3JXb41dUnz5lXxCwb6+qDlUfXWs9sNb6+1rr4YcJj621Pr/W+lf15er51XPXWn+r7mgzny+rflR9t7q8ek1191rLYsqufW6tdWK7/n6jOtLB19/3Vdeute5YG79cax3b4djPGILg4I6fsn2szUL7verSmXlumwn6lerwzFzQZjH+9s5HCScdbvMX/z//y7F7H95Yaz243Xz29teHP3ldsd2+pc0CK3LZl3tP2X6wzVw96Pp7uLpnh2M9YwmCgzt8yvaF1YntQvqD6kPVT9da/6huqz5c3bPW+tPuhwn/cby6cGbOPc33PTIIHv4kJgh4yjiN9fd4m3/q5XEIgoP7wMy8cGbOrz5W3bB9/Wj1wU4ulLc8Yh/25fbq99VnZuZZ2wexLj/A+26rXtrmU9bta627qovaPHfgrhdPJQdZf79QfWRmLpuNi2fmot0O88wgCA7u+upbbR5cuaf65Pb1o9V5nVwoH7kPe7F9PuCt1cXVb6vfVe86wPseqH5Y3bX91FWb27PH1lp/eJKGC/+Lx11/11o3tnnu6/rq/urr1fm7HeaZYdZa+x4DALBn7hAAAIIAABAEAECCAABIEAAA1WP+wJI3nnP1WfMtCDed2M//Q3TVoSN7Oe8+3PzQjbPrc87MWTOH29eV7vyruj9rrb1crXm8A+axOwQAgCAAABIEAECCAABIEAAACQIAIEEAACQIAIAEAQCQIAAAEgQAQIIAAEgQAAAJAgAgQQAAJAgAgAQBAJAgAAASBABAggAASBAAAAkCACBBAAAkCACABAEAkCAAABIEAECCAABIEAAACQIAIEEAACQIAIAEAQCQIAAAEgQAQIIAAEgQAAAJAgAgQQAAJAgAgAQBAJAgAAASBABAggAASBAAAAkCACBBAAAkCACABAEAkCAAABIEAECCAABIEAAACQIAIEEAACQIAIAEAQCQIAAAqllrPerBh+695NEPwmk653l3z85POnP2zOF9Xenuv6r7s9Z+rtY8fvKZx+4QAACCAABIEAAACQIAIEEAACQIAIAEAQCQIAAAEgQAQIIAAEgQAAAJAgAgQQAAJAgAgAQBAJAgAAASBABAggAASBAAAAkCACBBAAAkCACABAEAkCAAABIEAECCAABIEAAACQIAIEEAAFTnPtbBqw4d2dU49u6mE3fu5bxn05/xzQ/t/pyz+1Pyf2zt6bzmMU+kR5vH7hAAAIIAABAEAECCAABIEAAACQIAIEEAACQIAIAEAQCQIAAAEgQAQIIAAEgQAAAJAgAgQQAAJAgAgAQBAJAgAAASBABAggAASBAAAAkCACBBAAAkCACABAEAkCAAABIEAECCAABIEAAACQIAIEEAACQIAIAEAQCQIAAAEgQAQIIAAEgQAAAJAgAgQQAAJAgAgAQBAJAgAAASBABAggAASBAAAAkCACBBAAAkCACABAEAkCAAABIEAECCAABIEAAACQIAIEEAACQIAIAEAQCQIAAAqllr7XsMAMCeuUMAAAgCAEAQAAAJAgAgQQAAJAgAgOrf334nDSK8atkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 648x216 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image_batch(([im,im2,im3],['bw','chw','hwc']), items=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 01a_torch_core.ipynb.\n",
      "Converted 01b_script.ipynb.\n",
      "Converted 01c_dataloader.ipynb.\n",
      "Converted 02_data_transforms.ipynb.\n",
      "Converted 03_data_pipeline.ipynb.\n",
      "Converted 05_data_core.ipynb.\n",
      "Converted 06_data_source.ipynb.\n",
      "Converted 07_vision_core.ipynb.\n",
      "Converted 08_pets_tutorial.ipynb.\n",
      "Converted 09_vision_augment.ipynb.\n",
      "Converted 11_layers.ipynb.\n",
      "Converted 11a_vision_models_xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_learner.ipynb.\n",
      "Converted 14_callback_schedule.ipynb.\n",
      "Converted 15_callback_hook.ipynb.\n",
      "Converted 16_callback_progress.ipynb.\n",
      "Converted 17_callback_tracker.ipynb.\n",
      "Converted 18_callback_fp16.ipynb.\n",
      "Converted 19_callback_mixup.ipynb.\n",
      "Converted 20_metrics.ipynb.\n",
      "Converted 21_tutorial_imagenette.ipynb.\n",
      "Converted 30_text_core.ipynb.\n",
      "Converted 31_text_data.ipynb.\n",
      "Converted 32_text_models_awdlstm.ipynb.\n",
      "Converted 33_text_models_core.ipynb.\n",
      "Converted 34_callback_rnn.ipynb.\n",
      "Converted 35_tutorial_wikitext.ipynb.\n",
      "Converted 36_text_models_qrnn.ipynb.\n",
      "Converted 40_tabular_core.ipynb.\n",
      "Converted 41_tabular_model.ipynb.\n",
      "Converted 50_data_block.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n",
      "Converted 95_utils_test.ipynb.\n",
      "Converted 96_data_external.ipynb.\n",
      "Converted notebook2jekyll.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
