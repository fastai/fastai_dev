{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.torch_basics import *\n",
    "from local.test import *\n",
    "from local.data.load import *\n",
    "from local.data.transform import *\n",
    "from local.data.pipeline import *\n",
    "from local.data.external import *\n",
    "from local.notebook.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for processing data\n",
    "\n",
    "> Functions for getting, splitting, and labeling data, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get, split, and label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most data source creation we need functions to get a list of items, split them in to train/valid sets, and label them. fastai provides functions to make each of these steps easy (especially when combined with `fastai.data.blocks`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll look at functions that *get* a list of items (generally file names).\n",
    "\n",
    "We'll use *tiny MNIST* (a subset of MNIST with just two classes, `7`s and `3`s) for our examples/tests throughout this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [/home/condor/fastai_dev_my/dev/data/mnist_tiny/train/7,/home/condor/fastai_dev_my/dev/data/mnist_tiny/train/3]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_files(p, fs, extensions=None):\n",
    "    p = Path(p)\n",
    "    res = [p/f for f in fs if not f.startswith('.')\n",
    "           and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_files(path, extensions=None, recurse=True, include=None):\n",
    "    \"Get all the files in `path` with optional `extensions`, optionally with `recurse`.\"\n",
    "    path = Path(path)\n",
    "    extensions = setify(extensions)\n",
    "    extensions = {e.lower() for e in extensions}\n",
    "    if recurse:\n",
    "        res = []\n",
    "        for i,(p,d,f) in enumerate(os.walk(path)): # returns (dirpath, dirnames, filenames)\n",
    "            if include is not None and i==0: d[:] = [o for o in d if o in include]\n",
    "            else:                            d[:] = [o for o in d if not o.startswith('.')]\n",
    "            res += _get_files(p, f, extensions)\n",
    "    else:\n",
    "        f = [o.name for o in os.scandir(path) if o.is_file()]\n",
    "        res = _get_files(path, f, extensions)\n",
    "    return L(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most general way to grab a bunch of file names from disk. If you pass `extensions` (including the `.`) then returned file names are filtered by that list. Only those files directly in `path` are included, unless you pass `recurse`, in which case all child folders are also searched recursively. `include` is an optional list of directories to limit the search to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#709) [/home/condor/fastai_dev_my/dev/data/mnist_tiny/train/7/9267.png,/home/condor/fastai_dev_my/dev/data/mnist_tiny/train/7/9157.png,/home/condor/fastai_dev_my/dev/data/mnist_tiny/train/7/7226.png,/home/condor/fastai_dev_my/dev/data/mnist_tiny/train/7/8629.png,/home/condor/fastai_dev_my/dev/data/mnist_tiny/train/7/8571.png,/home/condor/fastai_dev_my/dev/data/mnist_tiny/train/7/8741.png,/home/condor/fastai_dev_my/dev/data/mnist_tiny/train/7/7438.png,/home/condor/fastai_dev_my/dev/data/mnist_tiny/train/7/9644.png,/home/condor/fastai_dev_my/dev/data/mnist_tiny/train/7/839.png,/home/condor/fastai_dev_my/dev/data/mnist_tiny/train/7/8044.png...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = get_files(path/'train'/'3', extensions='.png', recurse=False)\n",
    "t7 = get_files(path/'train'/'7', extensions='.png', recurse=False)\n",
    "t  = get_files(path/'train', extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(t3)+len(t7))\n",
    "test_eq(len(get_files(path/'train'/'3', extensions='.jpg', recurse=False)),0)\n",
    "test_eq(len(t), len(get_files(path, extensions='.png', recurse=True, include='train')))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(len(get_files(path/'train'/'3', recurse=False)),346)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, include=['train', 'test'])),729)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's often useful to be able to create functions with customized behavior. `fastai.data` generally uses functions named as CamelCase verbs ending in `er` to create these functions. `FileGetter` is a simple example of such a function creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def FileGetter(suf='', extensions=None, recurse=True, include=None):\n",
    "    \"Create `get_files` partial function that searches path suffix `suf` and passes along args\"\n",
    "    def _inner(o, extensions=extensions, recurse=recurse, include=include):\n",
    "        return get_files(o/suf, extensions, recurse, include)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpng = FileGetter(extensions='.png', recurse=False)\n",
    "test_eq(len(t7), len(fpng(path/'train'/'7')))\n",
    "test_eq(len(t), len(fpng(path/'train', recurse=True)))\n",
    "fpng_r = FileGetter(extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(fpng_r(path/'train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "image_extensions = set(k for k,v in mimetypes.types_map.items() if v.startswith('image/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_image_files(path, recurse=True, include=None):\n",
    "    \"Get image files in `path` recursively.\"\n",
    "    return get_files(path, extensions=image_extensions, recurse=recurse, include=include)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is simply `get_files` called with a list of standard image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(t), len(get_image_files(path, recurse=True, include='train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ImageGetter(suf='', recurse=True, include=None):\n",
    "    \"Create `get_image_files` partial function that searches path suffix `suf` and passes along `kwargs`\"\n",
    "    def _inner(o, recurse=recurse, include=include): return get_image_files(o/suf, recurse, include)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as `FileGetter`, but for image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(get_files(path/'train', extensions='.png', recurse=True, include='3')),\n",
    "        len(ImageGetter(   'train',                    recurse=True, include='3')(path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of functions are used to *split* data into training and validation sets. The functions return two lists - a list of indices or masks for each of training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def RandomSplitter(valid_pct=0.2, seed=None, **kwargs):\n",
    "    \"Create function that splits `items` between train/val with `valid_pct` randomly.\"\n",
    "    def _inner(o, **kwargs):\n",
    "        if seed is not None: torch.manual_seed(seed)\n",
    "        rand_idx = L(int(i) for i in torch.randperm(len(o)))\n",
    "        cut = int(valid_pct * len(o))\n",
    "        return rand_idx[cut:],rand_idx[:cut]\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = list(range(30))\n",
    "f = RandomSplitter(seed=42)\n",
    "trn,val = f(src)\n",
    "assert 0<len(trn)<len(src)\n",
    "assert all(o not in val for o in trn)\n",
    "test_eq(len(trn), len(src)-len(val))\n",
    "# test random seed consistency\n",
    "test_eq(f(src)[0], trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _grandparent_idxs(items, name): return mask2idxs(Path(o).parent.parent.name == name for o in items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def GrandparentSplitter(train_name='train', valid_name='valid'):\n",
    "    \"Split `items` from the grand parent folder names (`train_name` and `valid_name`).\"\n",
    "    def _inner(o, **kwargs):\n",
    "        return _grandparent_idxs(o, train_name),_grandparent_idxs(o, valid_name)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [path/'train/3/9932.png', path/'valid/7/7189.png', \n",
    "         path/'valid/7/7320.png', path/'train/7/9833.png',  \n",
    "         path/'train/3/7666.png', path/'valid/3/925.png',\n",
    "         path/'train/7/724.png', path/'valid/3/93055.png']\n",
    "splitter = GrandparentSplitter()\n",
    "test_eq(splitter(items),[[0,3,4,6],[1,2,5,7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final set of functions is used to *label* a single item of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parent_label(o, **kwargs):\n",
    "    \"Label `item` with the parent folder name.\"\n",
    "    return o.parent.name if isinstance(o, Path) else o.split(os.path.sep)[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `parent_label` doesn't have anything customize, so it doesn't return a function - you can just use it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eq(parent_label(items[0]), '3')\n",
    "[parent_label(o) for o in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eq(parent_label(str(items[0])), '3')\n",
    "[parent_label(o) for o in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def RegexLabeller(pat):\n",
    "    \"Label `item` with regex `pat`.\"\n",
    "    pat = re.compile(pat)\n",
    "    def _inner(o, **kwargs):\n",
    "        res = pat.search(str(o))\n",
    "        assert res,f'Failed to find \"{pat}\" in \"{o}\"'\n",
    "        return res.group(1)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RegexLabeller` is a very flexible function since it handles any regex search of the stringified item. For instance, here's an example the replicates the previous `parent_label` results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = RegexLabeller(r'/(\\d)/')\n",
    "test_eq(parent_label(items[0]), '3')\n",
    "[f(o) for o in items]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CategoryMap(CollBase):\n",
    "    def __init__(self, col, sort=True, add_na=False):\n",
    "        if is_categorical_dtype(col): items = L(col.cat.categories, use_list=True)\n",
    "        else:\n",
    "            # `o==o` is the generalized definition of non-NaN used by Pandas\n",
    "            items = L(o for o in L(col, use_list=True).unique() if o==o)\n",
    "            if sort: items = items.sorted()\n",
    "        self.items = '#na#' + items if add_na else items\n",
    "        self.o2i = defaultdict(int, self.items.val2idx())\n",
    "    def __eq__(self,b): return all_equal(b,self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap([4,2,3,4])\n",
    "test_eq(t, [2,3,4])\n",
    "test_eq(t.o2i, {2:0,3:1,4:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap([4,2,3,4], add_na=True)\n",
    "test_eq(t, ['#na#',2,3,4])\n",
    "test_eq(t.o2i, {'#na#':0,2:1,3:2,4:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap(pd.Series([4,2,3,4]), sort=False)\n",
    "test_eq(t, [4,2,3])\n",
    "test_eq(t.o2i, {4:0,2:1,3:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = pd.Series(pd.Categorical(['M','H','L','M'], categories=['H','M','L'], ordered=True))\n",
    "t = CategoryMap(col)\n",
    "test_eq(t, ['H','M','L'])\n",
    "test_eq(t.o2i, {'H':0,'M':1,'L':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Category(str, ShowTitle): _show_args = {'label': 'category'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Categorize(Transform):\n",
    "    \"Reversible transform of category string to `vocab` id\"\n",
    "    order=1\n",
    "    def __init__(self, vocab=None, add_na=False):\n",
    "        self.add_na = add_na\n",
    "        self.vocab = None if vocab is None else CategoryMap(vocab, add_na=add_na)\n",
    "\n",
    "    def setup(self, dsrc):\n",
    "        if self.vocab is None and dsrc: self.vocab = CategoryMap(getattr(dsrc,'train',dsrc), add_na=self.add_na)\n",
    "\n",
    "    def encodes(self, o): return self.vocab.o2i[o]\n",
    "    def decodes(self, o)->Category: return self.vocab[o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "Category.create = Categorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Category.create()\n",
    "tds = TfmdDS(['cat', 'dog', 'cat'], tfms=[cat])\n",
    "test_eq(cat.vocab, ['cat', 'dog'])\n",
    "test_eq(cat('cat'), 0)\n",
    "test_eq(cat.decode(1), 'dog')\n",
    "test_stdout(lambda: tds.show_at(2), 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Category.create(add_na=True)\n",
    "tds = TfmdDS(['cat', 'dog', 'cat'], tfms=[cat])\n",
    "test_eq(cat.vocab, ['#na#', 'cat', 'dog'])\n",
    "test_eq(cat('cat'), 1)\n",
    "test_eq(cat.decode(2), 'dog')\n",
    "test_stdout(lambda: tds.show_at(2), 'cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicategorize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MultiCategory(L):\n",
    "    def show(self, ctx=None, sep=';', **kwargs): return show_title(sep.join(self.mapped(str)), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MultiCategorize(Categorize):\n",
    "    \"Reversible transform of multi-category strings to `vocab` id\"\n",
    "    def setup(self, dsrc):\n",
    "        if not dsrc: return\n",
    "        if self.vocab is None:\n",
    "            dsrc1 = getattr(dsrc,'train',dsrc)\n",
    "            vals = set()\n",
    "            for b in dsrc1: vals = vals.union(set(b))\n",
    "            self.vocab,self.o2i = uniqueify(list(vals), sort=True, bidir=True)\n",
    "        setattr(dsrc, 'vocab', self.vocab)\n",
    "\n",
    "    def encodes(self, o):                return [self.o2i  [o_] for o_ in o]\n",
    "    def decodes(self, o)->MultiCategory: return [self.vocab[o_] for o_ in o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "MultiCategory.create = MultiCategorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = MultiCategorize()\n",
    "tds = TfmdDS([['b', 'c'], ['a'], ['a', 'c']], tfms=[cat])\n",
    "test_eq(cat.vocab, ['a', 'b', 'c'])\n",
    "test_eq(cat(['a', 'c']), [0,2])\n",
    "test_eq(cat([]), [])\n",
    "test_eq(cat.decode([1]), ['b'])\n",
    "test_stdout(lambda: tds.show_at(2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class OneHotEncode(Transform):\n",
    "    \"One-hot encodes targets and optionally decodes with `vocab`\"\n",
    "    order=2\n",
    "    def __init__(self, do_encode=True, vocab=None): self.do_encode,self.vocab = do_encode,vocab\n",
    "\n",
    "    def setup(self, dsrc):\n",
    "        if self.vocab is not None:  self.c = len(self.vocab)\n",
    "        else: self.c = len(L(getattr(dsrc, 'vocab', None)))\n",
    "        if not self.c: warn(\"Couldn't infer the number of classes, please pass a `vocab` at init\")\n",
    "\n",
    "    def encodes(self, o): return one_hot(o, self.c) if self.do_encode else tensor(o).byte()\n",
    "    def decodes(self, o): return one_hot_decode(o, self.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work in conjunction with ` MultiCategorize` or on its own if you have one-hot encoded targets (pass a `vocab` for decoding and `do_encode=False` in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = OneHotEncode(vocab=['a', 'b', 'c'])\n",
    "tds = TfmdDS([[1,2], [0], [0, 1]], tfms=[_tfm])\n",
    "test_eq(_tfm([0,2]), tensor([1, 0, 1]).byte())\n",
    "test_eq(_tfm.decode(tensor([0,1,1])), ['b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = OneHotEncode(vocab=['a', 'b', 'c'], do_encode=False)\n",
    "tds = TfmdDS([[0,1,1], [1,0,0], [1,1,0]], tfms=[_tfm])\n",
    "test_eq(_tfm([1,0,1]), tensor([1, 0, 1]).byte())\n",
    "test_eq(_tfm.decode(tensor([0,1,1])), ['b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = TfmdDS([['b', 'c'], ['a'], ['a', 'c']], [[MultiCategorize(), OneHotEncode()]])\n",
    "test_eq(tds[1], [tensor([1, 0, 0]).byte()])\n",
    "test_eq(tds.decode([tensor([0,1,1])]), [['b','c']])\n",
    "test_stdout(lambda: tds.show_at(2), 'a;c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-end dataset example with MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([PosixPath('/home/condor/fastai_dev_my/dev/data/mnist_tiny/train/7/9267.png'),\n",
       "  PosixPath('/home/condor/fastai_dev_my/dev/data/mnist_tiny/train/7/9157.png'),\n",
       "  PosixPath('/home/condor/fastai_dev_my/dev/data/mnist_tiny/train/7/7226.png')],\n",
       " [PosixPath('/home/condor/fastai_dev_my/dev/data/mnist_tiny/valid/7/8188.png'),\n",
       "  PosixPath('/home/condor/fastai_dev_my/dev/data/mnist_tiny/valid/7/9019.png'),\n",
       "  PosixPath('/home/condor/fastai_dev_my/dev/data/mnist_tiny/valid/7/9384.png')])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = get_image_files(path)\n",
    "splits = splitter(items)\n",
    "train,valid = (items[i] for i in splits)\n",
    "train[:3],valid[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def open_img(fn:Path)->Image.Image: return Image.open(fn).copy()\n",
    "def img2tensor(im:Image.Image)->TensorImage: return array(im)[None]\n",
    "\n",
    "tfms = [[open_img, img2tensor],\n",
    "        [parent_label, Categorize()]]\n",
    "train_ds = TfmdDS(train, tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_ds[3]\n",
    "xd,yd = train_ds.decode_at(3)\n",
    "test_eq(parent_label(train[3]),yd)\n",
    "test_eq(array(Image.open(train[3])),xd[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAD80lEQVR4nO2aO0ssSRiGn5YZVNbbiOAiuF5BFAMTFQwUTQUR1EAGnF8gmggmxgqiBqJgeEwMhI0FE9ENREEMjAw8gdGuBt5QGS+9gad37O/0XHbsmS4O3wOiThVVL2+/U11fdVu2baMkKAhagGmoIQI1RKCGCNQQgRoiUEMEgRtiWdaD+HmzLGs1KD2hoCZ2sG27xPnbsqzfgL+B7aD0BJ4QwSjwD3AQlADTDIkBm3aA9YRlSi1jWdYfwHeg2bbt70HpMCkhE8BfQZoB5hnyLWgRRnxlLMvqAXaB323bvg9SiykJiQF/Bm0GGJIQkzAlIcaghgjUEIEaIkhX3P3KK67l9aEmRKCGCNQQgRoiUEMEaohADRGoIQI1RKCGCNQQgRoiUEMEeX2UeX//cWTa398PwMnJyX9t4+PjAAwMDADQ3d0NQHt7u2uMm5sbAHp6elz/r65+PA4eGRn5kkZNiCDdIXNW5yFXV1cAHBy4H9EuLi4CcHR0lHzCH3oKCwsBKCoqcrW/vr4C8Pj46Pq8rq4OgIuLi0xl6nlIJuRkDTk7OwNgbGws6zHi8bjrdzr6+vqynuszmhBB4C/MAIRCISYmJgA4PT0F3HegTIjFYr5o0YQIcpKQ+fn5jPqtra0BMDg4SG1tLQAPDw8A7OzsAIkr//z87DmGs051dXVlL/gTmhBBTvYh6+vrAExOTnq2NzU1AYl1oqSkxLMfQH19PQCXl5ee7YeHhwB0dnb+X5m6D8mEnKwhra2tKdvLysqA1Ml4enoC4OXlxbO9uLg47RjZYMRt14vr62sgYYykqqoKgMrKSl/n1a+MwNeEnJ+fA7CxseHZ3tzcDMDy8nLSMZzibWZmBoDb21vPfnNzcwBUV1dnJzYJmhCBrwlxirrtbe9X1RsaGgDo7e1NOsbm5mbKMdra2gAYHR3NWmcqNCECXxPS0dEBQGlpKQB3d3eu9re3t7RjOBvFZBtGJyHl5eVZ60yFJkTga0IaGxsBOD4+BmBrawtIbNSGh4fTjuEcLjtHiPKAaGhoyB+xSdCECHJS3H0FZ/+xsrLyIeCHPqcg3NvbA6CmpuarU2lxlwnG1DLOerO0tASAZbkvoHOI7EMyUqIJERiRkHg8zuzsbMo+LS0tedGiCREYkRD4ec2Q+PWYIR2aEIERhoRCIaLRKNFoFNu2XXVMJBIhEokQDocJh8M512KEISZhxBqyu7vLwsKCZ9vU1BQAFRUVedGiCREEmhBnrdjf30/aZ3p6Ol9yAE3ITwRa7Tov4X1eH97f3wEoKPi4Vs5Ldc4pnI9otZsJxp2H5BFNSCaku8ukLjB+QTQhAjVEoIYI1BCBGiJQQwT/Alx0C3Zdj/P9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = train_ds.show_at(3, cmap=\"Greys\", figsize=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ax.title.get_text() in ('3','7')\n",
    "test_fig_exists(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmdDL -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ToTensor(Transform):\n",
    "    \"Convert item to appropriate tensor class\"\n",
    "    order = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_dl_tfms = ('after_item','before_batch','after_batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates()\n",
    "class TfmdDL(DataLoader):\n",
    "    \"Transformed `DataLoader`\"\n",
    "    def __init__(self, dataset, bs=16, shuffle=False, num_workers=None, **kwargs):\n",
    "        if num_workers is None: num_workers = min(16, defaults.cpus)\n",
    "        for nm in _dl_tfms:\n",
    "            kwargs[nm] = Pipeline(kwargs.get(nm,None), as_item=(nm=='before_batch'))\n",
    "            kwargs[nm].setup(self)\n",
    "        super().__init__(dataset, bs=bs, shuffle=shuffle, num_workers=num_workers, **kwargs)\n",
    "        it  = self.do_item(0)\n",
    "        its = self.after_batch(self.do_batch([it]))\n",
    "        #TODO do we still need?\n",
    "        self._retain_ds = partial(retain_types, typs=L(it ).mapped(type))\n",
    "        self._retain_dl = partial(retain_types, typs=L(its).mapped(type))\n",
    "\n",
    "    def before_iter(self):\n",
    "        super().before_iter()\n",
    "        filt = getattr(self.dataset, 'filt', None)\n",
    "        for nm in _dl_tfms:\n",
    "            f = getattr(self,nm)\n",
    "            if isinstance(f,Pipeline): f.filt=filt\n",
    "\n",
    "    def decode(self, b): return self.before_batch.decode(self.after_batch.decode(self._retain_dl(b)))\n",
    "    def decode_batch(self, b, max_n=10, ds_decode=True): return self._decode_batch(self.decode(b), max_n, ds_decode)\n",
    "\n",
    "    def _decode_batch(self, b, max_n=10, ds_decode=True):\n",
    "        f = compose(self._retain_ds, self.after_item.decode)\n",
    "        if ds_decode: f = compose(f, getattr(self.dataset,'decode',noop))\n",
    "        return L(batch_to_samples(b, max_n=max_n)).mapped(f)\n",
    "\n",
    "    def show_batch(self, b=None, max_n=10, ctxs=None, **kwargs):\n",
    "        \"Show `b` (defaults to `one_batch`), a list of lists of pipeline outputs (i.e. output of a `DataLoader`)\"\n",
    "        if b is None: b = self.one_batch()\n",
    "        b = self.decode(b)\n",
    "        if hasattr(b, 'show'): return b.show(max_n=max_n, **kwargs)\n",
    "        if ctxs is None:\n",
    "            if hasattr(b[0], 'get_ctxs'): ctxs = b[0].get_ctxs(max_n=max_n, **kwargs)\n",
    "            else: ctxs = [None] * len(b[0] if is_iter(b[0]) else b)\n",
    "        db = self._decode_batch(b, max_n, False)\n",
    "        ctxs = [self.dataset.show(o, ctx=ctx, **kwargs) for o,ctx in zip(db, ctxs)]\n",
    "        if hasattr(b[0], 'display'): b[0].display(ctxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_docs(TfmdDL,\n",
    "         decode=\"Decode `b` using `tfms`\",\n",
    "         decode_batch=\"Decode `b` entirely\",\n",
    "         show_batch=\"Show each item of `b`\",\n",
    "         before_iter=\"override\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [[open_img], [parent_label, Categorize()]]\n",
    "tds = TfmdDS(items, tfms)\n",
    "tdl = TfmdDL(tds, after_item=img2tensor, bs=4)\n",
    "b = tdl.one_batch()\n",
    "test_eq(L(tdl.decode_batch(b)[0]).mapped(type), (TensorImage,Category))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegTfm(Transform):\n",
    "    def encodes(self, x): return torch.neg(x)\n",
    "    def decodes(self, x): return torch.neg(x)\n",
    "    \n",
    "tdl = TfmdDL(train_ds, after_batch=NegTfm(), bs=4, num_workers=4)\n",
    "b = tdl.one_batch()\n",
    "test_eq(type(b[0]), TensorImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A(Transform): \n",
    "    def encodes(self, x): return x \n",
    "    def decodes(self, x)->Int: return x \n",
    "\n",
    "@Transform\n",
    "def f(x)->None: return TupleBase((x,x))\n",
    "\n",
    "start = torch.arange(50)\n",
    "test_eq_type(f(2), TupleBase((2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = TfmdDS(start, [[A()], [f]])\n",
    "tdl = TfmdDL(tds, bs=4)\n",
    "x,y = tdl.one_batch()\n",
    "test_eq(type(y), TupleBase)\n",
    "\n",
    "s = tdl.decode_batch((x,y))\n",
    "test_eq(type(s[0][1]), TupleBase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = NegTfm(filt=1)\n",
    "tds = TfmdDS(start, [A()])\n",
    "tdl = TfmdDL(tds, after_batch=tfm, bs=4)\n",
    "x = tdl.one_batch()[0]\n",
    "test_eq(x, torch.arange(4))\n",
    "tds.filt = 1\n",
    "x = tdl.one_batch()[0]\n",
    "test_eq(x, -torch.arange(4))\n",
    "tds.filt = 0\n",
    "x = tdl.one_batch()[0]\n",
    "test_eq(x, torch.arange(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = TfmdDS(start, [A()])\n",
    "tdl = TfmdDL(tds, after_item=NegTfm(), bs=4)\n",
    "test_stdout(tdl.show_batch, \"0\\n1\\n2\\n3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = TfmdDS(start, [A()])\n",
    "tdl = TfmdDL(tds, after_batch=NegTfm(), bs=4)\n",
    "test_eq(*tdl.dataset[0], start[0])\n",
    "test_eq(len(tdl), (len(tds)-1)//4+1)\n",
    "test_eq(tdl.bs, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"DataLoader.one_batch\" class=\"doc_header\"><code>DataLoader.one_batch</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/01c_dataloader.ipynb#DataLoader\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DataLoader.one_batch</code>()\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDL.one_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tdl.one_batch()\n",
    "test_eq(tensor([0,-1,-2,-3]), b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TfmdDL.decode\" class=\"doc_header\"><code>TfmdDL.decode</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/05_data_core.ipynb#TfmdDL--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDL.decode</code>(**`b`**)\n",
       "\n",
       "Decode `b` using `tfms`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDL.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tdl.decode(b), (tensor(0,1,2,3),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TfmdDL.decode_batch\" class=\"doc_header\"><code>TfmdDL.decode_batch</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/05_data_core.ipynb#TfmdDL--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDL.decode_batch</code>(**`b`**, **`max_n`**=*`10`*, **`ds_decode`**=*`True`*)\n",
       "\n",
       "Decode `b` entirely"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDL.decode_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tdl.decode_batch(b), ((0,),(1,),(2,),(3,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TfmdDL.show_batch\" class=\"doc_header\"><code>TfmdDL.show_batch</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/05_data_core.ipynb#TfmdDL--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdDL.show_batch</code>(**`b`**=*`None`*, **`max_n`**=*`10`*, **`ctxs`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Show each item of `b`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdDL.show_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stdout(tdl.show_batch, \"0\\n1\\n2\\n3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuda -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class Cuda(Transform):\n",
    "    \"Move batch to `device` (defaults to `default_device()`)\"\n",
    "    def __init__(self,device=None):\n",
    "        self.device=default_device() if device is None else device\n",
    "        super().__init__(filt=None, as_item=False)\n",
    "    def encodes(self, b): return to_device(b, self.device)\n",
    "    def decodes(self, b): return to_cpu(b)\n",
    "\n",
    "    _docs=dict(encodes=\"Move batch to `device`\", decodes=\"Return batch to CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Cuda.encodes\" class=\"doc_header\"><code>Cuda.encodes</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Cuda.encodes</code>()\n",
       "\n",
       "Move batch to [`device`](https://pytorch.org/docs/stable/tensor_attributes.html#torch-device)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Cuda.encodes, name='Cuda.encodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, like all `Transform`s, `encodes` is called by `tfm()` and `decodes` is called by `tfm.decode()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "==:\ntorch.LongTensor\ntorch.cuda.LongTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-f9d1a4b7211b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'torch.cuda.LongTensor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/fastai_dev_my/dev/local/test.py\u001b[0m in \u001b[0;36mtest_eq\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;34m\"`test` that `a==b`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'=='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#Cell 21\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai_dev_my/dev/local/test.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(a, b, cmp, cname)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;34m\"`assert` that `cmp(a,b)`; display inputs and `cname or cmp.__name__` if it fails\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"{cname}:\\n{a}\\n{b}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#Cell 14\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ==:\ntorch.LongTensor\ntorch.cuda.LongTensor"
     ]
    }
   ],
   "source": [
    "tfm = Cuda()\n",
    "t = tfm((tensor(1),))\n",
    "test_eq(*t,1)\n",
    "test_eq(t[0].type(),'torch.cuda.LongTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Cuda.decodes\" class=\"doc_header\"><code>Cuda.decodes</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Cuda.decodes</code>()\n",
       "\n",
       "Return batch to CPU"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Cuda.decodes, name='Cuda.decodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tfm.decode(t)\n",
    "test_eq(*t,1)\n",
    "test_eq(t[0].type(),'torch.LongTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ByteToFloatTensor -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ByteToFloatTensor(Transform):\n",
    "    \"Transform image to float tensor, optionally dividing by 255 (e.g. for images).\"\n",
    "    order = 20 #Need to run after CUDA if on the GPU\n",
    "    def __init__(self, div=True, div_mask=False, filt=None, as_item=True):\n",
    "        super().__init__(filt=filt,as_item=as_item)\n",
    "        self.div,self.div_mask = div,div_mask\n",
    "\n",
    "    def encodes(self, o:TensorImage): return o.float().div_(255.) if self.div else o.float()\n",
    "    def encodes(self, o:TensorMask ): return o.div_(255.).long() if self.div_mask else o.long()\n",
    "    def decodes(self, o:TensorImage): return o.clamp(0., 1.) if self.div else o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (TensorImage(tensor(1)),tensor(2).long(),TensorMask(tensor(3)))\n",
    "tfm = ByteToFloatTensor(as_item=False)\n",
    "ft = tfm(t)\n",
    "test_eq(ft, [1./255, 2, 3])\n",
    "test_eq(type(ft[0]), TensorImage)\n",
    "test_eq(type(ft[2]), TensorMask)\n",
    "test_eq(ft[0].type(),'torch.FloatTensor')\n",
    "test_eq(ft[1].type(),'torch.LongTensor')\n",
    "test_eq(ft[2].type(),'torch.LongTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class Normalize(Transform):\n",
    "    \"Normalize/denorm batch of `TensorImage`\"\n",
    "    order=99\n",
    "    def __init__(self, mean, std): self.mean,self.std = mean,std\n",
    "    def encodes(self, x:TensorImage): return (x-self.mean) / self.std\n",
    "    def decodes(self, x:TensorImage): return (x*self.std ) + self.mean\n",
    "\n",
    "    _docs=dict(encodes=\"Normalize batch\", decodes=\"Denormalize batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def broadcast_vec(dim, ndim, *t, cuda=True):\n",
    "    \"Make a vector broadcastable over `dim` (out of `ndim` total) by prepending and appending unit axes\"\n",
    "    v = [1]*ndim\n",
    "    v[dim] = -1\n",
    "    f = to_device if cuda else noop\n",
    "    return [f(tensor(o).view(*v)) for o in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean,std = [0.5]*3,[0.5]*3\n",
    "mean,std = broadcast_vec(1, 4, mean, std)\n",
    "dl_tfms = [Cuda(), ByteToFloatTensor(), Normalize(mean,std)]\n",
    "tdl = TfmdDL(train_ds, after_batch=dl_tfms, bs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "==:\ntorch.FloatTensor\ntorch.cuda.FloatTensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-9171f1427438>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mxd\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'torch.cuda.FloatTensor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'torch.FloatTensor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai_dev_my/dev/local/test.py\u001b[0m in \u001b[0;36mtest_eq\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_eq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;34m\"`test` that `a==b`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'=='\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#Cell 21\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/fastai_dev_my/dev/local/test.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(a, b, cmp, cname)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;34m\"`assert` that `cmp(a,b)`; display inputs and `cname or cmp.__name__` if it fails\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mcmp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mf\"{cname}:\\n{a}\\n{b}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#Cell 14\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: ==:\ntorch.FloatTensor\ntorch.cuda.FloatTensor"
     ]
    }
   ],
   "source": [
    "x,y  = tdl.one_batch()\n",
    "xd,yd = tdl.after_batch.decode((x,y))\n",
    "\n",
    "test_eq(x.type(), 'torch.cuda.FloatTensor')\n",
    "test_eq(xd.type(), 'torch.FloatTensor')\n",
    "assert x.mean()<0.0\n",
    "assert x.std()>0.5\n",
    "assert 0<xd.mean()/255.<1\n",
    "assert 0<xd.std()/255.<0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tdl.show_batch((x,y), figsize=(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = torch.add(x,0),torch.add(y,0) #Lose type of tensors (to emulate predictions)\n",
    "test_ne(type(x), TensorImage)\n",
    "tdl.show_batch((x,y), figsize=(4,4)) #Check that types are put back by dl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: make the above check a proper test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataBunch -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class DataBunch(GetAttr):\n",
    "    \"Basic wrapper around several `DataLoader`s.\"\n",
    "    _xtra = 'one_batch show_batch dataset'.split()\n",
    "\n",
    "    def __init__(self, *dls): self.dls,self.default = dls,dls[0]\n",
    "    def __getitem__(self, i): return self.dls[i]\n",
    "\n",
    "    train_dl,valid_dl = add_props(lambda i,x: x[i])\n",
    "    train_ds,valid_ds = add_props(lambda i,x: x[i].dataset)\n",
    "\n",
    "    _docs=dict(__getitem__=\"Retrieve `DataLoader` at `i` (`0` is training, `1` is validation)\",\n",
    "              train_dl=\"Training `DataLoader`\",\n",
    "              valid_dl=\"Validation `DataLoader`\",\n",
    "              train_ds=\"Training `Dataset`\",\n",
    "              valid_ds=\"Validation `Dataset`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbch = DataBunch(tdl,tdl)\n",
    "x,y  = dbch.train_dl.one_batch()\n",
    "x2,y2 = next(iter(tdl))\n",
    "test_eq(x,x2)\n",
    "x2,y2 = dbch.one_batch()\n",
    "test_eq(x,x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"DataBunch.__getitem__\" class=\"doc_header\"><code>DataBunch.__getitem__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/05_data_core.ipynb#DataBunch--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DataBunch.__getitem__</code>(**`i`**)\n",
       "\n",
       "Retrieve [`DataLoader`](/dataloader.html#DataLoader) at `i` (`0` is training, `1` is validation)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataBunch.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2,y2 = dbch[0].one_batch()\n",
    "test_eq(x,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"train_dl\" class=\"doc_header\"><code>train_dl</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Training [`DataLoader`](/dataloader.html#DataLoader)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataBunch.train_dl, name=\"train_dl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"valid_dl\" class=\"doc_header\"><code>valid_dl</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Validation [`DataLoader`](/dataloader.html#DataLoader)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataBunch.valid_dl, name=\"valid_dl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"train_ds\" class=\"doc_header\"><code>train_ds</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Training `Dataset`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataBunch.train_ds, name=\"train_ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"valid_ds\" class=\"doc_header\"><code>valid_ds</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "Validation `Dataset`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataBunch.valid_ds, name=\"valid_ds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 01a_torch_core.ipynb.\n",
      "Converted 01b_script.ipynb.\n",
      "Converted 01c_dataloader.ipynb.\n",
      "Converted 02_data_transforms.ipynb.\n",
      "Converted 03_data_pipeline.ipynb.\n",
      "Converted 05_data_core.ipynb.\n",
      "Converted 06_data_source.ipynb.\n",
      "Converted 07_vision_core.ipynb.\n",
      "Converted 08_pets_tutorial.ipynb.\n",
      "Converted 09_vision_augment.ipynb.\n",
      "Converted 11_layers.ipynb.\n",
      "Converted 11a_vision_models_xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_learner.ipynb.\n",
      "Converted 14_callback_schedule.ipynb.\n",
      "Converted 15_callback_hook.ipynb.\n",
      "Converted 16_callback_progress.ipynb.\n",
      "Converted 17_callback_tracker.ipynb.\n",
      "Converted 18_callback_fp16.ipynb.\n",
      "Converted 19_callback_mixup.ipynb.\n",
      "Converted 20_metrics.ipynb.\n",
      "Converted 21_tutorial_imagenette.ipynb.\n",
      "Converted 30_text_core.ipynb.\n",
      "Converted 31_text_data.ipynb.\n",
      "Converted 32_text_models_awdlstm.ipynb.\n",
      "Converted 33_test_models_core.ipynb.\n",
      "Converted 34_callback_rnn.ipynb.\n",
      "Converted 35_tutorial_wikitext.ipynb.\n",
      "Converted 36_text_models_qrnn.ipynb.\n",
      "Converted 40_tabular_core.ipynb.\n",
      "Converted 41_tabular_model.ipynb.\n",
      "Converted 50_data_block.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n",
      "Converted 95_utils_test.ipynb.\n",
      "Converted 96_data_external.ipynb.\n",
      "Converted notebook2jekyll.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
