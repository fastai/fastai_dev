{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms and Pipeline\n",
    "\n",
    "> Low-level transform pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export core\n",
    "def opt_call(f, fname='__call__', *args, **kwargs):\n",
    "    \"Call `f.{fname}(*args, **kwargs)`, or `noop` if not defined\"\n",
    "    return getattr(f,fname,noop)(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(opt_call(operator.neg, '__call__', 2), -2)\n",
    "test_eq(opt_call(list, 'foobar', [2]), [2])\n",
    "\n",
    "a=[2,1]\n",
    "opt_call(list, 'sort', a)\n",
    "test_eq(a, [1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class Transform():\n",
    "    \"A function that `encodes` if `filt` matches, and optionally `decodes`, with an optional `setup`\"\n",
    "    order,filt = 0,None\n",
    "\n",
    "    def __init__(self, encodes=None, **kwargs):\n",
    "        if encodes is not None: self.encodes=encodes\n",
    "        for k,v in kwargs.items(): setattr(self, k, v)\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, f, filt=None):\n",
    "        \"classmethod: Turn `f` into a `Transform` unless it already is one\"\n",
    "        return f if hasattr(f,'decode') or isinstance(f,Transform) else cls(f)\n",
    "    \n",
    "    def _filt_match(self, filt): return self.filt is None or self.filt==filt\n",
    "    def __call__(self, o, filt=None, **kwargs): return self.encodes(o, **kwargs) if self._filt_match(filt) else o\n",
    "    def __getitem__(self, x): return self(x)\n",
    "    def decode  (self, o, filt=None, **kwargs): return self.decodes(o, **kwargs) if self._filt_match(filt) else o\n",
    "    def decodes(self, o, *args, **kwargs): return o\n",
    "    def __repr__(self): return str(self.encodes) if self.__class__==Transform else str(self.__class__)\n",
    "    def show(self, o, filt=None, **kwargs): return self.shows(self.decode(o, filt=filt), **kwargs)\n",
    "    \n",
    "    _docs=dict(__call__=\"Call `self.encodes` unless `filt` is passed and it doesn't match `self.filt`\",\n",
    "              decode=\"Call `self.decodes` unless `filt` is passed and it doesn't match `self.filt`\",\n",
    "              decodes=\"Override to implement custom decoding\",\n",
    "              show=\"Call `shows` with decoded `o`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a transformation pipeline some steps need to be reversible - for instance, if you turn a string (such as *dog*) into an int (such as *1*) for modeling, then for display purposes you'll want to turn it back to a string again (e.g. when you have a prediction). In addition, you may wish to only run the transformation for a particular data subset, such as the training set.\n",
    "\n",
    "`Transform` provides all this functionality. `filt` is some dataset index (e.g. provided by `DataSource`), and you provide `encodes` and optional `decodes` functions for your code. You can pass `encodes` and `decodes` functions directly to the constructor for quickly creating simple transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tneg = Transform(operator.neg,decodes=operator.neg)\n",
    "tfloat = Transform(float,decodes=int,shows=print)\n",
    "\n",
    "start = 4\n",
    "t = tneg(start)\n",
    "test_eq(t, -4)\n",
    "test_eq(t, tneg[start])\n",
    "test_eq(tneg.decode(t), start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More commonly, you'll subclass `Transform` and define `encodes` and `decodes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _AddTfm(Transform):\n",
    "    def encodes(self, x, a=1): return x+a\n",
    "    def decodes(self, x, a=1): return x-a\n",
    "    \n",
    "addt  = _AddTfm()\n",
    "start = 4\n",
    "t = addt(start)\n",
    "test_eq(t, 5)\n",
    "test_eq(addt.decode(5), start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Transform.__call__</code>\" class=\"doc_header\"><code>Transform.__call__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Transform--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Transform.__call__</code>(**`o`**, **`filt`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Call `self.encodes` unless `filt` is passed and it doesn't match `self.filt`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Transform.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Transform.decode</code>\" class=\"doc_header\"><code>Transform.decode</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Transform--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Transform.decode</code>(**`o`**, **`filt`**=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Call `self.decodes` unless `filt` is passed and it doesn't match `self.filt`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Transform.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Transform.create</code>\" class=\"doc_header\"><code>Transform.create</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Transform--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Transform.create</code>(**`f`**, **`filt`**=*`None`*)\n",
       "\n",
       "classmethod: Turn `f` into a [`Transform`](/data.pipeline.html#Transform) unless it already is one"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Transform.create)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _set_mapped(tfms, m=True):\n",
    "    for t in tfms: getattr(t,'set_mapped',noop)(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Pipeline(NewChk):\n",
    "    \"A pipeline of composed (for encode/decode) transforms, setup one at a time\"\n",
    "    def __init__(self, tfms):\n",
    "        if self._newchk: return\n",
    "        self.tfms,self._tfms = [],[Transform.create(t) for t in L(tfms)]\n",
    "\n",
    "    def setup(self, items=None):\n",
    "        \"Transform setup\"\n",
    "        if getattr(self,'has_setup', False): return\n",
    "        self.has_setup = True\n",
    "        self.add(self._tfms, items)\n",
    "        self._tfms = None\n",
    "\n",
    "    def add(self, tfms, items=None):\n",
    "        \"Call `setup` on all `tfms` and append them to this pipeline\"\n",
    "        for t in sorted(L(tfms), key=lambda o: getattr(o, 'order', 0)):\n",
    "            self.tfms.append(t)\n",
    "            if hasattr(t, 'setup') and items is not None: t.setup(items)\n",
    "    \n",
    "    def composed(self, x, rev=False, fname='__call__', **kwargs):\n",
    "        \"Compose `{fname}` of all `self.tfms` (reversed if `rev`) on `x`\"\n",
    "        tfms = reversed(self.tfms) if rev else self.tfms\n",
    "        for f in tfms: x = opt_call(f, fname, x, **kwargs)\n",
    "        return x\n",
    "\n",
    "    def __call__(self, x, **kwargs): return self.composed(x, **kwargs)\n",
    "    def __getitem__(self, x): return self(x)\n",
    "    def decode(self, x, **kwargs): return self.composed(x, rev=True, fname='decode', **kwargs)\n",
    "    def decode_at(self, idx): return self.decode(self[idx])\n",
    "    def show_at(self, idx): return self.show(self[idx])\n",
    "    def __repr__(self): return str(self.tfms)\n",
    "    def delete(self, idx): del(self.tfms[idx])\n",
    "    def remove(self, tfm): self.tfms.remove(tfm)\n",
    "        \n",
    "    def show(self, o, *args, **kwargs):\n",
    "        \"Find last transform that supports `shows` and call it\"\n",
    "        for t in reversed(self.tfms):\n",
    "            if hasattr(t, 'shows'): return t.show(o, *args, **kwargs)\n",
    "            o = getattr(t, 'decode', noop)(o)\n",
    "            \n",
    "    def set_mapped(self, m=True): _set_mapped(self._tfms, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_docs(Pipeline,\n",
    "         __call__=\"Compose `__call__` of all `tfms` on `x`\",\n",
    "         decode=\"Compose `decode` of all `tfms` on `x`\",\n",
    "         decode_at=\"Decoded item at `idx`\",\n",
    "         show_at=\"Show item at `idx`\",\n",
    "         delete=\"Delete transform `idx` from pipeline\",\n",
    "         remove=\"Remove `tfm` from pipeline\",\n",
    "         set_mapped=\"Set any `MappedTransform`s in `tfms` to mapped mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of transforms are often applied in a particular order, and decoded by applying in the reverse order. `Pipeline` provides this functionality, and also ensures that any `setup` methods are called, without including later transforms in those calls. NB: `setup` must be run before encoding/decoding.\n",
    "\n",
    "Here's some simple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [tneg,tfloat]\n",
    "pipe = Pipeline(tfms)\n",
    "pipe.setup()\n",
    "\n",
    "start = 2\n",
    "t = pipe(2)\n",
    "test_eq(t, -2.0)\n",
    "test_eq(type(t), float)\n",
    "test_eq(t, pipe[2])\n",
    "test_eq(pipe.decode(t), start)\n",
    "# `show` is on `tfloat` so `show_at` decodes that tfm only\n",
    "test_stdout(lambda:pipe.show_at(1), '-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.__call__</code>\" class=\"doc_header\"><code>Pipeline.__call__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.__call__</code>(**`x`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Compose `__call__` of all `tfms` on `x`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.decode</code>\" class=\"doc_header\"><code>Pipeline.decode</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.decode</code>(**`x`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Compose `decode` of all `tfms` on `x`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.delete</code>\" class=\"doc_header\"><code>Pipeline.delete</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.delete</code>(**`idx`**)\n",
       "\n",
       "Delete transform `idx` from pipeline"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.remove</code>\" class=\"doc_header\"><code>Pipeline.remove</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.remove</code>(**`tfm`**)\n",
       "\n",
       "Remove `tfm` from pipeline"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.add</code>\" class=\"doc_header\"><code>Pipeline.add</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.add</code>(**`tfms`**, **`items`**=*`None`*)\n",
       "\n",
       "Call `setup` on all `tfms` and append them to this pipeline"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.show_at</code>\" class=\"doc_header\"><code>Pipeline.show_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.show_at</code>(**`idx`**)\n",
       "\n",
       "Show item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.show_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.decode_at</code>\" class=\"doc_header\"><code>Pipeline.decode_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.decode_at</code>(**`idx`**)\n",
       "\n",
       "Decoded item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.decode_at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PipedList -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@docs\n",
    "class PipedList(GetAttr):\n",
    "    \"A `Pipeline` of transforms applied to a collection of `items`\"\n",
    "    _xtra = 'decode __call__ show'.split()\n",
    "    \n",
    "    def __init__(self, items, tfms):\n",
    "        self.items = L(items)\n",
    "        self.tfm = Pipeline(tfms)\n",
    "        self.tfm.setup(self)\n",
    "        self.has_setup = True\n",
    "        self.default = self.tfm\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"Transformed item(s) at `i`\"\n",
    "        its = self.items[i]\n",
    "        return its.mapped(self.tfm) if is_iter(i) else self.tfm(its)\n",
    "\n",
    "    def decode_batch(self, b, **kwargs):\n",
    "        \"Decode `b`, a list of lists of pipeline outputs (i.e. output of a `DataLoader`)\"\n",
    "        transp = L(zip(*L(b)))\n",
    "        return transp.mapped(partial(self.decode, **kwargs)).zipped()\n",
    "\n",
    "    def subset(self, idxs): return self.__class__(self.items[idxs], self.tfm)\n",
    "    def decode_at(self, idx): return self.decode(self[idx])\n",
    "    def show_at(self, idx): return self.show(self[idx])\n",
    "    def __eq__(self, b): return all_equal(self, b)\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __iter__(self): return (self[i] for i in range_of(self))\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}: {self.items}\\ntfms - {self.tfm}\"\n",
    "    \n",
    "    _docs = dict(decode_at=\"Decoded item at `idx`\",\n",
    "                 show_at=\"Show item at `idx`\",\n",
    "                 subset=\"New `PipedList` that only includes items at `idxs`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipedList: (#3) [1,2,3]\n",
       "tfms - [<built-in function neg>, <class 'float'>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = PipedList([1,2,3], tfms)\n",
    "t = pipe[1]\n",
    "test_eq(t, -2.0)\n",
    "test_eq(type(t), float)\n",
    "test_eq(pipe.decode_at(1), 2)\n",
    "test_eq(pipe.decode(t), 2)\n",
    "test_stdout(lambda: pipe.show_at(2), '-3')\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = pipe.subset([0,2])\n",
    "test_eq(p2, [-1.,-3.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we can use `PipedList.setup` to implement a simple category list, getting labels from a mock file list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PipedList: (#5) [dog_0.jpg,cat_0.jpg,cat_2.jpg,cat_1.jpg,dog_1.jpg]\n",
       "tfms - [<function _lbl at 0x7fb4d0ddbea0>, <class '__main__._Cat'>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class _Cat(Transform):\n",
    "    order=1\n",
    "    def encodes(self, o): return self.o2i[o] if hasattr(self,'o2i') else o\n",
    "    def decodes(self, o): return self.vocab[o]\n",
    "    def setup(self, items): self.vocab,self.o2i = uniqueify(items, sort=True, bidir=True)\n",
    "    def shows(self, o): print(f\"I'm a {o}\")\n",
    "\n",
    "def _lbl(o): return o.split('_')[0]\n",
    "\n",
    "test_fns = ['dog_0.jpg','cat_0.jpg','cat_2.jpg','cat_1.jpg','dog_1.jpg']\n",
    "tcat = _Cat()\n",
    "pipe = PipedList(test_fns, [tcat,_lbl])\n",
    "\n",
    "test_eq(tcat.vocab, ['cat','dog'])\n",
    "test_eq([1,0,0,0,1], pipe)\n",
    "test_eq(1, pipe[-1])\n",
    "test_eq([1,0], pipe[0,1])\n",
    "t = list(pipe)\n",
    "test_eq([1,0,0,0,1], t)\n",
    "test_eq(['dog','cat','cat','cat','dog'], map(pipe.decode,t))\n",
    "test_stdout(lambda:pipe.show_at(0), \"I'm a dog\")\n",
    "pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>PipedList.__getitem__</code>\" class=\"doc_header\"><code>PipedList.__getitem__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#PipedList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>PipedList.__getitem__</code>(**`i`**)\n",
       "\n",
       "Transformed item(s) at `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(PipedList.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.decode(pipe[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(pipe.decode_at(1),'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>PipedList.show_at</code>\" class=\"doc_header\"><code>PipedList.show_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#PipedList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>PipedList.show_at</code>(**`idx`**)\n",
       "\n",
       "Show item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(PipedList.show_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a cat\n"
     ]
    }
   ],
   "source": [
    "pipe.show_at(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Pipelines(Transform):\n",
    "    \"Create a `Pipeline` for each tfm in `tfms`. Generally used inside a `PipedList`\"\n",
    "    def __init__(self, tfms): self.activ,self.tfms = None,[Pipeline(t) for t in L(tfms)]\n",
    "    def __repr__(self): return f'Pipelines({self.tfms})'\n",
    "\n",
    "    def encodes(self, o, *args, **kwargs):\n",
    "        \"List of output of each of `tfms` on `o`\"\n",
    "        if self.activ is not None: return self.activ(o, *args, **kwargs)\n",
    "        return [t(o, *args, **kwargs) for t in self.tfms]\n",
    "    \n",
    "    def decodes(self, o, **kwargs):\n",
    "        return [t.decode(p, **kwargs) for p,t in zip(o,self.tfms)]\n",
    "    \n",
    "    def show(self, o, ctx=None, **kwargs):\n",
    "        \"Show result of `show` from each of `tfms`\"\n",
    "        for p,t in zip(o,self.tfms): ctx = t.show(p, ctx=ctx, **kwargs)\n",
    "    def shows(self): pass # needed for `Pipeline` method search for `show`\n",
    "\n",
    "    def setup(self, o):\n",
    "        \"Setup each of `tfms` independently\"\n",
    "        for tfm in self.tfms:\n",
    "            self.activ = tfm\n",
    "            tfm.setup(o)\n",
    "        self.activ=None\n",
    "    \n",
    "    @classmethod\n",
    "    def xtra(cls, tfms, xtra=None):\n",
    "        \"PipedList over `items` with `tfms` `Pipelines` as first tfm optionally followed by any `xtra` tfms\"\n",
    "        xtra = L(xtra)\n",
    "        _set_mapped(xtra)\n",
    "        return Pipeline(cls(tfms)+xtra)\n",
    "\n",
    "    xt,yt = add_props(lambda i,x:x.tfms[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _TNorm(Transform):\n",
    "    def __init__(self): self.m,self.s = 0,1\n",
    "    def encodes(self, o): return (o-self.m)/self.s\n",
    "    def decodes(self, o): return (o*self.s)+self.m\n",
    "    def shows(self, o, **kwargs): print(o)\n",
    "    def setup(self, items):\n",
    "        its = tensor(items)\n",
    "        self.m,self.s = its.mean(),its.std()\n",
    "\n",
    "tnrm = _TNorm()\n",
    "items = [1,2,3,4]\n",
    "tfm = Pipelines.xtra([tneg, [tneg,tnrm]])\n",
    "pl = PipedList(items, tfm)\n",
    "x,y = zip(*pl)\n",
    "test_close(tensor(y).mean(), 0)\n",
    "test_close(tensor(y).std(), 1)\n",
    "test_eq(x, [-1,-2,-3,-4])\n",
    "test_stdout(lambda:pl.show_at(1), 'tensor(-2.)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-1, -2, -3, -4),\n",
       " (tensor(1.1619), tensor(0.3873), tensor(-0.3873), tensor(-1.1619))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a \"batch\"\n",
    "b = list(zip(*pl)); b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bd = pl.decode_batch(b)\n",
    "\n",
    "test_eq(len(bd),2)\n",
    "test_eq(bd[0],items)\n",
    "test_eq(bd[1],items)\n",
    "test_eq(type(bd[1][0]),Tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 02_data_pipeline.ipynb.\n",
      "Converted 03_data_external.ipynb.\n",
      "Converted 04_data_core.ipynb.\n",
      "Converted 05_data_source.ipynb.\n",
      "Converted 06_vision_core.ipynb.\n",
      "Converted 07_pets_tutorial.ipynb.\n",
      "Converted 10_layers.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
