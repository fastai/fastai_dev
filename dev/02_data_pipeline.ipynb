{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms and Pipeline\n",
    "\n",
    "> Low-level transform pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes here provide functionality for creating *partially reversible functions*, which we call `Transform`s. By \"partially reversible\" we mean that a transform can be `decode`d, creating a form suitable for display. This is not necessarily identical to the original form (e.g. a transform that changes a byte tensor to a float tensor does not recreate a byte tensor when decoded, since that may lose precision, and a float tensor can be displayed already.)\n",
    "\n",
    "Classes are also provided and for composing transforms, and mapping them over collections. The following functionality is provided:\n",
    "\n",
    "- A `Transform` can be created with `is_tuple=True`, which causes a single transform to be mapped over an input collection\n",
    "- `Pipeline` is a transform which composes transforms\n",
    "- `TfmOver` is a transform which applies multiple transforms over an input collection of the same length\n",
    "- `TfmdList` takes a collection and a transform, and provides an indexer (`__getitem__`) which dynamically applies the transform to the collection items."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export core\n",
    "def opt_call(f, fname='__call__', *args, **kwargs):\n",
    "    \"Call `f.{fname}(*args, **kwargs)`, or `noop` if not defined\"\n",
    "    return getattr(f,fname,noop)(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(opt_call(operator.neg, '__call__', 2), -2)\n",
    "test_eq(opt_call(list, 'foobar', [2]), [2])\n",
    "\n",
    "a=[2,1]\n",
    "opt_call(list, 'sort', a)\n",
    "test_eq(a, [1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class Transform():\n",
    "    \"A function that `encodes` if `filt` matches, and optionally `decodes`, with an optional `setup`\"\n",
    "    order,filt = 0,None\n",
    "\n",
    "    def __init__(self, encodes=None, mask=None, is_tuple=None, **kwargs):\n",
    "        self._done_init = True\n",
    "        if encodes is not None: self.encodes=encodes\n",
    "        self.mask,self.is_tuple = mask,is_tuple\n",
    "        for k,v in kwargs.items(): setattr(self, k, v)\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, f, filt=None):\n",
    "        \"classmethod: Turn `f` into a `Transform` unless it already is one\"\n",
    "        return f if isinstance(f,Transform) else cls(f)\n",
    "    \n",
    "    def setup(self, items=None):\n",
    "        if getattr(self,'_is_setup',False): return\n",
    "        self._is_setup = True\n",
    "        self.setups(items)\n",
    "\n",
    "    def _apply(self,f,b, **kwargs):\n",
    "        assert getattr(self,'_done_init',False), f\"{self.__class__}: `super().__init__` not called\"\n",
    "        mask = [i==0 for i in range_of(b)] if self.mask is None and self.is_tuple else self.mask\n",
    "        return tuple(f(o, **kwargs) if p else o for o,p in zip(b,mask)) if self.is_tuple else f(b, **kwargs)\n",
    "    \n",
    "    def _filt_match(self, filt): return self.filt is None or self.filt==filt\n",
    "    def __call__(self, b, filt=None, **kwargs):\n",
    "        return self._apply(self.encodes, b, **kwargs) if self._filt_match(filt) else b\n",
    "    def decode  (self, b, filt=None, **kwargs):\n",
    "        return self._apply(self.decodes, b, **kwargs) if self._filt_match(filt) else b\n",
    "    \n",
    "    def __getitem__(self, x): return self(x)\n",
    "    def decodes(self, o, *args, **kwargs): return o\n",
    "    def setups(self, items): pass\n",
    "    def __repr__(self): return str(self.encodes) if self.__class__==Transform else str(self.__class__)\n",
    "    def show(self, o, filt=None, **kwargs): return self.shows(self.decode(o, filt=filt), **kwargs)\n",
    "    def set_tupled(self, tf=True): self.is_tuple = ifnone(self.is_tuple,tf)\n",
    "    \n",
    "    _docs=dict(__call__=\"Call `self.encodes` unless `filt` is passed and it doesn't match `self.filt`\",\n",
    "              decode=\"Call `self.decodes` unless `filt` is passed and it doesn't match `self.filt`\",\n",
    "              decodes=\"Override to implement custom decoding\",\n",
    "              show=\"Call `shows` with decoded `o`\",\n",
    "              set_tupled=\"Set `is_tuple` to `tf` if it was `None` (used internally by `TfmOver`)\",\n",
    "              setup=\"Override `setups` for setup behavior\",\n",
    "              setups=\"Override to implement custom setup behavior\"\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a transformation pipeline some steps need to be reversible - for instance, if you turn a string (such as *dog*) into an int (such as *1*) for modeling, then for display purposes you'll want to turn it back to a string again (e.g. when you have a prediction). In addition, you may wish to only run the transformation for a particular data subset, such as the training set.\n",
    "\n",
    "`Transform` provides all this functionality. `filt` is some dataset index (e.g. provided by `DataSource`), and you provide `encodes` and optional `decodes` functions for your code. You can pass `encodes` and `decodes` functions directly to the constructor for quickly creating simple transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tneg = Transform(operator.neg,decodes=operator.neg)\n",
    "tfloat = Transform(float,decodes=int,shows=print)\n",
    "\n",
    "start = 4\n",
    "t = tneg(start)\n",
    "test_eq(t, -4)\n",
    "test_eq(t, tneg[start])\n",
    "test_eq(tneg.decode(t), start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More commonly, you'll subclass `Transform` and define `encodes` and `decodes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _AddTfm(Transform):\n",
    "    def encodes(self, x, a=1): return x+a\n",
    "    def decodes(self, x, a=1): return x-a\n",
    "    \n",
    "addt  = _AddTfm()\n",
    "start = 4\n",
    "t = addt(start)\n",
    "test_eq(t, 5)\n",
    "test_eq(addt.decode(5), start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addt.filt=1\n",
    "test_eq(addt(start,filt=1), 5)\n",
    "test_eq(addt(start,filt=0), start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `is_tuple` to map the transform over a collection of inputs, applying it where `mask` is `True`. Note that `mask` defaults to `(True,False)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "addt  = _AddTfm(is_tuple=True)\n",
    "start = (1,2,3)\n",
    "t = addt(start)\n",
    "test_eq(t,(2,2,3))\n",
    "test_eq(addt.decode(t), start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfm = _AddTfm(is_tuple=True, mask=(True,True))\n",
    "start = (1,2)\n",
    "t = tfm(start)\n",
    "test_eq(t,(2,3))\n",
    "test_eq(tfm.decode(t), start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _set_tupled(tfms, m=True):\n",
    "    for t in tfms: getattr(t,'set_tupled',noop)(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@newchk\n",
    "class Pipeline(Transform):\n",
    "    \"A pipeline of composed (for encode/decode) transforms, setup one at a time\"\n",
    "    def __init__(self, tfms=None):\n",
    "        self.tfms,self._tfms = [],L(tfms).mapped(Transform.create)\n",
    "\n",
    "    def setups(self, items=None):\n",
    "        \"Transform setup\"\n",
    "        self.add(self._tfms, items)\n",
    "        self._tfms = None\n",
    "\n",
    "    def add(self, tfms, items=None):\n",
    "        \"Call `setup` on all `tfms` and append them to this pipeline\"\n",
    "        for t in sorted(L(tfms), key=lambda o: getattr(o, 'order', 0)):\n",
    "            self.tfms.append(t)\n",
    "            if hasattr(t, 'setup'): t.setup(items)\n",
    "    \n",
    "    def composed(self, x, rev=False, fname='__call__', **kwargs):\n",
    "        \"Compose `{fname}` of all `self.tfms` (reversed if `rev`) on `x`\"\n",
    "        tfms = reversed(self.tfms) if rev else self.tfms\n",
    "        for f in tfms: x = opt_call(f, fname, x, **kwargs)\n",
    "        return x\n",
    "\n",
    "    def __call__(self, x, **kwargs): return self.composed(x, **kwargs)\n",
    "    def __getitem__(self, x): return self(x)\n",
    "    def decode(self, x, **kwargs): return self.composed(x, rev=True, fname='decode', **kwargs)\n",
    "    def decode_at(self, idx): return self.decode(self[idx])\n",
    "    def show_at(self, idx): return self.show(self[idx])\n",
    "    def __repr__(self): return str(self.tfms)\n",
    "    def delete(self, idx): del(self.tfms[idx])\n",
    "    def remove(self, tfm): self.tfms.remove(tfm)\n",
    "        \n",
    "    def show(self, o, *args, **kwargs):\n",
    "        \"Find last transform that supports `shows` and call it\"\n",
    "        for t in reversed(self.tfms):\n",
    "            if hasattr(t, 'shows'): return t.show(o, *args, **kwargs)\n",
    "            o = getattr(t, 'decode', noop)(o)\n",
    "            \n",
    "    def set_tupled(self, m=True): _set_tupled(self._tfms, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_docs(Pipeline,\n",
    "         __call__=\"Compose `__call__` of all `tfms` on `x`\",\n",
    "         decode=\"Compose `decode` of all `tfms` on `x`\",\n",
    "         decode_at=\"Decoded item at `idx`\",\n",
    "         show_at=\"Show item at `idx`\",\n",
    "         delete=\"Delete transform `idx` from pipeline\",\n",
    "         remove=\"Remove `tfm` from pipeline\",\n",
    "         set_tupled=\"Set any `MappedTransform`s in `tfms` to tupled mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of transforms are often applied in a particular order, and decoded by applying in the reverse order. `Pipeline` provides this functionality, and also ensures that any `setup` methods are called, without including later transforms in those calls. NB: `setup` must be run before encoding/decoding.\n",
    "\n",
    "Here's some simple examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty pipelines are a noop\n",
    "pipe = Pipeline()\n",
    "pipe.setup()\n",
    "test_eq(pipe(1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a standard pipeline\n",
    "tfms = [tneg,tfloat]\n",
    "pipe = Pipeline(tfms)\n",
    "pipe.setup()\n",
    "\n",
    "start = 2\n",
    "t = pipe(2)\n",
    "test_eq(t, -2.0)\n",
    "test_eq(type(t), float)\n",
    "test_eq(t, pipe[2])\n",
    "test_eq(pipe.decode(t), start)\n",
    "# `show` is on `tfloat` so `show_at` decodes that tfm only\n",
    "test_stdout(lambda:pipe.show_at(1), '-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.__call__</code>\" class=\"doc_header\"><code>Pipeline.__call__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.__call__</code>(**`x`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Compose `__call__` of all `tfms` on `x`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.decode</code>\" class=\"doc_header\"><code>Pipeline.decode</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.decode</code>(**`x`**, **\\*\\*`kwargs`**)\n",
       "\n",
       "Compose `decode` of all `tfms` on `x`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.delete</code>\" class=\"doc_header\"><code>Pipeline.delete</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.delete</code>(**`idx`**)\n",
       "\n",
       "Delete transform `idx` from pipeline"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.remove</code>\" class=\"doc_header\"><code>Pipeline.remove</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.remove</code>(**`tfm`**)\n",
       "\n",
       "Remove `tfm` from pipeline"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.add</code>\" class=\"doc_header\"><code>Pipeline.add</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.add</code>(**`tfms`**, **`items`**=*`None`*)\n",
       "\n",
       "Call `setup` on all `tfms` and append them to this pipeline"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.show_at</code>\" class=\"doc_header\"><code>Pipeline.show_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.show_at</code>(**`idx`**)\n",
       "\n",
       "Show item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.show_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>Pipeline.decode_at</code>\" class=\"doc_header\"><code>Pipeline.decode_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#Pipeline--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Pipeline.decode_at</code>(**`idx`**)\n",
       "\n",
       "Decoded item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(Pipeline.decode_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def make_tfm(tfm):\n",
    "    \"Create a `Pipeline` (if `tfm` is listy) or a `Transform` otherwise\"\n",
    "    return Pipeline(tfm) if is_listy(tfm) else Transform.create(tfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmdList -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@docs\n",
    "class TfmdList(GetAttr):\n",
    "    \"A transform applied to a collection of `items`\"\n",
    "    _xtra = 'decode __call__ show'.split()\n",
    "    \n",
    "    def __init__(self, items, tfm, do_setup=True):\n",
    "        self.items = L(items)\n",
    "        self.default = self.tfm = make_tfm(tfm)\n",
    "        if do_setup: self.setup()\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"Transformed item(s) at `i`\"\n",
    "        its = self.items[i]\n",
    "        return its.mapped(self.tfm) if is_iter(i) else self.tfm(its)\n",
    "\n",
    "    def decode_batch(self, b, **kwargs):\n",
    "        \"Decode `b`, a list of lists of pipeline outputs (i.e. output of a `DataLoader`)\"\n",
    "        transp = L(zip(*L(b)))\n",
    "        return transp.mapped(partial(self.decode, **kwargs)).zipped()\n",
    "\n",
    "    def setup(self): getattr(self.tfm,'setup',noop)(self)\n",
    "    def subset(self, idxs): return self.__class__(self.items[idxs], self.tfm, do_setup=False)\n",
    "    def decode_at(self, idx): return self.decode(self[idx])\n",
    "    def show_at(self, idx): return self.show(self[idx])\n",
    "    def __eq__(self, b): return all_equal(self, b)\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __iter__(self): return (self[i] for i in range_of(self))\n",
    "    def __repr__(self): return f\"{self.__class__.__name__}: {self.items}\\ntfms - {self.tfm}\"\n",
    "    \n",
    "    _docs = dict(setup=\"Transform setup with self\",\n",
    "                 decode_at=\"Decoded item at `idx`\",\n",
    "                 show_at=\"Show item at `idx`\",\n",
    "                 subset=\"New `TfmdList` that only includes items at `idxs`\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfmdList: (#3) [1,2,3]\n",
       "tfms - [<built-in function neg>, <class 'float'>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl = TfmdList([1,2,3], pipe)\n",
    "t = tl[1]\n",
    "test_eq(t, -2.0)\n",
    "test_eq(type(t), float)\n",
    "test_eq(tl.decode_at(1), 2)\n",
    "test_eq(tl.decode(t), 2)\n",
    "test_stdout(lambda: tl.show_at(2), '-3')\n",
    "tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2 = tl.subset([0,2])\n",
    "test_eq(p2, [-1.,-3.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how we can use `TfmdList.setup` to implement a simple category list, getting labels from a mock file list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfmdList: (#5) [dog_0.jpg,cat_0.jpg,cat_2.jpg,cat_1.jpg,dog_1.jpg]\n",
       "tfms - [<function _lbl at 0x7f554a9426a8>, <class '__main__._Cat'>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class _Cat(Transform):\n",
    "    order=1\n",
    "    def encodes(self, o): return self.o2i[o] if hasattr(self,'o2i') else o\n",
    "    def decodes(self, o): return self.vocab[o]\n",
    "    def setup(self, items): self.vocab,self.o2i = uniqueify(items, sort=True, bidir=True)\n",
    "    def shows(self, o): print(f\"I'm a {o}\")\n",
    "\n",
    "def _lbl(o): return o.split('_')[0]\n",
    "\n",
    "test_fns = ['dog_0.jpg','cat_0.jpg','cat_2.jpg','cat_1.jpg','dog_1.jpg']\n",
    "tcat = _Cat()\n",
    "tl = TfmdList(test_fns, [tcat,_lbl])\n",
    "\n",
    "test_eq(tcat.vocab, ['cat','dog'])\n",
    "test_eq([1,0,0,0,1], tl)\n",
    "test_eq(1, tl[-1])\n",
    "test_eq([1,0], tl[0,1])\n",
    "t = list(tl)\n",
    "test_eq([1,0,0,0,1], t)\n",
    "test_eq(['dog','cat','cat','cat','dog'], map(tl.decode,t))\n",
    "test_stdout(lambda:tl.show_at(0), \"I'm a dog\")\n",
    "tl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.__getitem__</code>\" class=\"doc_header\"><code>TfmdList.__getitem__</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmdList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.__getitem__</code>(**`i`**)\n",
       "\n",
       "Transformed item(s) at `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.decode(tl[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(tl.decode_at(1),'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>TfmdList.show_at</code>\" class=\"doc_header\"><code>TfmdList.show_at</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/02_data_pipeline.ipynb#TfmdList--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TfmdList.show_at</code>(**`idx`**)\n",
       "\n",
       "Show item at `idx`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TfmdList.show_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm a cat\n"
     ]
    }
   ],
   "source": [
    "tl.show_at(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfmOver -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TfmOver(Transform):\n",
    "    \"Create tuple containing each of `tfms` applied to each of `o`\"\n",
    "    def __init__(self, tfms=None):\n",
    "        super().__init__()\n",
    "        if tfms is None: tfms = [None]\n",
    "        self.activ,self.tfms = None,L(tfms).mapped(Pipeline)\n",
    "\n",
    "    def __call__(self, o, *args, **kwargs):\n",
    "        \"List of output of each of `tfms` on `o`\"\n",
    "        if self.activ is not None: return self.tfms[self.activ](o[self.activ], *args, **kwargs)\n",
    "        return [t(p, *args, **kwargs) for p,t in zip(o,self.tfms)]\n",
    "    \n",
    "    def decode(self, o, **kwargs):\n",
    "        return [t.decode(p, **kwargs) for p,t in zip(o,self.tfms)]\n",
    "    \n",
    "    def show(self, o, ctx=None, **kwargs):\n",
    "        \"Show result of `show` from each of `tfms`\"\n",
    "        for p,t in zip(o,self.tfms): ctx = t.show(p, ctx=ctx, **kwargs)\n",
    "        return ctx\n",
    "\n",
    "    def __repr__(self): return f'TfmOver({self.tfms})'\n",
    "    def shows(self): pass # needed for `Pipeline` method search for `show`\n",
    "\n",
    "    def setups(self, o=None):\n",
    "        \"Setup each of `tfms` independently\"\n",
    "        for i,tfm in enumerate(self.tfms):\n",
    "            self.activ = i\n",
    "            tfm.setup(o)\n",
    "        self.activ=None\n",
    "    \n",
    "    @classmethod\n",
    "    def piped(cls, tfms=None, final_tfms=None):\n",
    "        \"`Pipeline` that duplicates input, then maps `TfmOver` over `tfms`, optionally followed by any `final_tfms`\"\n",
    "        tfms = L(ifnone(tfms,[None]))\n",
    "        final_tfms = L(final_tfms)\n",
    "        _set_tupled(final_tfms)\n",
    "        init_tfm = partial(tuplify,match=tfms)\n",
    "        return Pipeline([init_tfm,cls(tfms)] + final_tfms)\n",
    "\n",
    "    xt,yt = add_props(lambda i,x:x.tfms[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _TNorm(Transform):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.m,self.s = 0,1\n",
    "        \n",
    "    def encodes(self, o): return (o-self.m)/self.s\n",
    "    def decodes(self, o): return (o*self.s)+self.m\n",
    "    def shows(self, o, **kwargs): print(o)\n",
    "    def setup(self, items):\n",
    "        its = tensor(items)\n",
    "        self.m,self.s = its.mean(),its.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnrm = _TNorm()\n",
    "items = [1,2,3,4]\n",
    "tl = TfmdList(items, TfmOver.piped([tneg, [tneg,tnrm]]))\n",
    "x,y = zip(*tl)\n",
    "test_close(tensor(y).mean(), 0)\n",
    "test_close(tensor(y).std(), 1)\n",
    "test_eq(x, [-1,-2,-3,-4])\n",
    "test_stdout(lambda:tl.show_at(1), 'tensor(-2.)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b  [(-1, -2, -3, -4), (tensor(1.1619), tensor(0.3873), tensor(-0.3873), tensor(-1.1619))]\n",
      "bd (#2) [(#4) [1,2,3,4],(#4) [tensor(1.),tensor(2.),tensor(3.),tensor(4.)]]\n"
     ]
    }
   ],
   "source": [
    "# Create a \"batch\"\n",
    "b = list(zip(*tl))\n",
    "bd = tl.decode_batch(b)\n",
    "\n",
    "test_eq(len(bd),2)\n",
    "test_eq(bd[0],items)\n",
    "test_eq(bd[1],items)\n",
    "test_eq(type(bd[1][0]),Tensor)\n",
    "print('b ',b)\n",
    "print('bd',bd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty tuplify\n",
    "tp = TfmOver()\n",
    "tp.setup()\n",
    "test_eq(tp([1]), [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 02_data_pipeline.ipynb.\n",
      "Converted 03_data_external.ipynb.\n",
      "Converted 04_data_core.ipynb.\n",
      "Converted 05_data_source.ipynb.\n",
      "Converted 06_vision_core.ipynb.\n",
      "Converted 07_pets_tutorial.ipynb.\n",
      "Converted 10_layers.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
