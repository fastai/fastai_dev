#AUTOGENERATED! DO NOT EDIT! File to edit: dev/07_data_block.ipynb (unless otherwise specified).

__all__ = ['DataBlock']

#Cell
from ..torch_basics import *
from ..test import *
from .core import *
from .load import *
from .external import *
from .transforms import *

#Cell
from inspect import isfunction,ismethod

#Cell
def _merge_tfms(*tfms):
    "Group the `tfms` in a single list, removing duplicates (from the same class) and instantiating"
    g = groupby(concat(*tfms), lambda o:
        o if isinstance(o, type) else o.__qualname__ if (isfunction(o) or ismethod(o)) else o.__class__)
    return L(v[-1] for k,v in g.items()).map(instantiate)

#Cell
@docs
@funcs_kwargs
class DataBlock():
    "Generic container to quickly build `DataSource` and `DataBunch`"
    get_x=get_items=splitter=get_y = None
    dl_type = TfmdDL
    _methods = 'get_items splitter get_y get_x'.split()
    def __init__(self, types=None, dl_type=None, getters=None, n_inp=None, **kwargs):
        types = L(getattr(self,'types',(float,float)) if types is None else types)
        self.default_type_tfms = types.map(
            lambda t: L(getattr(t,'create',None)) + L(getattr(t,'default_type_tfms',None)))
        self.default_item_tfms  = _merge_tfms(ToTensor, *types.attrgot('default_item_tfms',  L()))
        self.default_batch_tfms = _merge_tfms(Cuda,     *types.attrgot('default_batch_tfms', L()))
        for t in types: self.dl_type = getattr(t, 'dl_type', self.dl_type)
        if dl_type is not None: self.dl_type = dl_type
        self.databunch = delegates(self.dl_type.__init__)(self.databunch)
        self.dbunch_kwargs = {}
        for t in types: self.dbunch_kwargs.update(getattr(t, 'dbunch_kwargs', {}))
        self.n_inp,self.getters = n_inp,L(getters)
        if getters is not None: assert self.get_x is None and self.get_y is None
        assert not kwargs

    def datasource(self, source, type_tfms=None):
        self.source = source
        items = (self.get_items or noop)(source)
        if isinstance(items,tuple):
            items = L(items).zip()
            labellers = [itemgetter(i) for i in range_of(self.default_type_tfms)]
        else: labellers = [noop] * len(self.default_type_tfms)
        splits = (self.splitter or noop)(items)
        if self.get_x:   labellers[0] = self.get_x
        if self.get_y:   labellers[1] = self.get_y
        if self.getters: labellers = self.getters
        if type_tfms is None: type_tfms = [L() for t in self.default_type_tfms]
        type_tfms = L([self.default_type_tfms, type_tfms, labellers]).map_zip(
            lambda tt,tfm,l: L(l) + _merge_tfms(tt, tfm))
        return DataSource(items, tfms=type_tfms, splits=splits, dl_type=self.dl_type, n_inp=self.n_inp)

    def databunch(self, source, type_tfms=None, item_tfms=None, batch_tfms=None, bs=16, **kwargs):
        dsrc = self.datasource(source, type_tfms=type_tfms)
        item_tfms  = _merge_tfms(self.default_item_tfms,  item_tfms)
        batch_tfms = _merge_tfms(self.default_batch_tfms, batch_tfms)
        kwargs = {**self.dbunch_kwargs, **kwargs}
        return dsrc.databunch(bs=bs, after_item=item_tfms, after_batch=batch_tfms, **kwargs)

    _docs = dict(datasource="Create a `Datasource` from `source` with `type_tfms`",
                 databunch="Create a `DataBunch` from `source` with `item_tfms` and `batch_tfms`")