#AUTOGENERATED! DO NOT EDIT! File to edit: dev/40_tabular_core.ipynb (unless otherwise specified).

__all__ = ['Tabular', 'TabularProc', 'Categorify', 'Normalize', 'FillStrategy', 'FillMissing', 'process_df',
           'TabularLine', 'TensorTabular', 'ReadTabLine', 'ReadTabTarget', 'ReadTabBatch']

from ..imports import *
from ..test import *
from ..core import *
from ..data.all import *
from ..notebook.showdoc import show_doc

pd.set_option('mode.chained_assignment','raise')

class Tabular(CollBase):
    def __init__(self, df, cat_names=None, cont_names=None, y_names=None, is_y_cat=True, splits=None):
        super().__init__(df)
        self.splits = L(ifnone(splits,[None]))
        self.cat_names,self.cont_names,self.y_names = L(cat_names),L(cont_names),y_names
        self.cat_y  = None if not is_y_cat else y_names
        self.cont_y = None if     is_y_cat else y_names

    def __setitem__(self,k,v): super().__setitem__(list(k) if isinstance(k,L) else k, v)
    def transform(self, cols, f): self[cols] = self[cols].transform(f)

    @property
    def loc(self): return self.items.loc
    @property
    def iloc(self): return self.items.iloc

    @property
    def all_cont_names(self): return self.cont_names + self.cont_y
    @property
    def all_cat_names (self): return self.cat_names  + self.cat_y
    @property
    def all_col_names (self): return self.all_cont_names + self.all_cat_names

def _add_prop(cls, nm):
    prop = property(lambda o: o.items[list(getattr(o,nm+'_names'))])
    setattr(cls, nm+'s', prop)
    def _f(o,v): o.items[list(getattr(o,nm+'_names'))] = v
    setattr(cls, nm+'s', prop.setter(_f))

_add_prop(Tabular, 'cat')
_add_prop(Tabular, 'all_cat')
_add_prop(Tabular, 'cont')
_add_prop(Tabular, 'all_cont')
_add_prop(Tabular, 'all_col')

class TabularProc(Transform):
    "Base class to write a tabular processor for dataframes"
    process = NotImplemented
    def encodes(self, to, **kwargs):
        self.process(to)
        return to

class Categorify(TabularProc, CollBase):
    "Transform the categorical variables to that type."
    order = 1
    def setup(self, to):
        to.classes = self.items = {n:CategoryMap(to.loc[ifnone(to.splits[0], slice(None)),n])
                                   for n in to.all_cat_names}

    def _apply_cats(self, c): return c.cat.codes+1 if is_categorical_dtype(c) else c.map(self[c.name].o2i)
    def process(self, to): to.transform(to.all_cat_names, self._apply_cats)

    def decodes(self, to):
        cats = [self[c][v] for v,c in zip(to.items[0], to.cat_names)]
        to.items = (cats, to.items[1])
        return to

class Normalize(TabularProc):
    "Normalize the continuous variables."
    order = 2
    def setup(self, to):
        df = to.loc[ifnone(to.splits[0],slice(None)), to.cont_names]
        self.means,self.stds = df.mean(),df.std(ddof=0)

    def process(self, to): to.conts = (to.conts-self.means) / (self.stds+1e-7)

    def decodes(self, to):
        conts = [(v*self.stds[c] + self.means[c]).item() for v,c in zip(to.items[1], to.cont_names)]
        to.items = (to.items[0], conts)
        return to

class FillStrategy:
    "Namespace containing the various filling strategies."
    def median  (c,fill): return c.median()
    def constant(c,fill): return fill
    def mode    (c,fill): return c.dropna().value_counts().idxmax()

class FillMissing(TabularProc):
    "Fill the missing values in continuous columns."
    def __init__(self, fill_strategy=FillStrategy.median, add_col=True, fill_vals=None):
        if fill_vals is None: fill_vals = defaultdict(int)
        store_attr(self, 'fill_strategy,add_col,fill_vals')

    def setup(self, to):
        df = to.loc[ifnone(to.splits[0],slice(None)), to.cont_names]
        self.na_dict = {n:self.fill_strategy(df[n], self.fill_vals[n])
                        for n in pd.isnull(to.conts).any().keys()}

    def process(self, to):
        missing = pd.isnull(to.conts)
        for n in missing.any().keys():
            assert n in self.na_dict, f"nan values in `{n}` but not in setup training set"
            to[n].fillna(self.na_dict[n], inplace=True)
            if self.add_col:
                to[n+'_na'] = missing[n]
                if n+'_na' not in to.cat_names: to.cat_names.append(n+'_na')

@delegates(Tabular)
def process_df(df, procs, inplace=True, **kwargs):
    "Process `df` with `procs` and returns the processed dataframe and the `TabularProcessor` associated"
    to = Tabular(df if inplace else df.copy(), **kwargs)
    proc = Pipeline(procs)
    proc.setup(to)
    return to,proc

class TabularLine(pd.Series):
    "A line of a dataframe that knows how to show itself"
    def show(self, ctx=None, **kwargs): return self if ctx is None else ctx.append(self)

class TensorTabular(tuple):
    def get_ctxs(self, max_n=10, **kwargs):
        n_samples = min(self[0].shape[0], max_n)
        df = pd.DataFrame(index = range(n_samples))
        return [df.iloc[i] for i in range(n_samples)]

    def display(self, ctxs): display_df(pd.DataFrame(ctxs))

class ReadTabLine(ItemTransform):
    def __init__(self, proc): self.proc = proc

    def encodes(self, row):
        cats,conts = (o.mapped(row.__getitem__) for o in (self.proc.cat_names,self.proc.cont_names))
        return TensorTabular((tensor(cats).long(),tensor(conts).float()))

    def decodes(self, o) -> TabularLine:
        to = Tabular(o, self.proc.cat_names, self.proc.cont_names, self.proc.y_names)
        to = self.proc.decode(to)
        return pd.Series({c: v for v,c in zip(to.items[0]+to.items[1], self.proc.cat_names+self.proc.cont_names)})

class ReadTabTarget(ItemTransform):
    def __init__(self, proc): self.proc = proc
    def encodes(self, row): return row[self.proc.y_names].astype(np.int64)
    def decodes(self, o) -> Category: return self.proc.classes[self.proc.y_names][o]

class ReadTabBatch(ItemTransform):
    def __init__(self, proc): self.proc = proc

    def encodes(self, df):
        cats,conts,targ = (df[o] for o in (self.proc.cat_names,self.proc.cont_names,self.proc.y_names))
        return (TensorTabular((tensor(cats.values).long(),tensor(conts.values).float())), tensor(targ.values).long())

    #def decodes(self, o) -> TabularLine:
    #    to = Tabular(o, self.proc.cat_names, self.proc.cont_names, self.proc.y_names)
    #    to = self.proc.decode(to)
    #    return pd.Series({c: v for v,c in zip(to.items[0]+to.items[1], self.proc.cat_names+self.proc.cont_names)})