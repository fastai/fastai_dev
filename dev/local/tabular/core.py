#AUTOGENERATED! DO NOT EDIT! File to edit: dev/40_tabular_core.ipynb (unless otherwise specified).

__all__ = ['Tabular', 'TabularProc', 'Categorify', 'Normalize', 'FillStrategy', 'FillMissing', 'process_df',
           'ReadTabBatch', 'TabDataLoader', 'Tabular', 'TabularProc', 'Categorify', 'Normalize', 'FillStrategy',
           'FillMissing', 'process_df', 'ReadTabBatch', 'TabDataLoader']

#Cell
from ..torch_basics import *
from ..test import *
from ..core import *
from ..data.all import *
from ..notebook.showdoc import show_doc

#Cell
pd.set_option('mode.chained_assignment','raise')

#Cell
class Tabular(CollBase):
    def __init__(self, df, cat_names=None, cont_names=None, y_names=None, is_y_cat=True, splits=None):
        super().__init__(df)
        self.splits = L(ifnone(splits,slice(None)))
        store_attr(self, 'y_names,is_y_cat')
        self.cat_names,self.cont_names = L(cat_names),L(cont_names)
        self.cat_y  = None if not is_y_cat else y_names
        self.cont_y = None if     is_y_cat else y_names

    def _new(self, df):
        return Tabular(df, self.cat_names, self.cont_names, y_names=self.y_names, is_y_cat=self.is_y_cat, splits=self.splits)

    def set_col(self,k,v): super().__setitem__(k, v)
    def transform(self, cols, f): self.set_col(cols, self.loc[:,cols].transform(f))
    def show(self, max_n=10, **kwargs): display_df(self.all_cols[:max_n])
    def __getitem__(self, idxs): return self._new(self.items.iloc[idxs])
    def __getattr__(self,k):
        if k.startswith('_') or k=='items': raise AttributeError
        return getattr(self.items,k)

    @property
    def __array__(self): return self.items.__array__
    @property
    def iloc(self): return self
    @property
    def loc(self): return self.items.loc

    @property
    def targ(self): return self.loc[:,self.y_names]
    @property
    def all_cont_names(self): return self.cont_names + self.cont_y
    @property
    def all_cat_names (self): return self.cat_names  + self.cat_y
    @property
    def all_col_names (self): return self.all_cont_names + self.all_cat_names

#Cell
def _add_prop(cls, nm):
    prop = property(lambda o: o.items[list(getattr(o,nm+'_names'))])
    setattr(cls, nm+'s', prop)
    def _f(o,v): o.set_col(getattr(o,nm+'_names'), v)
    setattr(cls, nm+'s', prop.setter(_f))

_add_prop(Tabular, 'cat')
_add_prop(Tabular, 'all_cat')
_add_prop(Tabular, 'cont')
_add_prop(Tabular, 'all_cont')
_add_prop(Tabular, 'all_col')

#Cell
class TabularProc(InplaceTransform):
    "Base class to write a tabular processor for dataframes"
    def process(self, *args,**kwargs): return self(*args,**kwargs)

#Cell
class Categorify(TabularProc, CollBase):
    "Transform the categorical variables to that type."
    order = 1
    def setup(self, to):
        to.classes = self.items = {n:CategoryMap(to.loc[to.splits[0],n], add_na=True)
                                   for n in to.all_cat_names}

    def _apply_cats(self, c): return c.cat.codes+1 if is_categorical_dtype(c) else c.map(self[c.name].o2i)
    def encodes(self, to): to.transform(to.all_cat_names, self._apply_cats)
    def _decode_cats(self, c): return c.map(dict(enumerate(self[c.name].items)))
    def decodes(self, to): to.transform(to.all_cat_names, self._decode_cats)

#Cell
class Normalize(TabularProc):
    "Normalize the continuous variables."
    order = 2
    def setup(self, to):
        df = to.loc[to.splits[0], to.cont_names]
        self.means,self.stds = df.mean(),df.std(ddof=0)+1e-7

    def encodes(self, to): to.conts = (to.conts-self.means) / self.stds
    def decodes(self, to): to.conts = (to.conts*self.stds ) + self.means

#Cell
class FillStrategy:
    "Namespace containing the various filling strategies."
    def median  (c,fill): return c.median()
    def constant(c,fill): return fill
    def mode    (c,fill): return c.dropna().value_counts().idxmax()

#Cell
class FillMissing(TabularProc):
    "Fill the missing values in continuous columns."
    def __init__(self, fill_strategy=FillStrategy.median, add_col=True, fill_vals=None):
        if fill_vals is None: fill_vals = defaultdict(int)
        store_attr(self, 'fill_strategy,add_col,fill_vals')

    def setup(self, to):
        df = to.loc[to.splits[0], to.cont_names]
        self.na_dict = {n:self.fill_strategy(df[n], self.fill_vals[n])
                        for n in pd.isnull(to.conts).any().keys()}

    def encodes(self, to):
        missing = pd.isnull(to.conts)
        for n in missing.any().keys():
            assert n in self.na_dict, f"nan values in `{n}` but not in setup training set"
            to.loc[:,n].fillna(self.na_dict[n], inplace=True)
            if self.add_col:
                to.loc[:,n+'_na'] = missing[n]
                if n+'_na' not in to.cat_names: to.cat_names.append(n+'_na')

#Cell
@delegates(Tabular)
def process_df(df, procs, inplace=True, **kwargs):
    "Process `df` with `procs` and returns the processed dataframe and the `TabularProcessor` associated"
    to = Tabular(df if inplace else df.copy(), **kwargs)
    proc = Pipeline(procs)
    proc.setup(to)
    return to,proc

#Cell
class ReadTabBatch(ItemTransform):
    def __init__(self, proc): self.proc = proc

    def encodes(self, to):
        return (tensor(to.cats.values).long(),tensor(to.conts.values).float()), tensor(to.targ.values).long()

    def decodes(self, o):
        (cats,conts),targs = to_np(o)
        df = pd.DataFrame({**{c: cats [:,i] for i,c in enumerate(self.proc.cat_names )},
                           **{c: conts[:,i] for i,c in enumerate(self.proc.cont_names)},
                           self.proc.y_names: targs})
        to = Tabular(df, self.proc.cat_names, self.proc.cont_names, self.proc.y_names, is_y_cat=self.proc.cat_y is not None)
        to = self.proc.decode(to)
        return to

#Cell
@delegates()
class TabDataLoader(TfmdDL):
    do_item = noops
    def __init__(self, dataset, proc, bs=16, shuffle=False, after_batch=None, num_workers=0, **kwargs):
        after_batch = L(after_batch)+ReadTabBatch(proc)
        super().__init__(dataset, bs=bs, shuffle=shuffle, after_batch=after_batch, num_workers=num_workers, **kwargs)

    def create_batch(self, b): return self.dataset.items[b]