{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from local.imports import *\n",
    "from local.test import *\n",
    "from local.core import *\n",
    "from local.data.core import *\n",
    "from local.data.transform import *\n",
    "from local.data.pipeline import *\n",
    "from local.notebook.showdoc import show_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data source\n",
    "> Base container for all the items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export core\n",
    "def all_union(sets):\n",
    "    \"Set of union of all `sets` (each `setified` if needed)\"\n",
    "    return set().union(*(map(setify,sets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sets = [[1,2],[2,3]]\n",
    "test_eq(all_union(sets), {1,2,3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export core\n",
    "def all_disjoint(sets):\n",
    "    \"`True` iif no element appears in more than one item of `sets`\"\n",
    "    return sum(map(len,sets))==len(all_union(sets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not all_disjoint(sets)\n",
    "assert all_disjoint([[1,2],[3,4]])\n",
    "assert all_disjoint([[1,2],[]])\n",
    "assert all_disjoint([[1,2]])\n",
    "assert all_disjoint([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataSource -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _mk_subset(self, i):\n",
    "    tfms = [o.tfms for o in self.tls]\n",
    "    return TfmdDS(L._gets(self, self.filts[i]), tfms=tfms, do_setup=False, filt=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class _FiltTfmdList(TfmdList):\n",
    "    \"Like `TfmdList` but with filters and train/valid attribute, for proper setup\"\n",
    "    def __init__(self, dsrc, tfms, do_setup=True):\n",
    "        self.filt_idx = dsrc.filt_idx\n",
    "        super().__init__(dsrc.items, tfms, do_setup=do_setup, as_item=True, filt=None)\n",
    "\n",
    "    def subset(self, i): return _mk_subset(self, i)\n",
    "    def _get(self, i):\n",
    "        self.filt = self.filt_idx[i]\n",
    "        return super()._get(i)\n",
    "\n",
    "_FiltTfmdList.train,_FiltTfmdList.valid = add_props(lambda i,x: x.subset(i), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DataSource(TfmdDS):\n",
    "    \"Applies a `tfm` to filtered subsets of `items`\"\n",
    "    def __init__(self, items, tfms=None, filts=None, do_setup=True):\n",
    "        super(TfmdDS,self).__init__(items, use_list=None)\n",
    "        if filts is None: filts = [range_of(items)]\n",
    "        self.filts = L(mask2idxs(filt) for filt in filts)\n",
    "        \n",
    "        # Create map from item id to filter id\n",
    "        assert all_disjoint(self.filts)\n",
    "        self.filt_idx = L([None]*len(self.items))\n",
    "        for i,f in enumerate(self.filts): self.filt_idx[f] = i\n",
    "        self.tls = [_FiltTfmdList(self, t, do_setup=do_setup) for t in L(tfms)]\n",
    "\n",
    "    def __repr__(self): return '\\n'.join(map(str,self.subsets())) + f'\\ntls - {self.tls}'\n",
    "    def subsets(self): return map(self.subset, range_of(self.filts))\n",
    "    def subset(self, i): return _mk_subset(self, i)\n",
    "    def _get(self, i):\n",
    "        self.filt = self.filt_idx[i]\n",
    "        return super()._get(i)\n",
    "    \n",
    "    @delegates(TfmdDL.__init__)\n",
    "    def databunch(self, bs=16, val_bs=None, shuffle_train=True, **kwargs):\n",
    "        n = len(self.filts)-1\n",
    "        bss = [bs] + [2*bs]*n if val_bs is None else [bs] + [val_bs]*n\n",
    "        shuffles = [shuffle_train] + [False]*n\n",
    "        return DataBunch(*[TfmdDL(self.subset(i), bs=b, shuffle=s, drop_last=s, **kwargs)\n",
    "                           for i,(b,s) in enumerate(zip(bss, shuffles))])\n",
    "    \n",
    "DataSource.train,DataSource.valid = add_props(lambda i,x: x.subset(i), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_docs(DataSource,\n",
    "         subset=\"Filtered `DsrcSubset` `i`\",\n",
    "         subsets=\"Iterator for all subsets\",\n",
    "         databunch=\"Create a `DataBunch`\",\n",
    "         show=\"Show item `o` in `ctx`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A `DataSource` provides filtering and transformation capabilities to a list of items. Although it has all the attributes of `PipedList` (since it's a subclass) they are mainly used internally; you will generally want to instead access its `subset`s.\n",
    "\n",
    "If you don't pass any filters or transforms, it simply provides a single subset (of type `DsrcSubset`) with the same behavior as a `L`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = [0,1,2,3,4]\n",
    "dsrc = DataSource(inp, tfms=[None])\n",
    "\n",
    "test_eq(len(dsrc.filts), 1)\n",
    "test_eq(*dsrc[2], 2)          # Retrieve one item (subset 0 is the default)\n",
    "test_eq(dsrc[1,2], [(1,),(2,)])    # Retrieve two items by index\n",
    "mask = [True,False,False,True,False]\n",
    "test_eq(dsrc[mask], [(0,),(3,)])   # Retrieve two items by mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = pd.DataFrame(dict(a=[5,1,2,3,4]))\n",
    "dsrc = DataSource(inp, tfms=itemgetter(0)).subset(0)\n",
    "test_eq(*dsrc[2], (2,))          # Retrieve one item (subset 0 is the default)\n",
    "test_eq(dsrc[1,2], [(1,),(2,)])    # Retrieve two items by index\n",
    "mask = [True,False,False,True,False]\n",
    "test_eq(dsrc[mask], [(5,),(3,)])   # Retrieve two items by mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing `filts` to the `DataSource` constructor allows you to create multiple subsets, each of type `DsrcSubset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [(0,),(2,)]\n",
       "(#3) [(1,),(3,),(4,)]\n",
       "tls - [_FiltTfmdList: [0, 1, 2, 3, 4]\n",
       "tfms - [Transform: True {'object': 'noop'} {}]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filts can be indices\n",
    "dsrc = DataSource(range(5), tfms=[None], filts=[tensor([0,2]), [1,3,4]])\n",
    "\n",
    "test_eq(len(dsrc.filts), 2)\n",
    "test_eq(dsrc.subset(0), [(0,),(2,)])\n",
    "test_eq(dsrc.train, [(0,),(2,)])       # Subset 0 is aliased to `train`\n",
    "test_eq(dsrc.subset(1), [(1,),(3,),(4,)])\n",
    "test_eq(dsrc.valid, [(1,),(3,),(4,)])     # Subset 1 is aliased to `valid`\n",
    "test_eq(*dsrc.valid[2], 4)\n",
    "assert '[(1,),(3,),(4,)]' in str(dsrc) and '[(0,),(2,)]' in str(dsrc)\n",
    "dsrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.train.filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filts can be boolean masks (they don't have to cover all items, but must be disjoint)\n",
    "filts = [[False,True,True,False,True], [True,False,False,False,False]]\n",
    "dsrc = DataSource(range(5), tfms=[None], filts=filts)\n",
    "\n",
    "test_eq(dsrc.train, [(1,),(2,),(4,)])\n",
    "test_eq(dsrc.valid, [(0,)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass `tfms` to have transformations applied before returning items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply transforms to all items\n",
    "tfm = [[lambda x: x*2,lambda x: x+1]]\n",
    "filts = [[1,2],[0,3,4]]\n",
    "dsrc = DataSource(range(5), tfm, filts=filts)\n",
    "test_eq(dsrc.train,[(3,),(5,)])\n",
    "test_eq(dsrc.valid,[(1,),(7,),(9,)])\n",
    "test_eq(dsrc.train[False,True], [(5,)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subset index is also passed to your transform, so if it is an instance of `Transform` it will only be applied if the filt idx matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only transform subset 1\n",
    "class _Tfm(Transform):\n",
    "    filt=1\n",
    "    def encodes(self, x)     : return x*2\n",
    "    def decodes(self, x)->Str: return x//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [(1,),(2,)]\n",
       "(#3) [(0,),(6,),(8,)]\n",
       "tls - [_FiltTfmdList: [0, 1, 2, 3, 4]\n",
       "tfms - [_Tfm: True {'object': 'encodes'} {'object': 'decodes'}]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc = DataSource(range(5), [_Tfm()], filts=[[1,2],[0,3,4]])\n",
    "test_eq(dsrc.train,[(1,),(2,)])\n",
    "test_eq(dsrc.valid,[(0,),(6,),(8,)])\n",
    "test_eq(dsrc.train[False,True], [(2,)])\n",
    "dsrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Test setup works with train attribute\n",
    "def _lbl(o): return o.split('_')[0]\n",
    "\n",
    "test_fns = ['dog_0.jpg','cat_0.jpg','cat_2.jpg','cat_1.jpg','dog_1.jpg']\n",
    "tcat = Categorize()\n",
    "dsrc = DataSource(test_fns, [[tcat,_lbl]], filts=[[1,2,4], [0,3]])\n",
    "test_eq(tcat.vocab, ['cat','dog'])\n",
    "test_eq(dsrc.train, [(0,),(0,),(1,)])\n",
    "test_eq(dsrc.valid, [(1,),(0,)])\n",
    "test_stdout(lambda: dsrc.train.show_at(0), \"cat\")\n",
    "#test_eq(dsrc.vocab, ['cat','dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#Test DataSource pickles\n",
    "dsrc1 = pickle.loads(pickle.dumps(dsrc))\n",
    "test_eq(dsrc.train, dsrc1.train)\n",
    "test_eq(dsrc.valid, dsrc1.valid)\n",
    "#test_eq(dsrc1.vocab, ['cat','dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsrc = DataSource(range(5), [_Tfm(),noop], filts=[[1,2],[0,3,4]])\n",
    "test_eq(dsrc.train,[(1,1),(2,2)])\n",
    "test_eq(dsrc.valid,[(0,0),(6,3),(8,4)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `DataSource` Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You won't need to use many methods of `DataSource`, since normally you'll be accessing subsets, and therefore will be using `DsrcSubset` methods. However there are a few `DataSource` methods that may be useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>DataSource.databunch</code>\" class=\"doc_header\"><code>DataSource.databunch</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/06_data_source.ipynb#DataSource--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DataSource.databunch</code>(**`bs`**=*`16`*, **`val_bs`**=*`None`*, **`shuffle_train`**=*`True`*, **`shuffle`**=*`False`*, **`drop_last`**=*`False`*, **`indexed`**=*`None`*, **`num_workers`**=*`0`*, **`pin_memory`**=*`False`*, **`timeout`**=*`0`*, **`wif`**=*`None`*, **`before_iter`**=*`None`*, **`create_batches`**=*`None`*, **`sampler`**=*`None`*, **`create_item`**=*`None`*, **`after_item`**=*`None`*, **`before_batch`**=*`None`*, **`create_batch`**=*`None`*, **`retain`**=*`None`*, **`after_batch`**=*`None`*, **`after_iter`**=*`None`*)\n",
       "\n",
       "Create a [`DataBunch`](/data.core.html#DataBunch)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataSource.databunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>DataSource.subset</code>\" class=\"doc_header\"><code>DataSource.subset</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/06_data_source.ipynb#DataSource--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DataSource.subset</code>(**`i`**)\n",
       "\n",
       "Filtered `DsrcSubset` `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataSource.subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset 0 is aliased to the `train` property, and subset 1 is aliased to the `valid` property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [(0, 0),(6, 3),(8, 4)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsrc.subset(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"<code>DataSource.subsets</code>\" class=\"doc_header\"><code>DataSource.subsets</code><a href=\"https://nbviewer.jupyter.org/github/fastai/fastai_docs/blob/master/dev/06_data_source.ipynb#DataSource--\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>DataSource.subsets</code>()\n",
       "\n",
       "Iterator for all subsets"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(DataSource.subsets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_test.ipynb.\n",
      "Converted 01_core.ipynb.\n",
      "Converted 01a_dataloader.ipynb.\n",
      "Converted 01a_script.ipynb.\n",
      "Converted 02_transforms.ipynb.\n",
      "Converted 03_pipeline.ipynb.\n",
      "Converted 04_data_external.ipynb.\n",
      "Converted 05_data_core.ipynb.\n",
      "Converted 06_data_source.ipynb.\n",
      "Converted 07_vision_core.ipynb.\n",
      "Converted 08_pets_tutorial.ipynb.\n",
      "Converted 09_vision_augment.ipynb.\n",
      "Converted 11_layers.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_learner.ipynb.\n",
      "Converted 14_callback_schedule.ipynb.\n",
      "Converted 15_callback_hook.ipynb.\n",
      "Converted 16_callback_progress.ipynb.\n",
      "Converted 17_callback_tracker.ipynb.\n",
      "Converted 18_callback_fp16.ipynb.\n",
      "Converted 19_callback_mixup.ipynb.\n",
      "Converted 20_metrics.ipynb.\n",
      "Converted 21_tutorial_imagenette.ipynb.\n",
      "Converted 30_text_core.ipynb.\n",
      "Converted 31_text_data.ipynb.\n",
      "Converted 32_text_models_awdlstm.ipynb.\n",
      "Converted 33_test_models_core.ipynb.\n",
      "Converted 34_callback_rnn.ipynb.\n",
      "Converted 35_tutorial_wikitext.ipynb.\n",
      "Converted 36_text_models_qrnn.ipynb.\n",
      "Converted 40_tabular_core.ipynb.\n",
      "Converted 41_tabular_model.ipynb.\n",
      "Converted 50_data_block.ipynb.\n",
      "Converted 60_vision_models_xresnet.ipynb.\n",
      "Converted 90_notebook_core.ipynb.\n",
      "Converted 91_notebook_export.ipynb.\n",
      "Converted 92_notebook_showdoc.ipynb.\n",
      "Converted 93_notebook_export2html.ipynb.\n",
      "Converted 94_index.ipynb.\n",
      "Converted 95_synth_learner.ipynb.\n",
      "Converted notebook2jekyll.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from local.notebook.export import notebook2script\n",
    "notebook2script(all_fs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
