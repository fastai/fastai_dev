{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from fastai.datasets import URLs, untar_data\n",
    "from pathlib import Path\n",
    "import torch, re, PIL, os, mimetypes, csv\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from typing import *\n",
    "import pandas as pd, numpy as np\n",
    "from enum import Enum\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data block API from config class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noop(x): return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def listify(o):\n",
    "    if o is None: return []\n",
    "    if isinstance(o, list): return o\n",
    "    if isinstance(o, str): return [o]\n",
    "    if isinstance(o, Iterable): return list(o)\n",
    "    return [o]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def compose(x, funcs, *args, order_key='_order', **kwargs):\n",
    "    key = lambda o: getattr(o, order_key, 0)\n",
    "    for f in sorted(listify(funcs), key=key): x = f(x, **kwargs)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def uniqueify(x, sort=False):\n",
    "    res = list(OrderedDict.fromkeys(x).keys())\n",
    "    if sort: res.sort()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def setify(o): return o if isinstance(o,set) else set(listify(o))\n",
    "\n",
    "def _get_files(p, fs, extensions=None):\n",
    "    p = Path(p)\n",
    "    res = [p/f for f in fs if not f.startswith('.')\n",
    "           and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n",
    "    return res\n",
    "\n",
    "def get_files(path, extensions=None, recurse=False, include=None):\n",
    "    path = Path(path)\n",
    "    extensions = setify(extensions)\n",
    "    extensions = {e.lower() for e in extensions}\n",
    "    if recurse:\n",
    "        res = []\n",
    "        for i,(p,d,f) in enumerate(os.walk(path)): # returns (dirpath, dirnames, filenames)\n",
    "            if include is not None and i==0: d[:] = [o for o in d if o in include]\n",
    "            else:                            d[:] = [o for o in d if not o.startswith('.')]\n",
    "            res += _get_files(p, f, extensions)\n",
    "        return res\n",
    "    else:\n",
    "        f = [o.name for o in os.scandir(path) if o.is_file()]\n",
    "        return _get_files(path, f, extensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processor and ItemGetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Processor():\n",
    "    def __call__(self, items):  return items\n",
    "    def process1(self, item):   return item\n",
    "    def deprocess1(self, item): return item\n",
    "    def deprocess(self, items): return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ItemGetter():\n",
    "    _default_proc = None\n",
    "    def __init__(self, procs=None): \n",
    "        self.procs = [p() for p in listify(self._default_proc)] if procs is None else procs\n",
    "    def __call__(self, items): return compose(items, self.procs)\n",
    "    \n",
    "    def get(self, o): return o  #How to get the actual item from o (example: fn -> Image, idxs -> 1hot encoded tensor)\n",
    "    def raw(self, o): return o  #Undoes get when needed for representation (1hot encoded tensor -> idxs)\n",
    "    \n",
    "    def show(self, x, ax):                       raise NotImplementedError #How to show one element\n",
    "    def show_xys(self, xs, ys, y_get, **kwargs): raise NotImplementedError #How to show a bunch of xs and ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data block API core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One ItemList to contain them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ItemList():\n",
    "    def __init__(self, items, item_get=None):\n",
    "        self.item_get = ItemGetter() if item_get is None else item_get\n",
    "        self.items = self.item_get(listify(items))\n",
    "    def _get(self, i): return self.item_get.get(i)\n",
    "    def __getitem__(self, idx):\n",
    "        try: return self._get(self.items[idx])\n",
    "        except TypeError:\n",
    "            if isinstance(idx[0],bool):\n",
    "                assert len(idx)==len(self) # bool mask\n",
    "                return [self._get(o) for m,o in zip(idx,self.items) if m]\n",
    "            return [self._get(self.items[i]) for i in idx]\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __iter__(self): return iter(self.items)\n",
    "    def __setitem__(self, i, o): self.items[i] = o\n",
    "    def __delitem__(self, i): del(self.items[i])\n",
    "    def __repr__(self):\n",
    "        res = f'{self.__class__.__name__} ({len(self)} items)\\n{self.items[:10]}'\n",
    "        if len(self)>10: res = res[:-1]+ '...]'\n",
    "        return res\n",
    "    \n",
    "    def deproc(self, item):\n",
    "        item = self.item_get.raw(item)\n",
    "        for proc in reversed(listify(self.item_get.procs)):\n",
    "            item = proc.deproc1(item)\n",
    "        return item\n",
    "    \n",
    "    def obj(self, idx):\n",
    "        isint = isinstance(idx, int) or (isinstance(idx,torch.LongTensor) and not idx.ndim)\n",
    "        item = self[idx]\n",
    "        return self.deproc(item) if isint else [self.deprocess(o) for o in item]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LabeledData is just a convenience wrapper other xs and ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "TfmY = Enum('TfmY', 'No Mask Image Point Bbox')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddXContext():\n",
    "    def __init__(self, il,x): self.il,self.x = il,x \n",
    "    def __enter__(self, *args):\n",
    "        self.il.item_get._x = self.x\n",
    "        return self.il\n",
    "    def __exit__(self, *args): self.il.item_get._x = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class LabeledData():\n",
    "    def __init__(self, x, y, tfms=None, tfm_y=TfmY.No):  \n",
    "        self.x,self.y,self.tfms,self.tfm_y = x,y,tfms,tfm_y\n",
    "    def __repr__(self):        return f'{self.__class__.__name__}\\nx: {self.x}\\ny: {self.y}\\n'\n",
    "    def __getitem__(self,idx):\n",
    "        #TODO? Make below works if idx is a mask/array/list\n",
    "        x = self.x[idx]\n",
    "        with AddXContext(self.y, x) as yil: y = yil[idx] \n",
    "        return compose((x,y), self.tfms, tfm_y=self.tfm_y)\n",
    "    def __len__(self):         return len(self.x)\n",
    "    \n",
    "    def deproc(self, o):\n",
    "        x = self.x.deproc(o[0])\n",
    "        with AddXContext(self.y, x) as yil: y = yil.deproc(o[1])\n",
    "        return (x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataloader and DataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "def get_dl(ds, bs, shuffle=False, drop_last=False, **kwargs):\n",
    "    return DataLoader(ds, batch_size=bs, shuffle=shuffle, drop_last=drop_last, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DataBunch():\n",
    "    def __init__(self, train_dl, valid_dl):\n",
    "        self.train_dl,self.valid_dl = train_dl,valid_dl\n",
    "        \n",
    "    @property\n",
    "    def train_ds(self): return self.train_dl.dataset\n",
    "    @property\n",
    "    def valid_ds(self): return self.valid_dl.dataset\n",
    "    \n",
    "    def show_batch(self, is_valid=False, items=9, **kwargs):\n",
    "        xb,yb = next(iter(self.valid_dl if is_valid else self.train_dl))\n",
    "        xs,ys = [],[]\n",
    "        for i in range(items):\n",
    "            x,y = self.train_ds.deproc((xb[i], yb[i]))\n",
    "            xs.append(x); ys.append(y)\n",
    "        self.train_ds.x.item_get.show_xys(xs, ys, self.train_ds.y.item_get, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main class to represent any kind of data. User provides the `get_x_cls` and `get_y_cls` then the four functions. At init everything is constructed with optionals transforms or custom instances of `get_x`/`get_y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DataBlock():\n",
    "    get_x_cls = ItemGetter\n",
    "    get_y_cls = ItemGetter\n",
    "    def get_source(self):         raise NotImplementedError\n",
    "    #Return the source of your data (path, dataframe...) and optionally download it\n",
    "    def get_items(self, source):  raise NotImplementedError\n",
    "    #Use source to return the list of all items\n",
    "    def split(self, items):       raise NotImplementedError\n",
    "    #Explain how so split the items. Return two list of integers or two boolean masks\n",
    "    def label(self, items):       raise NotImplementedError\n",
    "    #Explain how to label your items. Return a list of labels\n",
    "        \n",
    "    def __init__(self, tfms=None, tfm_y=TfmY.No, get_x=None, get_y=None):\n",
    "        self.source = self.get_source()\n",
    "        items = ItemList(self.get_items(self.source)) #Just for fancy indexing\n",
    "        split_idx = self.split(items)\n",
    "        labels = ItemList(self.label(items))\n",
    "        if get_x is None: get_x = self.get_x_cls()\n",
    "        if get_y is None: get_y = self.get_y_cls()\n",
    "        x_train,x_valid = map(lambda o: ItemList(items[o],  item_get=get_x), split_idx)\n",
    "        y_train,y_valid = map(lambda o: ItemList(labels[o], item_get=get_y), split_idx)\n",
    "        self.train = LabeledData(x_train, y_train, tfms=tfms, tfm_y=tfm_y)\n",
    "        self.valid = LabeledData(x_valid, y_valid, tfms=tfms, tfm_y=tfm_y)\n",
    "    \n",
    "    def databunch(self, bs=64, **kwargs):\n",
    "        dls = [get_dl(ds, bs, shuffle=s, drop_last=s, **kwargs) for (ds, s) in zip([self.train, self.valid], [True,False])]\n",
    "        return DataBunch(*dls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First ItemGetters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to get images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ImageGetter(ItemGetter):\n",
    "    def __init__(self, procs=None, cmap=None, alpha=1.): \n",
    "        super().__init__(procs)\n",
    "        self.cmap,self.alpha = cmap,alpha\n",
    "    def get(self, fn): return PIL.Image.open(fn)\n",
    "    def show(self, x, ax):\n",
    "        ax.imshow(x[0] if x.shape[0] == 1 else x.permute(1,2,0), cmap=self.cmap, alpha=self.alpha)\n",
    "        ax.axis('off')\n",
    "    def show_xys(self, xs, ys, y_get, cols=3, figsize=None):\n",
    "        rows = (len(xs) // cols if len(xs)%cols == 0 else len(xs)//cols+1) \n",
    "        if figsize is None: figsize = (cols*3, rows*3)\n",
    "        fig,axs = plt.subplots(rows, cols, figsize=figsize)\n",
    "        for x,y,ax in zip(xs, ys, axs.flatten()):\n",
    "            self.show(x, ax)\n",
    "            y_get.show(y, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to get categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class CategoryProcessor(Processor):\n",
    "    def __init__(self): self.vocab=None\n",
    "    \n",
    "    def __call__(self, items):\n",
    "        #The vocab is defined on the first use.\n",
    "        if self.vocab is None:\n",
    "            self.vocab = uniqueify(items)\n",
    "            self.otoi  = {v:k for k,v in enumerate(self.vocab)}\n",
    "        return [self.proc1(o) for o in items]\n",
    "    def proc1(self, item):  return self.otoi[item]\n",
    "    \n",
    "    def deprocess(self, idxs):\n",
    "        assert self.vocab is not None\n",
    "        return [self.deproc1(idx) for idx in idxs]\n",
    "    def deproc1(self, idx): return self.vocab[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class CategoryGetter(ItemGetter):\n",
    "    _default_proc = CategoryProcessor\n",
    "    def show(self, x, ax): ax.set_title(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "image_extensions = set(k for k,v in mimetypes.types_map.items() if v.startswith('image/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_image_files(path, include=None):\n",
    "    return get_files(path, extensions=image_extensions, recurse=True, include=include)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def random_splitter(items, valid_pct=0.2, seed=None): \n",
    "    if seed is not None: torch.manual_seed(seed)\n",
    "    rand_idx = torch.randperm(len(items))\n",
    "    cut = int(valid_pct * len(items))\n",
    "    return rand_idx[:cut],rand_idx[cut:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _grandparent_mask(items, name):\n",
    "    return [(o.parent.parent.name if isinstance(o, Path) else o.split(os.path.sep)[-2]) == name for o in items]\n",
    "\n",
    "def grandparent_splitter(items, train_name='train', valid_name='valid'):\n",
    "    return _grandparent_mask(items, train_name),_grandparent_mask(items, valid_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parent_labeller(items):\n",
    "    return [o.parent.name if isinstance(o, Path) else o.split(os.path.sep)[-1] for o in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def func_labeller(items, func):\n",
    "    return [func(o) for o in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def re_labeller(items, pat):\n",
    "    pat = re.compile(pat)\n",
    "    def _inner(o):\n",
    "        res = pat.search(str(o))\n",
    "        assert res,f'Failed to find \"{pat}\" in \"{s}\"'\n",
    "        return res.group(1)\n",
    "    return func_labeller(items, _inner)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PetsData(DataBlock):\n",
    "    get_x_cls = ImageGetter\n",
    "    get_y_cls = CategoryGetter\n",
    "    \n",
    "    def get_source(self):        return untar_data(URLs.PETS)\n",
    "    def get_items(self, source): return get_image_files(source/\"images\")\n",
    "    def split(self, items):      return random_splitter(items)\n",
    "    def label(self, items):      return re_labeller(items, pat = r'/([^/]+)_\\d+.jpg$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PetsData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img,cls = data.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train.y.obj(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Transform(): \n",
    "    _order=0\n",
    "    _tfm_y_func={TfmY.Image: 'apply_img',   TfmY.Mask: 'apply_mask', TfmY.No: 'noop',\n",
    "                 TfmY.Point: 'apply_point', TfmY.Bbox: 'apply_bbox'}\n",
    "    \n",
    "    def apply(self, x):       return x\n",
    "    def apply_img(self, y):   return self.apply(y)\n",
    "    def apply_mask(self, y):  return self.apply_img(y)\n",
    "    def apply_point(self, y): return y\n",
    "    def apply_bbox(self, y):  return self.apply_point(y)\n",
    "    \n",
    "    def randomize(self): pass\n",
    "    \n",
    "    def __call__(self, o, tfm_y=TfmY.No):\n",
    "        (x,y) = o\n",
    "        self.randomize() #Ensures we have the same state for x and y\n",
    "        self.x = x #Saves the x in case it's needed in the apply for y (x.size for apply_point for instance)\n",
    "        return self.apply(x),getattr(self, self._tfm_y_func[tfm_y], noop)(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecodeImg(Transform):\n",
    "    def __init__(self, mode_x='RGB', mode_y=None):\n",
    "        self.mode_x,self.mode_y = mode_x,mode_y\n",
    "        \n",
    "    def apply(self, x):       return x.convert(self.mode_x)\n",
    "    def apply_image(self, y): return y.convert(self.mode_x if self.mode_y is None else self.mode_y)\n",
    "    def apply_mask(self, y):  return y.convert('L' if self.mode_y is None else self.mode_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResizeFixed(Transform):\n",
    "    _order=10\n",
    "    def __init__(self, size, mode_x=PIL.Image.BILINEAR, mode_y=None):\n",
    "        if isinstance(size,int): size=(size,size)\n",
    "        size = (size[1],size[0]) #PIL takes size in the otherway round\n",
    "        self.size,self.mode_x,self.mode_y = size,mode_x,mode_y\n",
    "        \n",
    "    def apply(self, x):       return x.resize(self.size, self.mode_x)\n",
    "    def apply_image(self, y): return y.resize(self.size, self.mode_x if self.mode_y is None else self.mode_y)\n",
    "    def apply_mask(self, y):  return y.resize(self.size, PIL.Image.NEAREST if self.mode_y is None else self.mode_y)\n",
    "    def apply_point(self, y):\n",
    "        rsz = tensor([self.x.size[1]/self.size[0], self.x.size[0]/self.size[1]], device=y.device)\n",
    "        return y / rsz\n",
    "    def apply_bbox(self, y): return self.apply_point(y[0]),y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToByteTensor(Transform):\n",
    "    _order=20\n",
    "    \n",
    "    def apply(self, x):\n",
    "        res = torch.ByteTensor(torch.ByteStorage.from_buffer(x.tobytes()))\n",
    "        w,h = x.size\n",
    "        return res.view(h,w,-1).permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToFloatTensor(Transform):\n",
    "    _order=20\n",
    "    def __init__(self, div_x=255., div_y=None):\n",
    "        self.div_x,self.div_y = div_x,div_y\n",
    "    def apply(self, x):      return x.float().div_(self.div_x)\n",
    "    def apply_mask(self, x): \n",
    "        return x.long() if self.div_y is None else x.long().div_(self.div_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = [DecodeImg(), ResizeFixed(128), ToByteTensor(), ToFloatTensor()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PetsData(tfms=tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datab = data.databunch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datab.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(iter(datab.train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistData(DataBlock):\n",
    "    get_x_cls = ImageGetter\n",
    "    get_y_cls = CategoryGetter\n",
    "    \n",
    "    def get_source(self):        return untar_data(URLs.MNIST)\n",
    "    def get_items(self, source): return get_image_files(source)\n",
    "    def split(self, items):      return grandparent_splitter(items, train_name='training', valid_name='testing')\n",
    "    def label(self, items):      return parent_labeller(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MnistData(tfms=[ToByteTensor(), ToFloatTensor()]).databunch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train_ds.x.item_get.cmap='gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.PLANET_SAMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def onehot(x, c):\n",
    "    res = torch.zeros(c)\n",
    "    res[x] = 1.\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MultiCategoryProcessor(CategoryProcessor):\n",
    "    def __call__(self, items):\n",
    "        #The vocab is defined on the first use.\n",
    "        if self.vocab is None:\n",
    "            vocab = set()\n",
    "            for c in items: vocab = vocab.union(set(c))\n",
    "            self.vocab = list(vocab)\n",
    "            self.vocab.sort()\n",
    "            self.otoi  = {v:k for k,v in enumerate(self.vocab)}\n",
    "        return [self.proc1(o) for o in items]\n",
    "    def proc1(self, item):  return [self.otoi[o] for o in item if o in self.otoi]\n",
    "    \n",
    "    def deproc1(self, idx): return [self.vocab[i] for i in idx]\n",
    "\n",
    "class MultiCategoryGetter(ItemGetter):\n",
    "    _default_proc = MultiCategoryProcessor\n",
    "    \n",
    "    def get(self, o): return onehot(o, len(self.procs[0].vocab))\n",
    "    def raw(self, o): return [i for i,x in enumerate(o) if x == 1]\n",
    "    def show(self, x, ax): ax.set_title(';'.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def read_column(df, col_name, prefix='', suffix='', delim=None):\n",
    "    values = df[col_name].values.astype(str)\n",
    "    values = np.char.add(np.char.add(prefix, values), suffix)\n",
    "    if delim is not None:\n",
    "        values = np.array(list(csv.reader(values, delimiter=delim)))\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanetData(DataBlock):\n",
    "    get_x_cls = ImageGetter\n",
    "    get_y_cls = MultiCategoryGetter\n",
    "    \n",
    "    def get_source(self):        \n",
    "        self.path = untar_data(URLs.PLANET_SAMPLE)\n",
    "        return pd.read_csv(path/'labels.csv')\n",
    "    def get_items(self, source): return read_column(source, 'image_name', prefix=f'{self.path}/train/', suffix='.jpg')\n",
    "    def split(self, items):      return random_splitter(items)\n",
    "    def label(self, items):      return read_column(self.source, 'tags', delim=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = PlanetData(tfms=tfms).databunch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camvid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class SegmentMaskGetter(ImageGetter):\n",
    "    def __init__(self, procs=None, cmap='tab20', alpha=0.5): \n",
    "        super().__init__(procs, cmap=cmap, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamvidData(DataBlock):\n",
    "    get_x_cls = ImageGetter\n",
    "    get_y_cls = SegmentMaskGetter\n",
    "    \n",
    "    def get_source(self):        return untar_data(URLs.CAMVID_TINY)      \n",
    "    def get_items(self, source): return get_image_files(source/'images')\n",
    "    def split(self, items):      return random_splitter(items)\n",
    "    def label(self, items):      \n",
    "        path_lbl = self.source/'labels'\n",
    "        codes = np.loadtxt(self.source/'codes.txt', dtype=str)\n",
    "        return func_labeller(items, lambda x: path_lbl/f'{x.stem}_P{x.suffix}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CamvidData(tfms=tfms, tfm_y=TfmY.Mask).databunch(bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Biwii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class PointsGetter(ItemGetter):\n",
    "    def __init__(self, procs=None, do_scale=True, y_first=False): \n",
    "        super().__init__(procs)\n",
    "        self.do_scale,self.y_first = do_scale,y_first\n",
    "    \n",
    "    def get(self, o):\n",
    "        if not isinstance(o, torch.Tensor): o = tensor(o)\n",
    "        o = o.view(-1, 2).float()\n",
    "        if self.do_scale and hasattr(self, '_x') and self._x is not None: \n",
    "            sz = tensor([self._x.size[1], self._x.size[0]]).float()\n",
    "            o = o * 2/sz - 1\n",
    "        return o if self.y_first else o.flip(1)\n",
    "    \n",
    "    def raw(self, o):\n",
    "        if hasattr(self, '_x') and self._x is not None: \n",
    "            sz = tensor(self._x.shape[1:]).float()\n",
    "            o = (o + 1) * sz/2\n",
    "        return o\n",
    "    \n",
    "    def show(self, x, ax):\n",
    "        params = {'s': 10, 'marker': '.', 'c': 'r'}\n",
    "        ax.scatter(x[:, 0], x[:, 1], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.BIWI_SAMPLE)\n",
    "fnames = get_image_files(path/'images')\n",
    "fn2ctr = pickle.load(open(path/'centers.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn2ctr[fnames[0].name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResizeFixed(Transform):\n",
    "    _order=10\n",
    "    def __init__(self, size, mode_x=PIL.Image.BILINEAR, mode_y=None):\n",
    "        if isinstance(size,int): size=(size,size)\n",
    "        size = (size[1],size[0]) #PIL takes size in the otherway round\n",
    "        self.size,self.mode_x,self.mode_y = size,mode_x,mode_y\n",
    "        \n",
    "    def apply(self, x):       return x.resize(self.size, self.mode_x)\n",
    "    def apply_image(self, y): return y.resize(self.size, self.mode_x if self.mode_y is None else self.mode_y)\n",
    "    def apply_mask(self, y):  return y.resize(self.size, PIL.Image.NEAREST if self.mode_y is None else self.mode_y)\n",
    "    def apply_point(self, y):\n",
    "        rsz = tensor([self.x.size[1]/self.size[1], self.x.size[0]/self.size[0]], device=y.device)\n",
    "        return (y+1) * rsz - 1\n",
    "    def apply_bbox(self, y): return self.apply_point(y[0]),y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiwiData(DataBlock):\n",
    "    get_x_cls = ImageGetter\n",
    "    get_y_cls = PointsGetter\n",
    "    \n",
    "    def get_source(self):        return untar_data(URLs.BIWI_SAMPLE)      \n",
    "    def get_items(self, source): return get_image_files(source/'images')\n",
    "    def split(self, items):      return random_splitter(items)\n",
    "    def label(self, items):      \n",
    "        fn2ctr = pickle.load(open(self.source/'centers.pkl', 'rb'))\n",
    "        return func_labeller(items, lambda o:fn2ctr[o.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = BiwiData(tfms=[DecodeImg(), ResizeFixed(128), ToByteTensor(), ToFloatTensor()], tfm_y=TfmY.Point).databunch(bs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train_ds.x[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.train_ds.y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python notebook2script.py \"200_datablock_config.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
