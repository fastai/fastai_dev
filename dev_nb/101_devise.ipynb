{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.docs import *\n",
    "from fastai.text import *\n",
    "torch.backends.cudnn.benchmark=True\n",
    "import json\n",
    "\n",
    "import fastText as ft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeVise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this class, we will implement the [DeVise paper](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41473.pdf). What makes this paper specially interesting is that it combines image classification and text embeddings. The technique presented by the authors leverages word embeddings to assign several possible tags to each image. By doing this, the model fares considerably well (achieving up to 18% hit rates) in never seen before categories (zero-shot learning). But how can the model classify objects it has never seen before? That is the power of word embeddings.\n",
    "\n",
    "Basically, the model will use the 'closeness' of several words it knows through the embeddings to classify a new image. Perhaps this is easiest explained through a human example. When we are teaching a toddler what a motorcycle is, for example, we might say \"Well, it is a bicycle but it goes faster\". That is we relate it to what *he/she already knows*. In the same way, if the model sees a trout, it might say \"Well, I know it is very similar to a trench and I know what a trench is so I will say it is either a trench or something very similar, like a sea bass or a trout\". In 2D these relationships would look like this:\n",
    "\n",
    "![clusters](imgs/clusters.png)\n",
    "Frome et al., 2013\n",
    "\n",
    "Please consider that while you may say \"Obviously, a goldfish has to do more with a shark than with an iguana because they are both aquatic\" you are comparing these across one dimension, namely natural habitat, while if you compared them by size the results would be different. These infinite dimensions across which you can compare two words are resumed into a finite number of categories which is what we call embeddings. In this image, we are arbitrarily choosing one dimension to make the point since it is intuitive to us human beings.\n",
    "\n",
    "To create this network the authors combined a computer vision architecture with the embeddings data to create a hybrid model that we can see in the following picture:\n",
    "\n",
    "![devise_arch](imgs/devise_arch.png)\n",
    "Frome et al., 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('../data/imagenet/')\n",
    "TMP_PATH = Path('../data/imagenet/tmp')\n",
    "TRANS_PATH = Path('../data/translate/')\n",
    "PATH_TRN = PATH/'train'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to load our word vectors. We'll see that each word has a normalized number between [-1, 1] for each of the 300 embeddings. This is effectively a 300 dimension representation of the meaning of each word. As an example, let's see the embedding for 'king'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_vecs = ft.load_model(str((TRANS_PATH/'wiki.en.bin')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_vecs.get_word_vector('king')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also see how correlated two words are in how close these numbers are for each embedding. For example we would stipulate that 'jeremy' and 'Jeremy' are more related than 'banana' and 'Jeremy'. Let's see if our embeddings think alike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.60866078],\n",
       "       [0.60866078, 1.        ]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(ft_vecs.get_word_vector('jeremy'), ft_vecs.get_word_vector('Jeremy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.14482342],\n",
       "       [0.14482342, 1.        ]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(ft_vecs.get_word_vector('banana'), ft_vecs.get_word_vector('Jeremy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map imagenet classes to word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will get all the words in the dictionary and sort them by their frequency (how often do they appear in the aforementioned datasets). We will then count how many words do we have in our dictionary as another step in the 'discovery phase' of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_words = ft_vecs.get_words(include_freq=True)\n",
    "ft_word_dict = {k:v for k,v in zip(*ft_words)}\n",
    "ft_words = sorted(ft_word_dict.keys(), key=lambda x: ft_word_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will download the names of our 1000 imagenet classes so that we can assign each class in our imagenet dataset to a 300-long embedding (for that we need the actual word-id for each class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES_FN = 'imagenet_class_index.json'\n",
    "download_url(f'http://files.fast.ai/models/{CLASSES_FN}', TMP_PATH/CLASSES_FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also download all the nouns in English from WORDNET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORDS_FN = 'classids.txt'\n",
    "download_url(f'http://files.fast.ai/data/{WORDS_FN}', PATH/WORDS_FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will build a dictionary that maps our classes to the word-id for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = json.load((TMP_PATH/CLASSES_FN).open())\n",
    "classids_1k = dict(class_dict.values())\n",
    "nclass = len(class_dict); nclass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check that our class-id assignments are made correctly. Here we can see our two worlds:\n",
    "\n",
    "1. Imagenet and its class to id mapping\n",
    "2. WORDNET and its class to id mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['n00001740 entity\\n',\n",
       " 'n00001930 physical_entity\\n',\n",
       " 'n00002137 abstraction\\n',\n",
       " 'n00002452 thing\\n',\n",
       " 'n00002684 object\\n']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classid_lines = (PATH/WORDS_FN).open().readlines()\n",
    "classid_lines[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the nouns in the English language and the Imagenet class ids, we need to connect each of these with the words in fastText. We will do this by creating a dictionary of synset to word vectors for both our WORDNET and Imagenet lists that __will only keep the words that are present in both datasets__ (i.e. both WORDNET and fastText for *syn_wv* and both Imagenet and fastText for *syn_wv_1k*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classids = dict(l.strip().split() for l in classid_lines)\n",
    "len(classids),len(classids_1k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_vec_d = {w.lower(): ft_vecs.get_word_vector(w) for w in ft_words[-1000000:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-fe7ccf6ebc30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m syn_wv = [(k, lc_vec_d[v.lower()]) for k,v in classids.items()\n\u001b[0m\u001b[1;32m      2\u001b[0m           if v.lower() in lc_vec_d]\n\u001b[1;32m      3\u001b[0m syn_wv_1k = [(k, lc_vec_d[v.lower()]) for k,v in classids_1k.items()\n\u001b[1;32m      4\u001b[0m           if v.lower() in lc_vec_d]\n\u001b[1;32m      5\u001b[0m \u001b[0msyn2wv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyn_wv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classids' is not defined"
     ]
    }
   ],
   "source": [
    "syn_wv = [(k, lc_vec_d[v.lower()]) for k,v in classids.items()\n",
    "          if v.lower() in lc_vec_d]\n",
    "syn_wv_1k = [(k, lc_vec_d[v.lower()]) for k,v in classids_1k.items()\n",
    "          if v.lower() in lc_vec_d]\n",
    "syn2wv = dict(syn_wv)\n",
    "len(syn2wv), len(syn_wv_1k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'syn2wv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-46ea570c57a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyn2wv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTMP_PATH\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'syn2wv.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyn_wv_1k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTMP_PATH\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m'syn_wv_1k.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'syn2wv' is not defined"
     ]
    }
   ],
   "source": [
    "pickle.dump(syn2wv, (TMP_PATH/'syn2wv.pkl').open('wb'))\n",
    "pickle.dump(syn_wv_1k, (TMP_PATH/'syn_wv_1k.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn2wv = pickle.load((TMP_PATH/'syn2wv.pkl').open('rb'))\n",
    "syn_wv_1k = pickle.load((TMP_PATH/'syn_wv_1k.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is building the data we are going to train our model on. For that we are only including images with ids that are English nouns. Our _x_ variables will be our images (which we are saving in a PosixPath format) and our *y* variables will be our vectors (300 floats, one for each embedding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "img_vecs = []\n",
    "images_val = []\n",
    "img_vecs_val = []\n",
    "\n",
    "for d in (PATH/'train').iterdir():\n",
    "    if d.name not in syn2wv: continue\n",
    "    vec = syn2wv[d.name]\n",
    "    for f in d.iterdir():\n",
    "        images.append(str(f.relative_to(PATH)))\n",
    "        img_vecs.append(vec)\n",
    "\n",
    "n_val=0\n",
    "for d in (PATH/'valid').iterdir():\n",
    "    if d.name not in syn2wv: continue\n",
    "    vec = syn2wv[d.name]\n",
    "    for f in d.iterdir():\n",
    "        images_val.append(str(f.relative_to(PATH)))\n",
    "        img_vecs_val.append(vec)\n",
    "        n_val += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28700"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(739526, 300)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_vecs = np.stack(img_vecs)\n",
    "img_vecs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(images, (TMP_PATH/'images.pkl').open('wb'))\n",
    "pickle.dump(img_vecs, (TMP_PATH/'img_vecs.pkl').open('wb'))\n",
    "pickle.dump(images_val, (TMP_PATH/'images_val.pkl').open('wb'))\n",
    "pickle.dump(img_vecs_val, (TMP_PATH/'img_vecs)val.pkl').open('wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = pickle.load((TMP_PATH/'images.pkl').open('rb'))\n",
    "img_vecs = pickle.load((TMP_PATH/'img_vecs.pkl').open('rb'))\n",
    "images_val = pickle.load((TMP_PATH/'images_val.pkl').open('rb'))\n",
    "img_vecs_val = pickle.load((TMP_PATH/'img_vecs_val.pkl').open('rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the data ready"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build our dataset and create our DataBunch object. Note that we will need to tell our model how many classes we have. We will specify this manually since our ImageDataset class does not support it natively (this argument will then be passed to our model). We will resize our pictures to a 224x224 size and normalize them. Finally we will check that our data looks as we would like it to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = (PATH/\"\").absolute()\n",
    "images = [folder_path/image for image in images]\n",
    "images_val = [folder_path/image_val for image_val in images_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "739526"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_val[0]\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ImageDataset(images, img_vecs)\n",
    "valid_ds = ImageDataset(images_val, img_vecs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.classes = range(300)\n",
    "valid_ds.classes = range(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = ([flip_lr()], [crop_pad(size=224)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DataBunch.create(train_ds, valid_ds, path=PATH, device=torch.device('cuda'), ds_tfms = get_transforms(), tfms=imagenet_norm, size=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 3, 224, 224]), torch.Size([128, 300]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(data.valid_dl))\n",
    "x.size(),y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-9.6364e-01, -9.7655e-01, -9.2227e-01,  ..., -9.6001e-01,\n",
       "            -9.2216e-01, -9.8587e-01],\n",
       "           [-1.0248e+00, -9.5857e-01, -9.8156e-01,  ..., -9.1072e-01,\n",
       "            -9.3120e-01, -9.2302e-01],\n",
       "           [-1.0324e+00, -8.6857e-01, -9.7989e-01,  ..., -9.4748e-01,\n",
       "            -7.5343e-01, -9.0856e-01],\n",
       "           ...,\n",
       "           [ 4.7123e-01, -2.8666e-01, -9.3839e-01,  ..., -2.1520e-01,\n",
       "            -1.2210e+00, -1.7548e+00],\n",
       "           [ 8.2635e-01, -1.1742e+00, -1.5453e-01,  ..., -1.4314e+00,\n",
       "            -1.7691e+00, -1.9772e+00],\n",
       "           [-5.8931e-01, -5.4998e-01, -2.1997e-01,  ..., -1.4780e+00,\n",
       "            -1.2982e+00, -1.0476e+00]],\n",
       " \n",
       "          [[-1.6658e-01, -1.2365e-01, -1.6498e-01,  ..., -4.7560e-02,\n",
       "            -2.8670e-02, -8.6025e-02],\n",
       "           [-1.9913e-01, -1.5006e-01, -1.9009e-01,  ..., -1.1081e-01,\n",
       "            -1.2808e-01, -1.2233e-01],\n",
       "           [-2.1026e-01, -1.6322e-01, -1.4784e-01,  ..., -7.5774e-02,\n",
       "            -1.5340e-01, -4.0798e-02],\n",
       "           ...,\n",
       "           [ 4.5991e-01, -3.2669e-01, -1.1474e+00,  ..., -5.0291e-04,\n",
       "            -8.3333e-01, -1.4873e+00],\n",
       "           [ 8.4916e-01, -1.2351e+00, -1.6720e-01,  ..., -1.0276e+00,\n",
       "            -1.5096e+00, -1.6421e+00],\n",
       "           [-6.6827e-01, -5.6700e-01, -2.3051e-01,  ..., -1.2718e+00,\n",
       "            -1.0844e+00, -6.6370e-01]],\n",
       " \n",
       "          [[ 1.2822e+00,  1.3034e+00,  1.2918e+00,  ...,  1.3104e+00,\n",
       "             1.3319e+00,  1.2853e+00],\n",
       "           [ 1.2491e+00,  1.2901e+00,  1.2515e+00,  ...,  1.2880e+00,\n",
       "             1.2728e+00,  1.2788e+00],\n",
       "           [ 1.2412e+00,  1.3024e+00,  1.2541e+00,  ...,  1.3007e+00,\n",
       "             1.3107e+00,  1.3291e+00],\n",
       "           ...,\n",
       "           [ 1.0465e-01, -4.8232e-01, -1.3825e+00,  ...,  8.8544e-01,\n",
       "             7.9544e-02, -6.8980e-01],\n",
       "           [ 1.0883e+00, -1.4588e+00, -7.7985e-01,  ..., -1.6768e-01,\n",
       "            -6.6514e-01, -1.2111e+00],\n",
       "           [-8.4516e-01, -8.8443e-01, -1.2596e+00,  ..., -7.5966e-01,\n",
       "            -5.4365e-01,  2.1833e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 1.6686e+00,  1.6789e+00,  1.6125e+00,  ..., -4.7761e-02,\n",
       "            -1.0717e-01, -1.0730e-01],\n",
       "           [ 1.5503e+00,  1.5804e+00,  1.7673e+00,  ..., -1.2518e-02,\n",
       "            -1.0438e-02,  1.8111e-01],\n",
       "           [ 1.5098e+00,  1.6572e+00,  1.7841e+00,  ...,  1.0773e-01,\n",
       "             2.1111e-01,  2.1467e-01],\n",
       "           ...,\n",
       "           [-9.6767e-01, -9.7370e-01, -1.1093e+00,  ...,  4.1307e-01,\n",
       "             4.8736e-01,  8.3162e-01],\n",
       "           [-1.0676e+00, -1.0488e+00, -1.0689e+00,  ...,  3.0292e-01,\n",
       "             4.8620e-01,  7.7544e-01],\n",
       "           [-1.0249e+00, -1.0454e+00, -1.1216e+00,  ...,  6.6216e-01,\n",
       "             8.5973e-01,  7.9955e-01]],\n",
       " \n",
       "          [[ 1.9902e+00,  2.0337e+00,  2.0013e+00,  ..., -2.0206e-01,\n",
       "            -2.3477e-01, -1.9459e-01],\n",
       "           [ 1.8787e+00,  1.9282e+00,  2.1502e+00,  ..., -2.1030e-01,\n",
       "            -1.7632e-01,  1.4836e-02],\n",
       "           [ 1.8275e+00,  1.9869e+00,  2.1678e+00,  ..., -1.7020e-01,\n",
       "            -1.0177e-01,  9.9659e-02],\n",
       "           ...,\n",
       "           [-1.1706e+00, -1.1530e+00, -1.2776e+00,  ...,  4.6465e-01,\n",
       "             5.7502e-01,  9.4925e-01],\n",
       "           [-1.2755e+00, -1.3553e+00, -1.3032e+00,  ...,  2.2119e-01,\n",
       "             5.9907e-01,  7.7817e-01],\n",
       "           [-1.2784e+00, -1.2876e+00, -1.2527e+00,  ...,  6.2024e-01,\n",
       "             8.3517e-01,  8.1415e-01]],\n",
       " \n",
       "          [[ 2.2641e+00,  2.3264e+00,  2.4528e+00,  ...,  2.1676e-01,\n",
       "             2.7809e-01,  1.8041e-01],\n",
       "           [ 2.1752e+00,  2.2860e+00,  2.3868e+00,  ...,  2.4129e-01,\n",
       "             2.8307e-01,  4.3938e-01],\n",
       "           [ 2.0972e+00,  2.3345e+00,  2.3939e+00,  ...,  1.8788e-01,\n",
       "             2.9963e-01,  5.9966e-01],\n",
       "           ...,\n",
       "           [-6.2741e-01, -7.2902e-01, -9.9195e-01,  ...,  8.8162e-01,\n",
       "             1.1693e+00,  1.3739e+00],\n",
       "           [-9.1078e-01, -7.6761e-01, -8.0459e-01,  ...,  5.2930e-01,\n",
       "             1.1023e+00,  1.3565e+00],\n",
       "           [-8.3651e-01, -8.1843e-01, -7.9277e-01,  ...,  7.5294e-01,\n",
       "             9.6631e-01,  1.2706e+00]]],\n",
       " \n",
       " \n",
       "         [[[-2.0662e+00, -1.9451e+00, -1.8072e+00,  ..., -1.7190e+00,\n",
       "            -1.6547e+00, -1.6345e+00],\n",
       "           [-2.0428e+00, -2.0599e+00, -1.9471e+00,  ..., -1.6808e+00,\n",
       "            -1.8008e+00, -1.8943e+00],\n",
       "           [-2.0442e+00, -2.1017e+00, -2.0082e+00,  ..., -1.7808e+00,\n",
       "            -1.8411e+00, -1.7100e+00],\n",
       "           ...,\n",
       "           [-2.0936e+00, -1.4160e+00, -2.0050e+00,  ..., -3.3847e-01,\n",
       "            -1.1528e+00, -1.9835e+00],\n",
       "           [-1.9149e+00, -1.7444e+00, -1.9751e+00,  ..., -8.1152e-01,\n",
       "            -1.1841e+00, -2.0448e+00],\n",
       "           [-1.7781e+00, -1.8256e+00, -1.8748e+00,  ..., -3.6366e-01,\n",
       "            -5.6151e-01, -2.0011e+00]],\n",
       " \n",
       "          [[-1.8984e+00, -1.8164e+00, -1.5914e+00,  ..., -1.0507e+00,\n",
       "            -1.1424e+00, -1.2437e+00],\n",
       "           [-1.8915e+00, -1.9108e+00, -1.8216e+00,  ..., -1.1712e+00,\n",
       "            -1.2786e+00, -1.3775e+00],\n",
       "           [-1.9993e+00, -1.9521e+00, -1.9239e+00,  ..., -1.2589e+00,\n",
       "            -1.2343e+00, -1.1268e+00],\n",
       "           ...,\n",
       "           [-2.0108e+00, -1.2711e+00, -1.8596e+00,  ..., -1.7599e-01,\n",
       "            -9.9995e-01, -1.8933e+00],\n",
       "           [-1.8481e+00, -1.6046e+00, -1.8833e+00,  ..., -6.1972e-01,\n",
       "            -1.0109e+00, -1.9591e+00],\n",
       "           [-1.8086e+00, -1.6561e+00, -1.7783e+00,  ..., -1.7967e-01,\n",
       "            -3.9216e-01, -1.9115e+00]],\n",
       " \n",
       "          [[-1.6848e+00, -1.6013e+00, -1.3297e+00,  ..., -2.6192e-02,\n",
       "             1.6163e-02, -6.5969e-02],\n",
       "           [-1.7560e+00, -1.7482e+00, -1.5582e+00,  ...,  8.8585e-02,\n",
       "            -6.1064e-02, -3.1240e-01],\n",
       "           [-1.7571e+00, -1.6934e+00, -1.6395e+00,  ...,  7.0459e-02,\n",
       "            -2.0183e-02, -1.0490e-01],\n",
       "           ...,\n",
       "           [-1.5755e+00, -8.6027e-01, -1.5625e+00,  ...,  4.3793e-01,\n",
       "            -6.0560e-01, -1.5866e+00],\n",
       "           [-1.5732e+00, -1.2793e+00, -1.5839e+00,  ...,  8.8676e-03,\n",
       "            -6.2173e-01, -1.6392e+00],\n",
       "           [-1.4781e+00, -1.5090e+00, -1.4980e+00,  ...,  2.7375e-01,\n",
       "            -1.6412e-01, -1.6680e+00]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 5.4182e-01,  8.4032e-01,  2.1003e+00,  ...,  2.2844e-01,\n",
       "             8.7656e-02,  5.6679e-01],\n",
       "           [ 1.1429e+00,  8.3414e-01,  2.1824e+00,  ...,  1.0775e-01,\n",
       "            -3.0939e-01,  3.7635e-01],\n",
       "           [ 8.8340e-01,  1.1066e+00,  2.2347e+00,  ...,  5.4176e-02,\n",
       "            -3.0282e-01, -2.0370e-01],\n",
       "           ...,\n",
       "           [ 1.6382e+00,  1.1198e+00,  1.2351e+00,  ...,  1.2542e+00,\n",
       "             2.1464e-01, -5.1127e-01],\n",
       "           [ 1.4795e+00,  8.2221e-01,  1.3867e+00,  ...,  5.4226e-01,\n",
       "             6.2133e-01,  8.1885e-02],\n",
       "           [-8.9380e-02,  7.6327e-01, -1.2204e+00,  ..., -1.8992e-02,\n",
       "             5.0204e-01,  6.1515e-02]],\n",
       " \n",
       "          [[-7.6692e-01, -7.7693e-01,  1.8621e+00,  ..., -3.8174e-01,\n",
       "            -4.8318e-01, -1.8992e-02],\n",
       "           [-2.6427e-01, -3.7212e-01,  2.1197e+00,  ..., -4.1491e-01,\n",
       "            -7.8236e-01, -1.5622e-01],\n",
       "           [-6.0510e-01,  4.9701e-01,  2.2889e+00,  ..., -5.6412e-01,\n",
       "            -8.4713e-01, -6.4160e-01],\n",
       "           ...,\n",
       "           [ 1.1085e+00,  4.5665e-01,  4.1919e-01,  ...,  9.8659e-01,\n",
       "            -2.2808e-01, -1.0093e+00],\n",
       "           [ 1.0025e+00,  3.3972e-02,  5.1020e-01,  ...,  4.4559e-01,\n",
       "             3.9484e-01, -2.2696e-01],\n",
       "           [ 2.2017e-01,  7.2019e-01, -1.5436e+00,  ...,  9.6691e-02,\n",
       "             4.9272e-01, -4.2497e-02]],\n",
       " \n",
       "          [[-1.3420e+00, -1.0796e+00,  1.5931e+00,  ..., -1.0273e+00,\n",
       "            -1.1914e+00, -6.5905e-01],\n",
       "           [-6.7261e-01, -6.6302e-01,  1.8397e+00,  ..., -1.0705e+00,\n",
       "            -1.4659e+00, -7.8131e-01],\n",
       "           [-7.2738e-01,  2.0083e-01,  2.0262e+00,  ..., -9.1033e-01,\n",
       "            -1.0936e+00, -8.5118e-01],\n",
       "           ...,\n",
       "           [ 1.1664e+00,  3.0633e-01,  1.6698e-01,  ..., -2.0580e-01,\n",
       "            -1.2666e+00, -1.6260e+00],\n",
       "           [ 1.2676e+00,  2.9193e-01,  7.1692e-01,  ..., -7.3925e-01,\n",
       "            -7.5159e-01, -1.0881e+00],\n",
       "           [-4.6414e-01,  1.3576e-01, -1.7727e+00,  ..., -1.0228e+00,\n",
       "            -6.6770e-01, -9.7357e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 5.2595e-01,  5.2180e-01,  5.4875e-01,  ...,  6.6489e-01,\n",
       "             5.4016e-01,  8.9954e-01],\n",
       "           [ 5.6365e-01,  5.5706e-01,  5.1440e-01,  ...,  7.5621e-01,\n",
       "             5.4337e-01,  8.1070e-01],\n",
       "           [ 5.3480e-01,  5.3205e-01,  4.7902e-01,  ...,  6.5793e-01,\n",
       "             7.8905e-01,  9.8293e-01],\n",
       "           ...,\n",
       "           [ 1.2447e+00,  1.1496e+00,  1.0451e+00,  ...,  1.3057e+00,\n",
       "             1.2464e+00,  1.1608e+00],\n",
       "           [ 1.2616e+00,  1.1858e+00,  1.0575e+00,  ...,  1.2271e+00,\n",
       "             1.1391e+00,  1.0516e+00],\n",
       "           [ 1.2525e+00,  1.1884e+00,  1.0717e+00,  ...,  1.0561e+00,\n",
       "             1.0993e+00,  1.0145e+00]],\n",
       " \n",
       "          [[ 6.1037e-01,  6.2340e-01,  5.9564e-01,  ..., -8.9675e-02,\n",
       "             1.6504e-01,  6.9261e-01],\n",
       "           [ 6.4677e-01,  6.4486e-01,  5.6254e-01,  ..., -4.1448e-02,\n",
       "             1.6784e-01,  3.9639e-01],\n",
       "           [ 5.8466e-01,  5.8335e-01,  4.8552e-01,  ..., -1.0618e-01,\n",
       "             1.8494e-01,  5.2852e-01],\n",
       "           ...,\n",
       "           [ 1.5315e-01, -2.7562e-02, -1.8237e-01,  ...,  1.1187e+00,\n",
       "             1.0329e+00,  8.2656e-01],\n",
       "           [ 2.3793e-01,  2.0287e-02, -1.5065e-01,  ...,  1.0085e+00,\n",
       "             7.8105e-01,  6.5336e-01],\n",
       "           [ 3.0272e-01,  9.0143e-02, -1.1730e-01,  ...,  8.4167e-01,\n",
       "             7.7145e-01,  6.7071e-01]],\n",
       " \n",
       "          [[ 6.7535e-01,  6.5510e-01,  6.5613e-01,  ..., -1.6037e+00,\n",
       "            -1.1492e+00, -2.7636e-01],\n",
       "           [ 7.5348e-01,  7.0512e-01,  5.6732e-01,  ..., -1.2204e+00,\n",
       "            -8.1021e-01,  1.0044e-01],\n",
       "           [ 6.4814e-01,  6.0399e-01,  4.6755e-01,  ..., -1.4573e+00,\n",
       "            -7.2307e-01,  5.8409e-01],\n",
       "           ...,\n",
       "           [-1.6556e+00, -1.7444e+00, -1.6837e+00,  ...,  1.0580e-01,\n",
       "            -9.8368e-02, -4.7062e-01],\n",
       "           [-1.5560e+00, -1.6625e+00, -1.7118e+00,  ...,  1.1082e-03,\n",
       "            -4.6016e-01, -6.8861e-01],\n",
       "           [-1.4649e+00, -1.5590e+00, -1.6907e+00,  ..., -2.5404e-01,\n",
       "            -3.3876e-01, -5.7796e-01]]],\n",
       " \n",
       " \n",
       "         [[[-9.6355e-01, -1.2854e+00, -1.0136e+00,  ...,  4.9505e-01,\n",
       "             4.1445e-01,  3.2170e-01],\n",
       "           [-7.4031e-01, -1.1498e+00, -1.0388e+00,  ...,  6.6095e-02,\n",
       "             3.5179e-01,  6.6887e-01],\n",
       "           [-5.9665e-01, -1.0543e+00, -1.0390e+00,  ...,  6.2589e-01,\n",
       "             5.8014e-01,  3.0785e-01],\n",
       "           ...,\n",
       "           [-4.8835e-01, -6.8254e-01, -8.5941e-01,  ...,  2.8545e-01,\n",
       "             8.3043e-02,  1.1760e-01],\n",
       "           [-6.5725e-01, -8.0741e-01, -7.5617e-01,  ...,  1.4192e-01,\n",
       "             3.3251e-01,  3.9284e-01],\n",
       "           [-5.2930e-01, -7.9628e-01, -7.7385e-01,  ...,  3.8222e-01,\n",
       "             5.1260e-01,  3.3267e-01]],\n",
       " \n",
       "          [[-7.2862e-01, -9.6965e-01, -5.4740e-01,  ...,  1.6308e+00,\n",
       "             1.5574e+00,  1.5602e+00],\n",
       "           [-4.9677e-01, -8.1184e-01, -5.5574e-01,  ...,  1.3221e+00,\n",
       "             1.5968e+00,  1.7551e+00],\n",
       "           [-3.7425e-01, -6.6536e-01, -5.3818e-01,  ...,  1.6615e+00,\n",
       "             1.2374e+00,  6.2423e-01],\n",
       "           ...,\n",
       "           [-5.7001e-02, -2.3426e-01, -3.3115e-01,  ...,  1.3214e+00,\n",
       "             1.0368e+00,  1.1065e+00],\n",
       "           [-4.1292e-01, -5.4595e-01, -3.4659e-01,  ...,  5.8877e-01,\n",
       "             9.8952e-01,  9.9154e-01],\n",
       "           [-2.6622e-01, -5.1236e-01, -4.0924e-01,  ...,  7.8712e-01,\n",
       "             9.1718e-01,  4.6434e-01]],\n",
       " \n",
       "          [[-1.0009e-01, -5.6933e-01, -3.1489e-01,  ...,  1.4548e+00,\n",
       "             1.4146e+00,  1.4737e+00],\n",
       "           [ 1.3743e-01, -3.6951e-01, -3.1501e-01,  ...,  1.2378e+00,\n",
       "             1.4104e+00,  1.4697e+00],\n",
       "           [ 2.6867e-01, -1.9915e-01, -2.8025e-01,  ...,  1.4270e+00,\n",
       "             1.1442e+00,  8.3141e-01],\n",
       "           ...,\n",
       "           [ 6.9067e-01,  4.8702e-01,  5.2147e-01,  ...,  1.1415e+00,\n",
       "             8.0832e-01,  9.0378e-01],\n",
       "           [ 2.8709e-01,  1.7244e-01,  4.0747e-01,  ...,  7.4888e-01,\n",
       "             8.9278e-01,  7.7259e-01],\n",
       "           [ 5.3717e-01,  2.2253e-01,  2.1981e-01,  ...,  7.8527e-01,\n",
       "             8.5365e-01,  8.2295e-01]]]], device='cuda:0'),\n",
       " tensor([[-0.4566, -0.3479, -0.3509,  ...,  0.6010,  0.1175,  0.3293],\n",
       "         [ 0.4089,  0.2701, -0.5081,  ...,  0.1911,  0.1770,  0.3183],\n",
       "         [ 0.1062, -0.1147,  0.0016,  ...,  0.2513, -0.3345,  0.3226],\n",
       "         ...,\n",
       "         [-0.3662,  0.0633, -0.2282,  ...,  0.3584,  0.0008,  0.1923],\n",
       "         [ 0.0677, -0.0345,  0.1490,  ...,  0.4540,  0.0251, -0.1667],\n",
       "         [ 0.0088, -0.0327, -0.2295,  ...,  0.4646, -0.0174, -0.1849]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data.train_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to train our model. Our model will try to predict the value of each embedding for each of our images. To accomplish this we will add a fully connected layer at the end of our resnet50 architecture (with 300 output neurons) and precompute the activations of the backbone model so as to save training time. We will also initialize the weights of the backbone model with the weights of the pretrained model. Given that the pretrained model and ours are both training in the same dataset we will not need to do any finetuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we are going to start by precomputing our activations for the convolutional backbone and we will then train our head from these activations (so our model will not have to calculate them again for each epoch). Since we already have a pretrained backbone, we will just need to run one forward pass to compute the final activations; that is we will not need any optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bcolz, threading\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = ConvLearner(data, tvm.resnet50, ps=[0.2,0.2], pretrained=True, callback_fns=BnFreeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.opt_fn = partial(AdamW, betas=(0.9,0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_loss(inp,targ): return 1 - F.cosine_similarity(inp,targ).mean()\n",
    "learn.loss_fn = cos_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body = learn.model[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activations(path, model_name, tmp_path, nf, force=False): \n",
    "    tmpl = f'_{model_name}.bc'\n",
    "    names = [os.path.join(path/'tmp', p+tmpl) for p in ('x_act', 'x_act_val')]\n",
    "    if os.path.exists(names[0]) and not force:\n",
    "        activations = [bcolz.open(p) for p in names]\n",
    "    else:\n",
    "        activations = [create_empty_bcolz(nf,p) for p in names]\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_empty_bcolz(n, name):\n",
    "    return bcolz.carray(np.zeros((0,n), np.float32), chunklen=1, mode='w', rootdir=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_to_bcolz(m, gen, arr, workers=4):\n",
    "    arr.trim(len(arr))\n",
    "    lock=threading.Lock()\n",
    "    m.eval()\n",
    "    for x,*_ in tqdm(gen):\n",
    "        y = to_np((m(x.data)).detach())\n",
    "        with lock:\n",
    "            arr.append(y)\n",
    "    arr.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fc1(data, model, path, model_name, tmp_path, nf):\n",
    "    activations = get_activations(path, model_name, tmp_path, nf)\n",
    "    act=activations[0]\n",
    "    val_act=activations[1]\n",
    "    m=model\n",
    "    if len(act)!=len(data.train_dl):\n",
    "        print(len(act)), print(len(data.train_dl))\n",
    "        sct = predict_to_bcolz(m, data.train_dl, act)\n",
    "    if len(val_act)!=len(data.train_dl):\n",
    "        val_act = predict_to_bcolz(m, data.valid_dl, val_act)\n",
    "\n",
    "    fc_data = ImageDataset(act, data.train_dl.y, val_act, data.valid_dl.y)\n",
    "    fc_data.classes = data.classes\n",
    "    return fc_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_features(m:Model)->int:\n",
    "    \"Return the number of output features for a `model`.\"\n",
    "    for l in reversed(flatten_model(m)):\n",
    "        if hasattr(l, 'num_features'): \n",
    "            return l.num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = num_features(body)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/11556 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "11556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array trailing dimensions do not match with self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-147-c5f2b3c46004>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfc_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_fc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'resnet50'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTMP_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-143-1cb20fbf121b>\u001b[0m in \u001b[0;36msave_fc1\u001b[0;34m(data, model, path, model_name, tmp_path, nf)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0msct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_to_bcolz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_act\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mval_act\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_to_bcolz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_act\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-142-2ef45692c45a>\u001b[0m in \u001b[0;36mpredict_to_bcolz\u001b[0;34m(m, gen, arr, workers)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mbcolz/carray_ext.pyx\u001b[0m in \u001b[0;36mbcolz.carray_ext.carray.append\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: array trailing dimensions do not match with self"
     ]
    }
   ],
   "source": [
    "fc_data = save_fc1(data, body, learn.path, 'resnet50', TMP_PATH, nf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_head(nf:int, nc:int, lin_ftrs:Optional[Collection[int]]=None, ps:Floats=0.5):\n",
    "    \"\"\"Model head that takes `nf` features, runs through `lin_ftrs`, and about `nc` classes.\n",
    "    :param ps: dropout, can be a single float or a list for each layer.\"\"\"\n",
    "    lin_ftrs = [nf, 512, nc] if lin_ftrs is None else [nf] + lin_ftrs + [nc]\n",
    "    ps = listify(ps)\n",
    "    if len(ps)==1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    layers = [AdaptiveConcatPool2d(), Flatten()]\n",
    "    for ni,no,p,actn in zip(lin_ftrs[:-1],lin_ftrs[1:],ps,actns):\n",
    "        layers += bn_drop_lin(ni,no,True,p,actn)\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = create_head(2048, 300, lin_ftrs=[1024], ps=[0.2, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fc_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-22f08aa8da49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mHeadLearner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfc_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcos_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fc_data' is not defined"
     ]
    }
   ],
   "source": [
    "learn_head = Learner(data=fc_data, model=head, opt_fn = partial(AdamW, betas=(0.9,0.99)), loss_fn = cos_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): AdaptiveConcatPool2d(\n",
       "    (ap): AdaptiveAvgPool2d(output_size=1)\n",
       "    (mp): AdaptiveMaxPool2d(output_size=1)\n",
       "  )\n",
       "  (1): Lambda()\n",
       "  (2): BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (3): Dropout(p=0.2)\n",
       "  (4): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "  (5): ReLU(inplace)\n",
       "  (6): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): Dropout(p=0.2)\n",
       "  (8): Linear(in_features=1024, out_features=300, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_head.lr_find(start_lr=1e-4, end_lr=1e15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_head.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "wd = 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "295995b124de42c181cdcbaffbf9b7d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=3), HTML(value='0.00% [0/3 00:00<00:00]'))), HTML(value"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn_head.fit_one_cycle(3, lr, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load pretrained weights to our custom head and finetune network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = np.array([lr/1000,lr/100,lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.precompute=False\n",
    "learn.freeze_to(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('pre0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('pre0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search imagenet classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syns, wvs = list(zip(*syn_wv_1k))\n",
    "wvs = np.array(wvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'learn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'learn' is not defined"
     ]
    }
   ],
   "source": [
    "%time pred_wv = learn.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "denorm = md.val_ds.denorm\n",
    "\n",
    "def show_img(im, figsize=None, ax=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im)\n",
    "    ax.axis('off')\n",
    "    return ax\n",
    "\n",
    "def show_imgs(ims, cols, figsize=None):\n",
    "    fig,axes = plt.subplots(len(ims)//cols, cols, figsize=figsize)\n",
    "    for i,ax in enumerate(axes.flat): show_img(ims[i], ax=ax)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_imgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e5f8ae797ce9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'show_imgs' is not defined"
     ]
    }
   ],
   "source": [
    "show_imgs(denorm(md.val_ds[start:start+25][0]), 5, (10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nmslib\n",
    "\n",
    "def create_index(a):\n",
    "    index = nmslib.init(space='angulardist')\n",
    "    index.addDataPointBatch(a)\n",
    "    index.createIndex()\n",
    "    return index\n",
    "\n",
    "def get_knns(index, vecs):\n",
    "     return zip(*index.knnQueryBatch(vecs, k=10, num_threads=4))\n",
    "\n",
    "def get_knn(index, vec): return index.knnQuery(vec, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_wvs = create_index(wvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs,dists = get_knns(nn_wvs, pred_wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['limpkin', 'oystercatcher', 'spoonbill'],\n",
       " ['limpkin', 'oystercatcher', 'spoonbill'],\n",
       " ['limpkin', 'oystercatcher', 'spoonbill'],\n",
       " ['spoonbill', 'bustard', 'oystercatcher'],\n",
       " ['limpkin', 'oystercatcher', 'spoonbill'],\n",
       " ['limpkin', 'oystercatcher', 'spoonbill'],\n",
       " ['limpkin', 'oystercatcher', 'spoonbill'],\n",
       " ['limpkin', 'oystercatcher', 'spoonbill'],\n",
       " ['limpkin', 'oystercatcher', 'spoonbill'],\n",
       " ['limpkin', 'oystercatcher', 'spoonbill']]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[classids[syns[id]] for id in ids[:3]] for ids in idxs[start:start+10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search all wordnet noun classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_syns, all_wvs = list(zip(*syn2wv.items()))\n",
    "all_wvs = np.array(all_wvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_allwvs = create_index(all_wvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs,dists = get_knns(nn_allwvs, pred_wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['limpkin', 'oystercatcher', 'spoonbill'],\n",
       " ['limpkin', 'oystercatcher', 'spoonbill'],\n",
       " ['limpkin', 'oystercatcher', 'spoonbill'],\n",
       " ['spoonbill', 'bustard', 'oystercatcher'],\n",
       " ['limpkin', 'oystercatcher', 'spoonbill'],\n",
       " ['limpkin', 'oystercatcher', 'spoonbill'],\n",
       " ['limpkin', 'oystercatcher', 'spoonbill'],\n",
       " ['limpkin', 'oystercatcher', 'spoonbill'],\n",
       " ['limpkin', 'oystercatcher', 'spoonbill'],\n",
       " ['limpkin', 'oystercatcher', 'spoonbill']]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[classids[all_syns[id]] for id in ids[:3]] for ids in idxs[start:start+10]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text -> image search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_predwv = create_index(pred_wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vecd = pickle.load(open(TRANS_PATH/'wiki.en.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = en_vecd['boat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_knn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-89391ccab9a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_predwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mshow_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopen_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_knn' is not defined"
     ]
    }
   ],
   "source": [
    "idxs,dists = get_knn(nn_predwv, vec)\n",
    "show_imgs([open_image(PATH/md.val_ds.fnames[i]) for i in idxs[:3]], 3, figsize=(9,3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = (en_vecd['engine'] + en_vecd['boat'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_knn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-89391ccab9a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_predwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mshow_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopen_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_knn' is not defined"
     ]
    }
   ],
   "source": [
    "idxs,dists = get_knn(nn_predwv, vec)\n",
    "show_imgs([open_image(PATH/md.val_ds.fnames[i]) for i in idxs[:3]], 3, figsize=(9,3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = (en_vecd['sail'] + en_vecd['boat'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_knn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-89391ccab9a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_predwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mshow_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopen_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_knn' is not defined"
     ]
    }
   ],
   "source": [
    "idxs,dists = get_knn(nn_predwv, vec)\n",
    "show_imgs([open_image(PATH/md.val_ds.fnames[i]) for i in idxs[:3]], 3, figsize=(9,3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image->image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'valid/n01440764/ILSVRC2012_val_00007197.JPEG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = open_image(PATH/fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'show_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-c9b680a767fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'show_img' is not defined"
     ]
    }
   ],
   "source": [
    "show_img(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_img = md.val_ds.transform(img)\n",
    "pred = learn.predict_array(t_img[None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_knn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cf37ec4574c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0midxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_knn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_predwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mshow_imgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mopen_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mmd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_knn' is not defined"
     ]
    }
   ],
   "source": [
    "idxs,dists = get_knn(nn_predwv, pred)\n",
    "show_imgs([open_image(PATH/md.val_ds.fnames[i]) for i in idxs[1:4]], 3, figsize=(9,3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
