{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_12 import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imagenet(te) training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = datasets.untar_data(datasets.URLs.IMAGENETTE_320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 128\n",
    "#tfms = [make_rgb, RandomResizedCrop(128,scale=(0.35,1)), to_byte_tensor, to_float_tensor, PilRandomFlip()]\n",
    "tfms = [make_rgb, PilTiltRandomCrop(size, 160, magnitude=0.2), to_byte_tensor, to_float_tensor, PilRandomFlip()]\n",
    "il = ImageItemList.from_files(path, tfms=tfms)\n",
    "sd = SplitData.split_by_func(il, partial(grandparent_splitter, valid_name='val'))\n",
    "ll = label_by_func(sd, parent_labeler)\n",
    "\n",
    "ll.valid.x.tfms = [make_rgb, CenterCrop(size), to_byte_tensor, to_float_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=2\n",
    "\n",
    "train_dl,valid_dl = get_dls(ll.train,ll.valid,bs, num_workers=4)\n",
    "data = DataBunch(train_dl, valid_dl, 3, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def noop(x): return x\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "def conv(ni, nf, ks=3, stride=1, bias=False):\n",
    "    return nn.Conv2d(ni, nf, kernel_size=ks, stride=stride, padding=ks//2, bias=bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "act_fn = nn.ReLU(inplace=True)\n",
    "\n",
    "def init_cnn(m, a=0):\n",
    "    if getattr(m, 'bias', None) is not None: nn.init.constant_(m.bias, 0)\n",
    "    if isinstance(m, (nn.Conv2d,nn.Linear)): nn.init.kaiming_normal_(m.weight, a=a)\n",
    "    for l in m.children(): init_cnn(l, a)\n",
    "\n",
    "def conv_layer(ni, nf, ks=3, stride=1, zero_bn=False, act=True):\n",
    "    bn = nn.BatchNorm2d(nf)\n",
    "    nn.init.constant_(bn.weight, 0. if zero_bn else 1.)\n",
    "    layers = [conv(ni, nf, ks, stride=stride), bn]\n",
    "    if act: layers.append(act_fn)\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, expansion, ni, nh, stride=1):\n",
    "        super().__init__()\n",
    "        nf,ni = nh*expansion,ni*expansion\n",
    "        layers  = [conv_layer(ni, nh, 1)]\n",
    "        layers += [\n",
    "            conv_layer(nh, nf, 3, stride=stride, zero_bn=True, act=False)\n",
    "        ] if expansion==1 else [\n",
    "            conv_layer(nh, nh, 3, stride=stride),\n",
    "            conv_layer(nh, nf, 1, zero_bn=True, act=False)\n",
    "        ]\n",
    "        self.convs = nn.Sequential(*layers)\n",
    "        self.idconv = noop if ni==nf else conv_layer(ni, nf, 1)\n",
    "        self.pool = noop if stride==1 else nn.AvgPool2d(2)\n",
    "\n",
    "    def forward(self, x): return act_fn(self.convs(x) + self.pool(self.idconv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class XResNet(nn.Sequential):\n",
    "    def __init__(self, expansion, layers, c_in=3, c_out=1000):\n",
    "        stem = []\n",
    "        sizes = [c_in,32,32,64]\n",
    "        for i in range(3):\n",
    "            stem.append(conv_layer(sizes[i], sizes[i+1], stride=2 if i==0 else 1))\n",
    "            #nf = filt_sz(c_in*9)\n",
    "            #stem.append(conv_layer(c_in, nf, stride=2 if i==1 else 1))\n",
    "            #c_in = nf\n",
    "\n",
    "        block_szs = [64//expansion,64,128,256,512]\n",
    "        blocks = [self._make_layer(expansion, block_szs[i], block_szs[i+1], l, 1 if i==0 else 2)\n",
    "                  for i,l in enumerate(layers)]\n",
    "        super().__init__(\n",
    "            *stem,\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n",
    "            *blocks,\n",
    "            nn.AdaptiveAvgPool2d(1), Flatten(),\n",
    "            nn.Linear(block_szs[-1]*expansion, c_out),\n",
    "        )\n",
    "        init_cnn(self)\n",
    "\n",
    "    def _make_layer(self, expansion, ni, nf, blocks, stride):\n",
    "        return nn.Sequential(\n",
    "            *[ResBlock(expansion, ni if i==0 else nf, nf, stride if i==0 else 1)\n",
    "              for i in range(blocks)])\n",
    "\n",
    "def xresnet18 (**kwargs): return XResNet(1, [2, 2, 2, 2], **kwargs)\n",
    "def xresnet34 (**kwargs): return XResNet(1, [3, 4, 6, 3], **kwargs)\n",
    "def xresnet50 (**kwargs): return XResNet(4, [3, 4, 6, 3], **kwargs)\n",
    "def xresnet101(**kwargs): return XResNet(4, [3, 4, 23, 3], **kwargs)\n",
    "def xresnet152(**kwargs): return XResNet(4, [3, 8, 36, 3], **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 4e-3 * bs/256\n",
    "sched_lr  = combine_scheds([0.5,0.5], cos_1cycle_anneal(lr/10.,lr, 0))\n",
    "sched_mom = combine_scheds([0.5,0.5], cos_1cycle_anneal(0.95,0.85, 0.95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbfs = [partial(AvgStatsCallback,accuracy), ProgressCallback, CudaCallback,\n",
    "        partial(BatchTransformXCallback, norm_imagenette),\n",
    "        partial(MixUp, alpha=0.2), \n",
    "        partial(ParamScheduler, 'lr', sched_lr),\n",
    "        partial(ParamScheduler, 'mom', sched_mom)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = [AverageGrad(dampening=True), AverageSqrGrad(), StepCount()]\n",
    "loss_func = LabelSmoothingCrossEntropy()\n",
    "arch = partial(xresnet34, c_out=10)\n",
    "opt_func = partial(StatefulOptimizer, steppers=AdamStep(), stats=stats,\n",
    "               mom=0.9, mom_sqr=0.99, eps=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(arch(), data, loss_func, lr=lr, cb_funcs=cbfs, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_batch(dl, learn):\n",
    "    learn.xb,learn.yb = next(iter(dl))\n",
    "    learn.do_begin_fit(0)\n",
    "    learn('begin_batch')\n",
    "    learn('after_fit')\n",
    "    return learn.xb,learn.yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 32, 64, 64])\n",
      "torch.Size([4, 32, 64, 64])\n",
      "torch.Size([4, 64, 64, 64])\n",
      "torch.Size([4, 64, 32, 32])\n",
      "torch.Size([4, 64, 32, 32])\n",
      "torch.Size([4, 128, 16, 16])\n",
      "torch.Size([4, 256, 8, 8])\n",
      "torch.Size([4, 512, 4, 4])\n",
      "torch.Size([4, 512, 1, 1])\n",
      "torch.Size([4, 512])\n",
      "torch.Size([4, 10])\n"
     ]
    }
   ],
   "source": [
    "learn.model = learn.model.cuda()\n",
    "model_summary(learn.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>valid_accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.939471</td>\n",
       "      <td>0.395067</td>\n",
       "      <td>1.567447</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.581493</td>\n",
       "      <td>0.592834</td>\n",
       "      <td>1.441457</td>\n",
       "      <td>0.606000</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.457034</td>\n",
       "      <td>0.655266</td>\n",
       "      <td>1.150521</td>\n",
       "      <td>0.736000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.337099</td>\n",
       "      <td>0.715216</td>\n",
       "      <td>1.046517</td>\n",
       "      <td>0.782000</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.244254</td>\n",
       "      <td>0.768032</td>\n",
       "      <td>0.939585</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>00:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 13_train_imagenette.ipynb to exp/nb_13.py\r\n"
     ]
    }
   ],
   "source": [
    "!./notebook2script.py 13_train_imagenette.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
