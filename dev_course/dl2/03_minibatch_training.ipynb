{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_02 import *\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_valid,y_valid = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m = x_train.shape\n",
    "c = y_train.max()+1\n",
    "nh = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_in,nh), nn.ReLU(), nn.Linear(nh,n_out)]\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return torch.log(x.exp()/(x.exp().sum(-1,keepdim=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target): return -input[range(target.shape[0]), target].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nll(log_softmax(pred), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x.sub_(x.exp().sum(-1,keepdim=True).log())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(nll(log_softmax(pred), y_train), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_softmax(x): return x.sub_(x.logsumexp(-1,keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(nll(log_softmax(pred), y_train), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(F.nll_loss(F.log_softmax(pred, -1), y_train), loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(F.cross_entropy(pred, y_train), loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def accuracy(out, yb): return (torch.argmax(out, dim=1)==yb).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-0.1291, -0.0693,  0.1564,  0.0707,  0.0950, -0.1403,  0.0764,  0.0090,\n",
       "         -0.1503, -0.0179], grad_fn=<SelectBackward>), torch.Size([64, 10]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=64                  # batch size\n",
    "\n",
    "xb = x_train[0:bs]     # a mini-batch from x\n",
    "preds = model(xb)      # predictions\n",
    "preds[0], preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3032, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "loss_func(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1094)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(preds, yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5   # learning rate\n",
    "epochs = 1 # how many epochs to train for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "#         set_trace()\n",
    "        start_i = i*bs\n",
    "        end_i = start_i+bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        loss = loss_func(model(xb), yb)\n",
    "\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for l in model.layers:\n",
    "                if hasattr(l, 'weight'):\n",
    "                    l.weight -= l.weight.grad * lr\n",
    "                    l.bias   -= l.bias.grad   * lr\n",
    "                    l.weight.grad.zero_()\n",
    "                    l.bias  .grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2518, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using parameters and optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `nn.Module.__setattr__` and move relu to functional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_in, nh, n_out):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(n_in,nh)\n",
    "        self.l2 = nn.Linear(nh,n_out)\n",
    "        \n",
    "    def __call__(self, x): return self.l2(F.relu(self.l1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(m, nh, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1: Linear(in_features=784, out_features=50, bias=True)\n",
      "l2: Linear(in_features=50, out_features=10, bias=True)\n"
     ]
    }
   ],
   "source": [
    "for name,l in model.named_children(): print(f\"{name}: {l}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=784, out_features=50, bias=True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (l1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (l2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n-1)//bs + 1):\n",
    "            start_i = i*bs\n",
    "            end_i = start_i+bs\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            loss = loss_func(model(xb), yb)\n",
    "\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters(): p -= p.grad * lr\n",
    "                model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2026, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the original `layers` approach, but we have to register the modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = layers\n",
    "        for i,l in enumerate(self.layers): self.add_module(f'layer_{i}', l)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (layer_0): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (layer_1): ReLU()\n",
       "  (layer_2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.ModuleList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.ModuleList` does this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, layers):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1905, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Sequential` is a convenient class which does the same as the above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0420, grad_fn=<NllLossBackward>), tensor(1.))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch also has a package with various optimization algorithms, `torch.optim`. We can use the `step` method from our optimizer to take a forward step, instead of manually updating each parameter.\n",
    "\n",
    "This will let us replace our previous manually coded optimization step:\n",
    "\n",
    "```python\n",
    "with torch.no_grad():\n",
    "    for p in model.parameters(): p -= p.grad * lr\n",
    "    model.zero_grad()\n",
    "```\n",
    "\n",
    "and instead use just:\n",
    "\n",
    "```python\n",
    "opt.step()\n",
    "opt.zero_grad()\n",
    "```\n",
    "\n",
    "(`optim.zero_grad()` resets the gradient to 0 and we need to call it before computing the gradient for the next minibatch.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(nn.Linear(m,nh), nn.ReLU(), nn.Linear(nh,10))\n",
    "    return model, optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3356, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "loss_func(model(xb), yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        start_i = i*bs\n",
    "        end_i = start_i+bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2757, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomized tests can be very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert acc>0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's clunky to iterate through minibatches of x and y values separately:\n",
    "\n",
    "```python\n",
    "    xb = x_train[start_i:end_i]\n",
    "    yb = y_train[start_i:end_i]\n",
    "```\n",
    "\n",
    "Instead, let's do these two steps together, by introducing a `Dataset` class:\n",
    "\n",
    "```python\n",
    "    xb,yb = train_ds[i*bs : i*bs+bs]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Dataset():\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, i): return self.x[i],self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,valid_ds = Dataset(x_train, y_train),Dataset(x_valid, y_valid)\n",
    "assert len(train_ds)==len(x_train)\n",
    "assert len(valid_ds)==len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([5, 0, 4, 1, 9]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = train_ds[0:5]\n",
    "assert xb.shape==(5,28*28)\n",
    "assert yb.shape==(5,)\n",
    "xb,yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range((n-1)//bs + 1):\n",
    "        xb,yb = train_ds[i*bs : i*bs+bs]\n",
    "        pred = model(xb)\n",
    "        loss = loss_func(pred, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2757, grad_fn=<NllLossBackward>), tensor(0.9375))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc>0.7\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously, our loop iterated over batches (xb, yb) like this:\n",
    "\n",
    "```python\n",
    "for i in range((n-1)//bs + 1):\n",
    "    xb,yb = train_ds[i*bs : i*bs+bs]\n",
    "    pred = model(xb)\n",
    "```\n",
    "\n",
    "Let's make our loop much cleaner, using a data loader:\n",
    "\n",
    "```python\n",
    "for xb,yb in train_dl:\n",
    "    pred = model(xb)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, bs): self.ds,self.bs = ds,bs\n",
    "    def __iter__(self):\n",
    "        for i in range(0, len(self.ds), self.bs): yield self.ds[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs)\n",
    "valid_dl = DataLoader(valid_ds, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = next(iter(valid_dl))\n",
    "assert xb.shape==(bs,28*28)\n",
    "assert yb.shape==(bs,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for xb,yb in train_dl:\n",
    "            pred = model(xb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1232, grad_fn=<NllLossBackward>), tensor(0.9688))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc>0.7\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want our training set to be in a random order, and that order should differ each iteration. But the validation set shouldn't be randomized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(b):\n",
    "    xs,ys = zip(*b)\n",
    "    return torch.stack(xs),torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader():\n",
    "    def __init__(self, ds, sampler): self.ds,self.sampler = ds,sampler\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for s in self.sampler: yield collate([self.ds[i] for i in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler():\n",
    "    def __init__(self, ds, bs, shuffle=False):\n",
    "        self.n,self.bs,self.shuffle = len(ds),bs,shuffle\n",
    "        \n",
    "    def __iter__(self):\n",
    "        self.idxs = torch.randperm(self.n) if self.shuffle else torch.arange(self.n)\n",
    "        for i in range(0, self.n, self.bs): yield self.idxs[i:i+self.bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_ds = Dataset(*train_ds[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0, 1, 2]), tensor([3, 4, 5]), tensor([6, 7, 8]), tensor([9])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Sampler(small_ds,3,False)\n",
    "[o for o in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([8, 6, 2]), tensor([1, 7, 3]), tensor([9, 0, 5]), tensor([4])]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = Sampler(small_ds,3,True)\n",
    "[o for o in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samp = Sampler(train_ds, bs, shuffle=True)\n",
    "valid_samp = Sampler(valid_ds, bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, train_samp)\n",
    "valid_dl = DataLoader(valid_ds, valid_samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb,yb = next(iter(valid_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb,yb = next(iter(train_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xb,yb = next(iter(train_dl))\n",
    "plt.imshow(xb[0].view(28,28))\n",
    "yb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1521, grad_fn=<NllLossBackward>), tensor(0.9531))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "\n",
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc>0.7\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, sampler=RandomSampler(train_ds), collate_fn=collate)\n",
    "valid_dl = DataLoader(valid_ds, bs, sampler=SequentialSampler(valid_ds), collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1507, grad_fn=<NllLossBackward>), tensor(0.9531))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "loss_func(model(xb), yb), accuracy(model(xb), yb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch's defaults work fine for most things however:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_ds, bs, shuffle=True, drop_last=True)\n",
    "valid_dl = DataLoader(valid_ds, bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1555, grad_fn=<NllLossBackward>), tensor(0.9062))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model,opt = get_model()\n",
    "fit()\n",
    "\n",
    "loss,acc = loss_func(model(xb), yb), accuracy(model(xb), yb)\n",
    "assert acc>0.7\n",
    "loss,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You **always** should also have a [validation set](http://www.fast.ai/2017/11/13/validation-sets/), in order to identify if you are overfitting.\n",
    "\n",
    "We will calculate and print the validation loss at the end of each epoch.\n",
    "\n",
    "(Note that we always call `model.train()` before training, and `model.eval()` before inference, because these are used by layers such as `nn.BatchNorm2d` and `nn.Dropout` to ensure appropriate behaviour for these different phases.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for xb,yb in train_dl:\n",
    "            loss = loss_func(model(xb), yb)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            tot_loss,tot_acc = 0.,0.\n",
    "            for xb,yb in valid_dl:\n",
    "                pred = model(xb)\n",
    "                tot_loss += loss_func(pred, yb)\n",
    "                tot_acc  += accuracy (pred,yb)\n",
    "        nv = len(valid_dl)\n",
    "        print(epoch, tot_loss/nv, tot_acc/nv)\n",
    "    return tot_loss/nv, tot_acc/nv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Question*: Are these validation results correct is batch size varies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_dls` returns dataloaders for the training and validation sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_dls(train_ds, valid_ds, bs):\n",
    "    return (DataLoader(train_ds, batch_size=bs, shuffle=True),\n",
    "            DataLoader(valid_ds, batch_size=bs*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our whole process of obtaining the data loaders and fitting the model can be run in 3 lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.1379) tensor(0.9611)\n",
      "1 tensor(0.1489) tensor(0.9545)\n",
      "2 tensor(0.1037) tensor(0.9674)\n",
      "3 tensor(0.0992) tensor(0.9696)\n",
      "4 tensor(0.1617) tensor(0.9514)\n"
     ]
    }
   ],
   "source": [
    "train_dl,valid_dl = get_dls(train_ds, valid_ds, bs)\n",
    "model,opt = get_model()\n",
    "loss,acc = fit(5, model, loss_func, opt, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert acc>0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 03_minibatch_training.ipynb to nb_03.py\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py 03_minibatch_training.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
