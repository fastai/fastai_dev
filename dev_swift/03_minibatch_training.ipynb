{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages:\n",
      "\t.package(path: \"/home/clattner/fastai_docs/dev_swift/FastaiNotebook_02a_why_sqrt5\")\n",
      "\t\tFastaiNotebook_02a_why_sqrt5\n",
      "With SwiftPM flags: []\n",
      "Working in: /tmp/tmpy_i3hj89\n",
      "/home/clattner/swift/usr/bin/swift-build: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/lib/swift/linux/libFoundation.so)\n",
      "Fetching https://github.com/mxcl/Path.swift\n",
      "Fetching https://github.com/JustHTTP/Just\n",
      "Fetching https://github.com/latenitesoft/NotebookExport\n",
      "Completed resolution in 2.46s\n",
      "Cloning https://github.com/latenitesoft/NotebookExport\n",
      "Resolving https://github.com/latenitesoft/NotebookExport at 0.5.0\n",
      "Cloning https://github.com/mxcl/Path.swift\n",
      "Resolving https://github.com/mxcl/Path.swift at 0.16.2\n",
      "Cloning https://github.com/JustHTTP/Just\n",
      "Resolving https://github.com/JustHTTP/Just at 0.7.1\n",
      "/home/clattner/swift/usr/bin/swiftc: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swiftc)\n",
      "Compile Swift Module 'Just' (1 sources)\n",
      "Compile Swift Module 'Path' (9 sources)\n",
      "/home/clattner/swift/usr/bin/swiftc: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swiftc)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swiftc: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swiftc)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "Compile Swift Module 'NotebookExport' (2 sources)\n",
      "/home/clattner/swift/usr/bin/swiftc: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swiftc)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "Compile Swift Module 'FastaiNotebook_00_load_data' (1 sources)\n",
      "/home/clattner/swift/usr/bin/swiftc: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swiftc)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "Compile Swift Module 'FastaiNotebook_01_matmul' (2 sources)\n",
      "/home/clattner/swift/usr/bin/swiftc: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swiftc)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "Compile Swift Module 'FastaiNotebook_01a_fastai_layers' (3 sources)\n",
      "/home/clattner/swift/usr/bin/swiftc: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swiftc)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "Compile Swift Module 'FastaiNotebook_02_fully_connected' (4 sources)\n",
      "/home/clattner/swift/usr/bin/swiftc: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swiftc)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "Compile Swift Module 'FastaiNotebook_02a_why_sqrt5' (5 sources)\n",
      "/home/clattner/swift/usr/bin/swiftc: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swiftc)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "Compile Swift Module 'jupyterInstalledPackages' (1 sources)\n",
      "/home/clattner/swift/usr/bin/swiftc: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swiftc)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift)\n",
      "\n",
      "Linking ./.build/x86_64-unknown-linux/debug/libjupyterInstalledPackages.so\n",
      "/home/clattner/swift/usr/bin/swiftc: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swiftc)\n",
      "\n",
      "/home/clattner/swift/usr/bin/swift-autolink-extract: /home/clattner/anaconda3/envs/swift/lib/libuuid.so.1: no version information available (required by /home/clattner/swift/usr/bin/swift-autolink-extract)\n",
      "\n",
      "Initializing Swift...\n",
      "Loading library...\n",
      "Installation complete!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "error: <Cell 1>:1:18: error: consecutive statements on a line must be separated by ';'\n%install-location $cwd/swift-install\n                 ^\n                 ;\n\n"
     ]
    }
   ],
   "source": [
    "%install-location $cwd/swift-install\n",
    "%install '.package(path: \"$cwd/FastaiNotebook_02a_why_sqrt5\")' FastaiNotebook_02a_why_sqrt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "import Path\n",
    "import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FastaiNotebook_02a_why_sqrt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// export\n",
    "public typealias TI = Tensor<Int32>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fatal error: failed initializing StreamExecutor for CUDA device ordinal 0: Internal: failed call to cuDevicePrimaryCtxRetain: CUDA_ERROR_OUT_OF_MEMORY: out of memory; total memory reported: 17071734784: file /swift-base/swift/stdlib/public/TensorFlow/CompilerRuntime.swift, line 682\r\n",
      "Current stack trace:\r\n",
      "0    libswiftCore.so                    0x00007fcb495db410 _swift_stdlib_reportFatalErrorInFile + 115\r\n",
      "1    libswiftCore.so                    0x00007fcb4952338c <unavailable> + 3036044\r\n",
      "2    libswiftCore.so                    0x00007fcb4952347e <unavailable> + 3036286\r\n",
      "3    libswiftCore.so                    0x00007fcb4936a742 <unavailable> + 1230658\r\n",
      "4    libswiftCore.so                    0x00007fcb494f0312 <unavailable> + 2827026\r\n",
      "5    libswiftCore.so                    0x00007fcb49369c29 <unavailable> + 1227817\r\n",
      "6    libswiftTensorFlow.so              0x00007fcb46569512 <unavailable> + 599314\r\n",
      "7    libswiftTensorFlow.so              0x00007fcb46567c60 checkOk(_:file:line:) + 508\r\n",
      "8    libswiftTensorFlow.so              0x00007fcb46572e50 _ExecutionContext.init() + 1959\r\n",
      "9    libswiftTensorFlow.so              0x00007fcb46572c20 _ExecutionContext.__allocating_init() + 64\r\n",
      "10   libswiftTensorFlow.so              0x00007fcb46572c0c <unavailable> + 637964\r\n",
      "11   libpthread.so.0                    0x00007fcb5a9e1827 <unavailable> + 63527\r\n",
      "12   libswiftCore.so                    0x00007fcb4959e490 swift_once + 102\r\n",
      "13   libswiftTensorFlow.so              0x00007fcb4656b960 _ExecutionContext.global.unsafeMutableAddressor + 23\r\n",
      "14   libswiftTensorFlow.so              0x00007fcb46569ab0 _TFCGetGlobalEagerContext() + 98\r\n",
      "15   libswiftTensorFlow.so              0x00007fcb465864c0 _swift_tfc_GetGlobalEagerContext + 9\r\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "Current stack trace:",
      "\tframe #15: 0x00007fcb46cfbd25 libjupyterInstalledPackages.so`loadMNIST<A>(training=true, labels=false, path=(string = \"/home/clattner/.fastai/data/mnist_tst\"), flat=true) at 00_load_data.swift:72:40",
      "\tframe #16: 0x00007fcb46cfbf2a libjupyterInstalledPackages.so`loadMNIST(path=(string = \"/home/clattner/.fastai/data/mnist_tst\"), flat=true) at 00_load_data.swift:79:9",
      "\tframe #17: 0x00007fcb75cad69a $__lldb_expr45`main at <Cell 5>:1:37"
     ]
    }
   ],
   "source": [
    "var (xTrain,yTrain,xValid,yValid) = loadMNIST(path: Path.home/\".fastai\"/\"data\"/\"mnist_tst\", flat: true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let trainMean = xTrain.mean()\n",
    "let trainStd  = xTrain.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain = normalize(xTrain, mean: trainMean, std: trainStd)\n",
    "xValid = normalize(xValid, mean: trainMean, std: trainStd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let (n,m) = (xTrain.shape[0],xTrain.shape[1])\n",
    "let c = yTrain.max().scalarized()+1\n",
    "print(n,m,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let nHid = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public struct MyModel: Layer {\n",
    "    public var layer1: FADense<Float>\n",
    "    public var layer2: FADense<Float>\n",
    "    \n",
    "    public init(nIn: Int, nHid: Int, nOut: Int){\n",
    "        layer1 = FADense(nIn, nHid, activation: relu)\n",
    "        layer2 = FADense(nHid, nOut)\n",
    "    }\n",
    "    \n",
    "    @differentiable\n",
    "    public func call(_ input: TF) -> TF {\n",
    "        return input.sequenced(through: layer1, layer2)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var model = MyModel(nIn: m, nHid: nHid, nOut: Int(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let pred = model(xTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func logSoftmax<Scalar>(_ activations: Tensor<Scalar>) -> Tensor<Scalar> where Scalar:TensorFlowFloatingPoint{\n",
    "    let exped = exp(activations) \n",
    "    return log(exped / exped.sum(alongAxes: -1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let smPred = logSoftmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 0, 4]\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTrain[0..<3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "‚ñø 3 elements\n",
       "  - .0 : -3.4204087\n",
       "  - .1 : -2.1114194\n",
       "  - .2 : -2.6280856\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(smPred[0][5],smPred[1][0],smPred[2][4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no fancy indexing yet so we have to use gather to get the indices we want out of our softmaxed predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func nll<Scalar>(_ input: Tensor<Scalar>, _ target :TI) -> Tensor<Scalar> \n",
    "    where Scalar:TensorFlowFloatingPoint{\n",
    "        let idx: TI = Raw.range(start: Tensor(0), limit: Tensor(60000), delta: Tensor(1))\n",
    "        let indices = Raw.concat(concatDim: Tensor(1), [idx.expandingShape(at: 1), target.expandingShape(at: 1)])\n",
    "        let losses = Raw.gatherNd(params: input, indices: indices)\n",
    "        return -losses.mean()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5361195\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll(smPred, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average: 0.9588508400000002 ms,   min: 0.903631 ms,   max: 1.073547 ms\r\n"
     ]
    }
   ],
   "source": [
    "time(repeating: 100){ let _ = nll(smPred, yTrain) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simplify `logSoftmax` with log formulas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func logSoftmax<Scalar>(_ activations: Tensor<Scalar>) -> Tensor<Scalar> where Scalar:TensorFlowFloatingPoint{\n",
    "    return activations - log(exp(activations).sum(alongAxes: -1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let smPred = logSoftmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5361195\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll(smPred, yTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use LogSumExp trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "‚ñø [60000, 1]\n",
       "  ‚ñø dimensions : 2 elements\n",
       "    - 0 : 60000\n",
       "    - 1 : 1\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smPred.max(alongAxes: -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func logSumExp<Scalar>(_ x: Tensor<Scalar>) -> Tensor<Scalar> where Scalar:TensorFlowFloatingPoint{\n",
    "    let m = x.max(alongAxes: -1)\n",
    "    return m + log(exp(x-m).sum(alongAxes: -1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func logSoftmax<Scalar>(_ activations: Tensor<Scalar>) -> Tensor<Scalar> where Scalar:TensorFlowFloatingPoint{\n",
    "    return activations - logSumExp(activations)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let smPred = logSoftmax(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5361195\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nll(smPred, yTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In S4TF nll loss is combined with softmax in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5361195\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let loss = softmaxCrossEntropy(logits: pred, labels: yTrain)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average: 1.13397705 ms,   min: 1.073414 ms,   max: 1.246404 ms\r\n"
     ]
    }
   ],
   "source": [
    "time(repeating: 100){ let _ = nll(logSoftmax(pred), yTrain)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average: 1.1167375999999993 ms,   min: 1.029799 ms,   max: 1.146573 ms\r\n"
     ]
    }
   ],
   "source": [
    "time(repeating: 100){ let _ = softmaxCrossEntropy(logits: pred, labels: yTrain)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic training loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically the training loop repeats over the following steps:\n",
    "- get the output of the model on a batch of inputs\n",
    "- compare the output to the labels we have and compute a loss\n",
    "- calculate the gradients of the loss with respect to every parameter of the model\n",
    "- update said parameters with those gradients to make them a little bit better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// export\n",
    "public func accuracy(_ output: TF, _ target: TI) -> TF{\n",
    "    let corrects = TF(output.argmax(squeezingAxis: 1) .== target)\n",
    "    return corrects.mean()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.053316668\r\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(pred, yTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.23664445,      2.04683,   -1.1999371,   -0.8093258,  -0.39569956,   -0.6040486,\r\n",
      " -0.037230372,  0.024000853,   0.84425664,     0.354469] [64, 10]\r\n"
     ]
    }
   ],
   "source": [
    "let bs=64                         // batch size\n",
    "let xb = xTrain[0..<bs]          // a mini-batch from x\n",
    "let preds = model(xb) //predictions\n",
    "print(preds[0], preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let yb = yTrain[0..<bs]\n",
    "let loss = softmaxCrossEntropy(logits: preds, labels: yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.046875\r\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(preds, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let lr:Float = 0.5   // learning rate\n",
    "let epochs = 1      // how many epochs to train for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let (loss, grads) = model.valueWithGradient { model -> TF in\n",
    "    let preds = model(xb)\n",
    "    return softmaxCrossEntropy(logits: preds, labels: yb)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in 1 ... epochs {\n",
    "    for i in 0 ..< (n-1)/bs {\n",
    "        let startIdx = i * bs\n",
    "        let endIdx = startIdx + bs\n",
    "        let xb = xTrain[startIdx..<endIdx]\n",
    "        let yb = yTrain[startIdx..<endIdx]\n",
    "        let (loss, grads) = model.valueWithGradient { model -> TF in\n",
    "            let preds = model(xb)\n",
    "            return softmaxCrossEntropy(logits: preds, labels: yb)\n",
    "        }\n",
    "        model.layer1.weight -= lr * grads.layer1.weight\n",
    "        model.layer1.bias   -= lr * grads.layer1.bias\n",
    "        model.layer2.weight -= lr * grads.layer2.weight\n",
    "        model.layer2.bias   -= lr * grads.layer2.bias\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8894\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let preds = model(xValid)\n",
    "accuracy(preds, yValid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "86% in one epoch, not too bad!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naming all the parameters is a bit boring. We can use keyPaths objects to access them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in 1 ... epochs{\n",
    "    for i in 0 ..< (n-1)/bs {\n",
    "        let startIdx = i * bs\n",
    "        let endIdx = startIdx + bs\n",
    "        let xb = xTrain[startIdx..<endIdx]\n",
    "        let yb = yTrain[startIdx..<endIdx]\n",
    "        let (loss, grads) = model.valueWithGradient { model -> TF in\n",
    "            let preds = model(xb)\n",
    "            return softmaxCrossEntropy(logits: preds, labels: yb)\n",
    "        }\n",
    "        var parameters = model.variables\n",
    "        for kp in parameters.keyPaths{ \n",
    "            parameters[keyPath: kp] -= lr * grads[keyPath: kp]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use a S4TF optimizer to do the step for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let optimizer = SGD(for: model, learningRate: lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in 1 ... epochs{\n",
    "    for i in 0 ..< (n-1)/bs {\n",
    "        let startIdx = i * bs\n",
    "        let endIdx = startIdx + bs\n",
    "        let xb = xTrain[startIdx..<endIdx]\n",
    "        let yb = yTrain[startIdx..<endIdx]\n",
    "        let (loss, grads) = model.valueWithGradient { model -> TF in\n",
    "            let preds = model(xb)\n",
    "            return softmaxCrossEntropy(logits: preds, labels: yb)\n",
    "        }\n",
    "        optimizer.update(&model.allDifferentiableVariables, along: grads)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a swift `Dataset` from our arrays. It will automatically batch things for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// export\n",
    "public struct DataBatch<Inputs: Differentiable & TensorGroup, Labels: TensorGroup>: TensorGroup {\n",
    "    public var xb: Inputs\n",
    "    public var yb: Labels    \n",
    "    \n",
    "    public init(xb: Inputs, yb: Labels){ (self.xb,self.yb) = (xb,yb) }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let train_ds:Dataset<DataBatch> = Dataset(elements:DataBatch(xb:xTrain, yb:yTrain)).batched(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in 1...epochs{\n",
    "    for batch in train_ds{\n",
    "        let (loss, grads) = model.valueWithGradient { model -> TF in\n",
    "            let preds = model(batch.xb)\n",
    "            return softmaxCrossEntropy(logits: preds, labels: batch.yb)\n",
    "        }\n",
    "        optimizer.update(&model.allDifferentiableVariables, along: grads)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `Dataset` can also do the shuffle for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in 1...epochs{\n",
    "    for batch in train_ds.shuffled(sampleCount: 60000, randomSeed: 42){\n",
    "        let (loss, grads) = model.valueWithGradient { model -> TF in\n",
    "            let preds = model(batch.xb)\n",
    "            return softmaxCrossEntropy(logits: preds, labels: batch.yb)\n",
    "        }\n",
    "        optimizer.update(&model.allDifferentiableVariables, along: grads)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public func train<Opt: Optimizer, Label:TensorGroup>(\n",
    "    _ model: inout Opt.Model,\n",
    "    on ds: Dataset<DataBatch<Opt.Model.Input, Label>>,\n",
    "    using opt: inout Opt,\n",
    "    lossFunc: @escaping @differentiable (Opt.Model.Output, @nondiff Label) -> Tensor<Opt.Scalar>\n",
    ") where Opt.Model: Layer,\n",
    "        Opt.Model.Input: TensorGroup,\n",
    "        Opt.Model.CotangentVector == Opt.Model.AllDifferentiableVariables,\n",
    "        Opt.Scalar: TensorFlowFloatingPoint\n",
    "{\n",
    "    for batch in ds {\n",
    "        let (loss, ùõÅmodel) = model.valueWithGradient { model -> Tensor<Opt.Scalar> in \n",
    "            let pred = model(batch.xb)                                      \n",
    "            return lossFunc(pred, batch.yb)\n",
    "        }\n",
    "        opt.update(&model.allDifferentiableVariables, along: ùõÅmodel)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var model = MyModel(nIn: m, nHid: nHid, nOut: Int(c))\n",
    "var optimizer = SGD(for: model, learningRate: lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(&model, on: train_ds, using: &optimizer, lossFunc: softmaxCrossEntropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9052\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "let preds = model(xValid)\n",
    "accuracy(preds, yValid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\r\n"
     ]
    }
   ],
   "source": [
    "import NotebookExport\n",
    "let exporter = NotebookExport(Path.cwd/\"03_minibatch_training.ipynb\")\n",
    "print(exporter.export(usingPrefix: \"FastaiNotebook_\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
