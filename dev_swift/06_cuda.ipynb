{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A CNN Mnist Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages:\n",
      "\t.package(path: \"/home/ubuntu/fastai_docs/dev_swift/FastaiNotebook_05b_early_stopping\")\n",
      "\t\tFastaiNotebook_05b_early_stopping\n",
      "With SwiftPM flags: []\n",
      "Working in: /tmp/tmpi9bdeq36/swift-install\n",
      "Compile Swift Module 'FastaiNotebook_05b_early_stopping' (9 sources)\n",
      "Compile Swift Module 'jupyterInstalledPackages' (1 sources)\n",
      "Compile Swift Module 'FastaiNotebook_05_anneal' (8 sources)\n",
      "Compile Swift Module 'FastaiNotebook_04_callbacks' (7 sources)\n",
      "Compile Swift Module 'FastaiNotebook_03_minibatch_training' (6 sources)\n",
      "Compile Swift Module 'FastaiNotebook_02a_why_sqrt5' (5 sources)\n",
      "Linking ./.build/x86_64-unknown-linux/debug/libjupyterInstalledPackages.so\n",
      "Compile Swift Module 'FastaiNotebook_02_fully_connected' (4 sources)\n",
      "Compile Swift Module 'FastaiNotebook_01a_fastai_layers' (3 sources)\n",
      "Compile Swift Module 'FastaiNotebook_01_matmul' (2 sources)\n",
      "Initializing Swift...\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "%install-location $cwd/swift-install\n",
    "%install '.package(path: \"$cwd/FastaiNotebook_05b_early_stopping\")' FastaiNotebook_05b_early_stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "import FastaiNotebook_05b_early_stopping\n",
    "import Path\n",
    "import TensorFlow\n",
    "import Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('inline', 'module://ipykernel.pylab.backend_inline')\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%include \"EnableIPythonDisplay.swift\"\n",
    "IPythonDisplay.shell.enable_matplotlib(\"inline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let data = mnistDataBunch(flat: false, bs: 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 512\r\n",
      "Example side size: 28\r\n",
      "Class count: 512\r\n"
     ]
    }
   ],
   "source": [
    "let firstBatch = data.train.ds.first(where: { _ in true })!\n",
    "let batchShape = firstBatch.xb.shape\n",
    "let batchSize = batchShape.dimensions[0]\n",
    "let exampleSideSize = batchShape.dimensions[1]\n",
    "assert(exampleSideSize == batchShape.dimensions[2])\n",
    "print(\"Batch size: \\(batchSize)\")\n",
    "print(\"Example side size: \\(exampleSideSize)\")\n",
    "\n",
    "let classCount = firstBatch.yb.shape.dimensions[0]\n",
    "print(\"Class count: \\(classCount)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "▿ TensorShape\n",
       "  ▿ dimensions : 3 elements\n",
       "    - 0 : 512\n",
       "    - 1 : 28\n",
       "    - 2 : 28\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firstBatch.xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// export\n",
    "extension Learner {\n",
    "    public class AddChannel: Delegate {\n",
    "        public override func batchWillStart(learner: Learner) {\n",
    "            learner.currentInput = learner.currentInput!.expandingShape(at: -1)\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    public func makeAddChannel() -> AddChannel { return AddChannel() }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "extension Array: Layer where Element: Layer, Element.Input == Element.Output {\n",
    "    public typealias Input = Element.Input\n",
    "    public typealias Output = Element.Output\n",
    "    \n",
    "    @differentiable(vjp: _vjpApplied)\n",
    "    public func call(_ input: Input) -> Output {\n",
    "        var activation = input\n",
    "        for layer in self {\n",
    "            activation = layer(activation)\n",
    "        }\n",
    "        return activation\n",
    "    }\n",
    "    \n",
    "    public func _vjpApplied(_ input: Input)\n",
    "        -> (Output, (Output.CotangentVector) -> (Array.CotangentVector, Input.CotangentVector))\n",
    "    {\n",
    "        var activation = input\n",
    "        var pullbacks: [(Input.CotangentVector) -> (Element.CotangentVector, Input.CotangentVector)] = []\n",
    "        for layer in self {\n",
    "            let (newActivation, newPullback) = layer.valueWithPullback(at: activation) { $0($1) }\n",
    "            activation = newActivation\n",
    "            pullbacks.append(newPullback)\n",
    "        }\n",
    "        func pullback(_ v: Input.CotangentVector) -> (Array.CotangentVector, Input.CotangentVector) {\n",
    "            var activationGradient = v\n",
    "            var layerGradients: [Element.CotangentVector] = []\n",
    "            for pullback in pullbacks.reversed() {\n",
    "                let (newLayerGradient, newActivationGradient) = pullback(activationGradient)\n",
    "                activationGradient = newActivationGradient\n",
    "                layerGradients.append(newLayerGradient)\n",
    "            }\n",
    "            return (Array.CotangentVector(layerGradients.reversed()), activationGradient)\n",
    "        }\n",
    "        return (activation, pullback)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "error: <Cell 8>:24:41: error: argument type '[FAConv2D<Float>]' does not conform to expected type 'Layer'\n        return input.sequenced(through: convs, pool, flatten, linear)\n                                        ^\n\n"
     ]
    }
   ],
   "source": [
    "//export \n",
    "public func conv<Scalar>(_ cIn: Int, _ cOut: Int, ks: Int = 3, stride: Int = 2) -> FAConv2D<Scalar> {\n",
    "    return FAConv2D<Scalar>(filterShape: (ks, ks, cIn, cOut), \n",
    "                            strides: (stride,stride), \n",
    "                            padding: .same, \n",
    "                            activation: relu)\n",
    "}\n",
    "\n",
    "public struct CnnModel: Layer {\n",
    "    public var convs: [FAConv2D<Float>]\n",
    "    public var pool = FAAdaptiveAvgPool2D<Float>()\n",
    "    public var flatten = Flatten<Float>()\n",
    "    public var linear: FADense<Float>\n",
    "    \n",
    "    public init(channelIn: Int, nOut: Int, filters: [Int]){\n",
    "        convs = []\n",
    "        let allFilters = [channelIn] + filters\n",
    "        for i in 0..<filters.count { convs.append(conv(allFilters[i], allFilters[i+1])) }\n",
    "        linear = FADense<Float>(inputSize: filters.last!, outputSize: nOut)\n",
    "    }\n",
    "    \n",
    "    @differentiable\n",
    "    public func call(_ input: TF) -> TF {\n",
    "        return input.sequenced(through: convs, pool, flatten, linear)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let model = CnnModel(channelIn: 1, nOut: 10, filters: [8, 16, 32, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Test that data goes through the model as expected.\n",
    "let predictions = model(firstBatch.xb.expandingShape(at: -1))\n",
    "print(predictions.shape)\n",
    "print(predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare training on CPU and GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func optFunc(_ model: CnnModel) -> SGD<CnnModel> { return SGD(for: model, learningRate: 0.4)}\n",
    "func modelInit() -> CnnModel { return CnnModel(channelIn: 1, nOut: 10, filters: [8, 16, 32, 32]) }\n",
    "let learner = Learner(data: data, lossFunc: softmaxCrossEntropy, optFunc: optFunc, modelInit: modelInit)\n",
    "let recorder = learner.makeDefaultDelegates(metrics: [accuracy])\n",
    "learner.addDelegates([learner.makeNormalize(mean: mnistStats.mean, std: mnistStats.std),\n",
    "                      learner.makeAddChannel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// This happens on the GPU (if you have one and it's configured correctly).\n",
    "// I tried this on a GCE 8vCPU 30GB + Tesla P100:\n",
    "// - time: ~4.3s\n",
    "// - nvidia-smi shows ~10% GPU-Util while this is running\n",
    "time { try! learner.fit(1) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// This happens on the CPU.\n",
    "// I tried this on a GCE 8vCPU 30GB + Tesla P100:\n",
    "// - time: ~6.3s\n",
    "// - nvidia-smi shows 0% GPU-Util while this is running\n",
    "time {\n",
    "    withDevice(.cpu) { try! learner.fit(1) }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect Layer Activation Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationStatistics: LayerDelegate<Tensor<Float>> {\n",
    "    var activationMeans: [Float] = []\n",
    "    var activationStds: [Float] = []    \n",
    "    override func didProduceActivation(_ activation: Tensor<Float>) {\n",
    "        activationMeans.append(activation.mean().scalar!)\n",
    "        activationStds.append(activation.standardDeviation().reshaped(to: []).scalar!)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension KeyPathIterable {    \n",
    "    mutating func initializeLayerDelegates<T>(with initializer: () -> LayerDelegate<T>) {\n",
    "        for kp in recursivelyAllWritableKeyPaths(to: LayerDelegate<T>.self) {\n",
    "            self[keyPath: kp] = initializer()\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    func layerDelegates<T, D: LayerDelegate<T>>(havingType: D.Type) -> [D] {\n",
    "        var result: [D] = []\n",
    "        for kp in recursivelyAllWritableKeyPaths(to: LayerDelegate<T>.self) {\n",
    "            guard let d = self[keyPath: kp] as? D else { continue }\n",
    "            result.append(d)\n",
    "        }\n",
    "        return result\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let learner = Learner(data: data, lossFunc: softmaxCrossEntropy, optFunc: optFunc, modelInit: modelInit)\n",
    "let recorder = learner.makeDefaultDelegates(metrics: [accuracy])\n",
    "learner.addDelegates([learner.makeNormalize(mean: mnistStats.mean, std: mnistStats.std),\n",
    "                      learner.makeAddChannel()])\n",
    "\n",
    "learner.model.initializeLayerDelegates(with: { ActivationStatistics() })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// This LayerDelegate stuff slows it down to ~6s/epoch.\n",
    "time { try! learner.fit(2) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "let activationStatistics = learner.model.layerDelegates(havingType: ActivationStatistics.self)\n",
    "for stats in activationStatistics {\n",
    "    plt.plot(stats.activationMeans)\n",
    "}\n",
    "plt.legend(Array(1...activationStatistics.count))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stats in activationStatistics {\n",
    "    plt.plot(stats.activationStds)\n",
    "}\n",
    "plt.legend(Array(1...activationStatistics.count))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebookToScript(fname: (Path.cwd / \"06_cuda.ipynb\").string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
