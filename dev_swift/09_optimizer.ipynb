{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages:\n",
      "\t.package(path: \"/usr/local/google/home/jekbradbury/fastai_docs/dev_swift/FastaiNotebook_08a_heterogeneous_dictionary\")\n",
      "\t\tFastaiNotebook_08a_heterogeneous_dictionary\n",
      "With SwiftPM flags: []\n",
      "Working in: /tmp/tmpy8z2fmjk\n",
      "Fetching https://github.com/mxcl/Path.swift\n",
      "Fetching https://github.com/JustHTTP/Just\n",
      "Completed resolution in 5.60s\n",
      "Cloning https://github.com/JustHTTP/Just\n",
      "Resolving https://github.com/JustHTTP/Just at 0.7.1\n",
      "Cloning https://github.com/mxcl/Path.swift\n",
      "Resolving https://github.com/mxcl/Path.swift at 0.16.2\n",
      "Compile Swift Module 'Path' (9 sources)\n",
      "Compile Swift Module 'Just' (1 sources)\n",
      "Compile Swift Module 'FastaiNotebook_08a_heterogeneous_dictionary' (13 sources)\n",
      "Compile Swift Module 'jupyterInstalledPackages' (1 sources)\n",
      "Linking ./.build/x86_64-unknown-linux/debug/libjupyterInstalledPackages.so\n",
      "Initializing Swift...\n",
      "Loading library...\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "%install '.package(path: \"$cwd/FastaiNotebook_08a_heterogeneous_dictionary\")' FastaiNotebook_08a_heterogeneous_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('inline', 'module://ipykernel.pylab.backend_inline')\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import FastaiNotebook_08a_heterogeneous_dictionary\n",
    "%include \"EnableIPythonDisplay.swift\"\n",
    "IPythonDisplay.shell.enable_matplotlib(\"inline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "// export\n",
    "import Path\n",
    "import TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://s3.amazonaws.com/fast-ai-imageclas/imagenette-160.tgz...\r\n"
     ]
    }
   ],
   "source": [
    "let path = downloadImagette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "let il = ItemList(fromFolder: path, extensions: [\"jpeg\", \"jpg\"])\n",
    "let sd = SplitData(il, fromFunc: {grandParentSplitter(fName: $0, valid: \"val\")})\n",
    "var (procItem,procLabel) = (NoopProcessor<Path>(),CategoryProcessor())\n",
    "let sld = SplitLabeledData(sd, fromFunc: parentLabeler, procItem: &procItem, procLabel: &procLabel)\n",
    "var rawData = sld.toDataBunch(itemToTensor: pathsToTensor, labelToTensor: intsToTensor)\n",
    "let data = transformData(rawData, tfmItem: { openAndResize(fname: $0, size: 128) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "let data = mnistDataBunch(flat: true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "let (n,m) = (60000,784)\n",
    "let c = 10\n",
    "let nHid = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "func modelInit() -> BasicModel {return BasicModel(nIn: m, nHid: nHid, nOut: c)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "open class StatDelegate<Scalar: TensorFlowFloatingPoint> {\n",
    "    open var name: String { return \"\" }\n",
    "    var defaultConfig: HeterogeneousDictionary { return HeterogeneousDictionary() }\n",
    "    func update(\n",
    "        state: inout [String: Tensor<Scalar>],\n",
    "        for param: Tensor<Scalar>,\n",
    "        along direction: Tensor<Scalar>,\n",
    "        config: inout HeterogeneousDictionary\n",
    "    ) { }\n",
    "}\n",
    "\n",
    "//export\n",
    "open class StepDelegate<Scalar: TensorFlowFloatingPoint> {\n",
    "    var defaultConfig: HeterogeneousDictionary { return HeterogeneousDictionary() }\n",
    "    func update(\n",
    "        param: inout Tensor<Scalar>,\n",
    "        along direction: inout Tensor<Scalar>,\n",
    "        state: [String: Tensor<Scalar>],\n",
    "        config: inout HeterogeneousDictionary\n",
    "    ) { }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "class StatefulOptimizer<Model: Layer,\n",
    "                        Scalar: TensorFlowFloatingPoint>: Optimizer\n",
    "    where Model.AllDifferentiableVariables == Model.CotangentVector{\n",
    "    var configs: [HeterogeneousDictionary]\n",
    "    var learningRate: Float {\n",
    "        get { return configs.last![LearningRate()] } \n",
    "        set { \n",
    "            for i in configs.indices {self.configs[i][LearningRate()] = newValue }\n",
    "        }\n",
    "    }\n",
    "    var learningRates: [Float] {\n",
    "        get {\n",
    "            var res: [Float] = []\n",
    "            for config in configs {res.append(config[LearningRate()])}\n",
    "            return res\n",
    "        }\n",
    "        set { \n",
    "            for i in configs.indices {self.configs[i][LearningRate()] = newValue[i] } \n",
    "        }\n",
    "    }\n",
    "    var splits: (Int) -> Int\n",
    "    var states: [String: Model.AllDifferentiableVariables]\n",
    "    var statDelegates: [StatDelegate<Scalar>]\n",
    "    var stepDelegates: [StepDelegate<Scalar>]\n",
    "    init(\n",
    "        stepDelegates: [StepDelegate<Scalar>],\n",
    "        statDelegates: [StatDelegate<Scalar>],\n",
    "        configs: [HeterogeneousDictionary],\n",
    "        splits: @escaping (Int) -> Int\n",
    "    ) {\n",
    "        self.configs = Array(repeating: HeterogeneousDictionary(), count: configs.count)\n",
    "        states = [:]\n",
    "        for stepDelegate in stepDelegates {\n",
    "            for i in self.configs.indices { self.configs[i].merge(stepDelegate.defaultConfig) { (_, new) in new } }\n",
    "        }\n",
    "        for statDelegate in statDelegates {\n",
    "            for i in self.configs.indices { self.configs[i].merge(statDelegate.defaultConfig) { (_, new) in new } }\n",
    "            states[statDelegate.name] = Model.AllDifferentiableVariables.zero\n",
    "        }\n",
    "        for i in 0..<configs.count {\n",
    "            self.configs[i].merge(configs[i]) { (_, new) in new }\n",
    "        }\n",
    "        self.stepDelegates = stepDelegates\n",
    "        self.statDelegates = statDelegates\n",
    "        self.splits = splits\n",
    "    }\n",
    "        \n",
    "    func update(\n",
    "        _ model: inout Model.AllDifferentiableVariables,\n",
    "        along direction: Model.CotangentVector\n",
    "    ) {\n",
    "        for (i,kp) in model.recursivelyAllWritableKeyPaths(to: Tensor<Scalar>.self).enumerated() {\n",
    "            var grad = direction[keyPath: kp]\n",
    "            var state = states.mapValues(){$0[keyPath: kp]}\n",
    "            var config = configs[splits(i)]\n",
    "            for statDelegate in statDelegates {\n",
    "                statDelegate.update(\n",
    "                    state: &state,\n",
    "                    for: model[keyPath: kp],\n",
    "                    along: grad,\n",
    "                    config: &config\n",
    "                )\n",
    "            }\n",
    "            for n in states.keys { states[n]![keyPath: kp] = state[n]! }\n",
    "            for stepDelegate in stepDelegates {\n",
    "                stepDelegate.update(\n",
    "                    param: &model[keyPath: kp],\n",
    "                    along: &grad,\n",
    "                    state: state,\n",
    "                    config: &config\n",
    "                )\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "class SGDStep: StepDelegate<Float> {\n",
    "    override func update(\n",
    "        param: inout Tensor<Float>,\n",
    "        along direction: inout Tensor<Float>,\n",
    "        state: [String: Tensor<Float>],\n",
    "        config: inout HeterogeneousDictionary\n",
    "    ) {\n",
    "        param -= direction * config[LearningRate()]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "public struct WeightDecayKey: HetDictKey, Equatable {\n",
    "    public static var defaultValue: Float = 0.0\n",
    "}\n",
    "\n",
    "class WeightDecay: StepDelegate<Float> {\n",
    "    override func update(\n",
    "        param: inout Tensor<Float>,\n",
    "        along direction: inout Tensor<Float>,\n",
    "        state: [String: Tensor<Float>],\n",
    "        config: inout HeterogeneousDictionary\n",
    "    ) {\n",
    "        param *= 1 - config[LearningRate()] * config[WeightDecayKey()]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "\n",
    "class L2Regularization: StepDelegate<Float> {\n",
    "    override func update(\n",
    "        param: inout Tensor<Float>,\n",
    "        along direction: inout Tensor<Float>,\n",
    "        state: [String: Tensor<Float>],\n",
    "        config: inout HeterogeneousDictionary\n",
    "    ) {\n",
    "        direction += config[WeightDecayKey()] * param\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "\n",
    "public struct Momentum: HetDictKey, Equatable {\n",
    "    public static var defaultValue: Float = 0.9\n",
    "}\n",
    "\n",
    "public struct MomentumDampening: HetDictKey, Equatable {\n",
    "    public static var defaultValue: Float = 0.9\n",
    "}\n",
    "\n",
    "class AverageGrad: StatDelegate<Float> {\n",
    "    let dampened: Bool\n",
    "    init(dampened: Bool = false) { self.dampened = dampened }\n",
    "    override var name: String { return \"averageGrad\" }\n",
    "    override func update(\n",
    "        state: inout [String: Tensor<Float>],\n",
    "        for param: Tensor<Float>,\n",
    "        along direction: Tensor<Float>,\n",
    "        config: inout HeterogeneousDictionary\n",
    "    ) {\n",
    "        state[\"averageGrad\"]! *= config[Momentum()]\n",
    "        config[MomentumDampening()] = 1.0 - (dampened ? config[Momentum()] : 0.0)\n",
    "        state[\"averageGrad\"]! += config[MomentumDampening()] * direction\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "func split_func(_ a: Int) -> Int { return a < 2 ? 0 : 1 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "var configs = [HeterogeneousDictionary(LearningRate(), 0.0), HeterogeneousDictionary(LearningRate(), 0.01)]\n",
    "func opt(_ model: BasicModel) -> StatefulOptimizer<BasicModel, Float> {\n",
    "    return StatefulOptimizer(\n",
    "        stepDelegates: [SGDStep()],\n",
    "        statDelegates: [],\n",
    "        configs: configs,\n",
    "        splits: split_func)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "let learner = Learner(data: data, lossFunction: softmaxCrossEntropy, optimizer: opt, initializingWith: modelInit)\n",
    "let recorder = learner.makeDefaultDelegates(metrics: [accuracy])\n",
    "learner.delegates.append(learner.makeNormalize(mean: mnistStats.mean, std: mnistStats.std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "let params = learner.model.allDifferentiableVariables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    -0.046549, -0.0056212405,    0.04649705,   0.041535746,   -0.03871442,   -0.08179674,\r\n",
      "   -0.03968917,  -0.013780484,   0.051365733,   0.042979345,   0.014209886,   -0.07570091,\r\n",
      "   0.020541439,   -0.03300613,    0.04694891,   0.010562088,    0.03216306, -0.0078320345,\r\n",
      "     0.0676105,   -0.02969341,   0.029745907,    0.06272062,   -0.04326095,   0.008575076,\r\n",
      "   -0.07724032,  -0.039810453,   0.057117227,   0.030263104,   0.031303518,  -0.008565996,\r\n",
      "    0.06568537,      0.059534,  0.0016873064,  -0.034330063,   0.013239545,   0.055974327,\r\n",
      "  -0.021404885,   0.041099936,   0.038637787,  -0.016372196,  -0.014275174,   0.012478242,\r\n",
      "    0.02541998,    0.07681102,    0.05248556,    0.07618754,  -0.045867424,   -0.06004807,\r\n",
      "     0.0574056,   -0.03207307]\r\n",
      "0.0\r\n",
      "[ -0.1687389,  -0.2625489,  0.13653485,   0.2740094, -0.27290937,  0.17933364,  0.20196906,\r\n",
      "  0.12957323, -0.28662503,  0.12529063]\r\n",
      "0.0\r\n"
     ]
    }
   ],
   "source": [
    "for kp in params.recursivelyAllWritableKeyPaths(to: TF.self) { \n",
    "    print(params[keyPath: kp][0]) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: [1.1812385, 0.6439]                                                    \n",
      "Epoch 1: [0.98253614, 0.7015]                                                   \n",
      "                                                                              \r"
     ]
    }
   ],
   "source": [
    "learner.fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    -0.046549, -0.0056212405,    0.04649705,   0.041535746,   -0.03871442,   -0.08179674,\r\n",
      "   -0.03968917,  -0.013780484,   0.051365733,   0.042979345,   0.014209886,   -0.07570091,\r\n",
      "   0.020541439,   -0.03300613,    0.04694891,   0.010562088,    0.03216306, -0.0078320345,\r\n",
      "     0.0676105,   -0.02969341,   0.029745907,    0.06272062,   -0.04326095,   0.008575076,\r\n",
      "   -0.07724032,  -0.039810453,   0.057117227,   0.030263104,   0.031303518,  -0.008565996,\r\n",
      "    0.06568537,      0.059534,  0.0016873064,  -0.034330063,   0.013239545,   0.055974327,\r\n",
      "  -0.021404885,   0.041099936,   0.038637787,  -0.016372196,  -0.014275174,   0.012478242,\r\n",
      "    0.02541998,    0.07681102,    0.05248556,    0.07618754,  -0.045867424,   -0.06004807,\r\n",
      "     0.0574056,   -0.03207307]\r\n",
      "0.0\r\n",
      "[ -0.30932078,   0.18727356,   0.14484356, -0.049940858, -0.092392795,   0.12527509,\r\n",
      "   0.23155186,    0.3126535,  -0.50158757,     0.007534]\r\n",
      "-0.07913654\r\n"
     ]
    }
   ],
   "source": [
    "let params = learner.model.allDifferentiableVariables\n",
    "for kp in params.recursivelyAllWritableKeyPaths(to: TF.self) { \n",
    "    print(params[keyPath: kp][0]) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "class MomentumStep: StepDelegate<Float> {\n",
    "    override func update(\n",
    "        param: inout Tensor<Float>,\n",
    "        along direction: inout Tensor<Float>,\n",
    "        state: [String: Tensor<Float>],\n",
    "        config: inout HeterogeneousDictionary\n",
    "    ) {\n",
    "        param -= config[LearningRate()] * state[\"averageGrad\"]!\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "func opt(_ model: BasicModel) -> StatefulOptimizer<BasicModel, Float> {\n",
    "    return StatefulOptimizer(\n",
    "        stepDelegates: [MomentumStep()],\n",
    "        statDelegates: [AverageGrad()],\n",
    "        configs: configs,\n",
    "        splits: split_func)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "let learner = Learner(data: data, lossFunction: softmaxCrossEntropy, optimizer: opt, initializingWith: modelInit)\n",
    "let recorder = learner.makeDefaultDelegates(metrics: [accuracy])\n",
    "learner.delegates.append(learner.makeNormalize(mean: mnistStats.mean, std: mnistStats.std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: [0.8318388, 0.7328]                                                    \n",
      "Epoch 1: [0.788731, 0.7465]                                                     \n",
      "                                                                              \r"
     ]
    }
   ],
   "source": [
    "learner.fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "\n",
    "public struct SquareMomentum: HetDictKey, Equatable {\n",
    "    public static var defaultValue: Float = 0.99\n",
    "}\n",
    "\n",
    "public struct SquareMomentumDampening: HetDictKey, Equatable {\n",
    "    public static var defaultValue: Float = 0.99\n",
    "}\n",
    "\n",
    "\n",
    "class AverageSquaredGrad: StatDelegate<Float> {\n",
    "    let dampened: Bool\n",
    "    init(dampened: Bool = false) { self.dampened = dampened }\n",
    "    override var name: String { return \"averageSquaredGrad\" }\n",
    "    override func update(\n",
    "        state: inout [String: Tensor<Float>],\n",
    "        for param: Tensor<Float>,\n",
    "        along direction: Tensor<Float>,\n",
    "        config: inout HeterogeneousDictionary\n",
    "    ) {\n",
    "        state[\"averageSquaredGrad\"]! *= config[SquareMomentum()]\n",
    "        config[SquareMomentumDampening()] = 1.0 - (dampened ? config[SquareMomentum()] : 0.0)\n",
    "        state[\"averageSquaredGrad\"]! += config[SquareMomentumDampening()] * direction.squared()\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "class StepCount: StatDelegate<Float> {\n",
    "    override var name: String { return \"step\" }\n",
    "    override func update(\n",
    "        state: inout [String: Tensor<Float>],\n",
    "        for param: Tensor<Float>,\n",
    "        along direction: Tensor<Float>,\n",
    "        config: inout HeterogeneousDictionary\n",
    "    ) {\n",
    "        state[\"step\"]! += 1.0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "func debias<Scalar: TensorFlowFloatingPoint>(\n",
    "    momentum: Scalar,\n",
    "    dampening: Scalar,\n",
    "    step: Tensor<Scalar> \n",
    ") -> Tensor<Scalar> {\n",
    "    return dampening * (1 - pow(momentum, step)) / (1 - momentum)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "//export\n",
    "public struct Epsilon: HetDictKey, Equatable {\n",
    "    public static var defaultValue: Float = 1e-5\n",
    "}\n",
    "\n",
    "class AdamStep: StepDelegate<Float> {\n",
    "    override func update(\n",
    "        param: inout Tensor<Float>,\n",
    "        along direction: inout Tensor<Float>,\n",
    "        state: [String: Tensor<Float>],\n",
    "        config: inout HeterogeneousDictionary\n",
    "    ) {\n",
    "        let debiasedLearningRate = config[LearningRate()] / debias(\n",
    "            momentum: config[Momentum()],\n",
    "            dampening: config[MomentumDampening()],\n",
    "            step: state[\"step\"]!\n",
    "        )\n",
    "        let debiasedRMSGrad = sqrt(state[\"averageSquaredGrad\"]! / debias(\n",
    "            momentum: config[SquareMomentum()],\n",
    "            dampening: config[SquareMomentumDampening()],\n",
    "            step: state[\"step\"]!\n",
    "        )) + config[Epsilon()]\n",
    "        param -= debiasedLearningRate * state[\"averageGrad\"]! / debiasedRMSGrad\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "func opt(_ model: BasicModel) -> StatefulOptimizer<BasicModel, Float> {\n",
    "    return StatefulOptimizer(\n",
    "        stepDelegates: [AdamStep()], \n",
    "        statDelegates: [AverageGrad(), AverageSquaredGrad(), StepCount()], \n",
    "        configs: configs,\n",
    "        splits: split_func)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "let learner = Learner(data: data, lossFunction: softmaxCrossEntropy, optimizer: opt, initializingWith: modelInit)\n",
    "let recorder = learner.makeDefaultDelegates(metrics: [accuracy])\n",
    "learner.delegates.append(learner.makeNormalize(mean: mnistStats.mean, std: mnistStats.std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: [0.6520929, 0.7885]                                                    \n",
      "Epoch 1: [0.6512625, 0.7906]                                                    \n",
      "                                                                              \r"
     ]
    }
   ],
   "source": [
    "learner.fit(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambStep: StepDelegate<Float> {\n",
    "    override var defaultConfig: HeterogeneousDictionary {\n",
    "        return HeterogeneousDictionary(Epsilon(), 1e-6, WeightDecayKey(), 0.0)\n",
    "    }\n",
    "    override func update(\n",
    "        param: inout Tensor<Float>,\n",
    "        along direction: inout Tensor<Float>,\n",
    "        state: [String: Tensor<Float>],\n",
    "        config: inout HeterogeneousDictionary\n",
    "    ) {\n",
    "        let debiasedAverageGrad = state[\"averageGrad\"]! / debias(\n",
    "            momentum: config[Momentum()],\n",
    "            dampening: config[MomentumDampening()],\n",
    "            step: state[\"step\"]!\n",
    "        )\n",
    "        let debiasedRMSGrad = sqrt(state[\"averageSquaredGrad\"]! / debias(\n",
    "            momentum: config[SquareMomentum()],\n",
    "            dampening: config[SquareMomentumDampening()],\n",
    "            step: state[\"step\"]!\n",
    "        ) + config[Epsilon()])\n",
    "        let step = debiasedAverageGrad / debiasedRMSGrad + config[WeightDecayKey()] * param\n",
    "        let r1 = sqrt((param * param).mean())\n",
    "        let r2 = sqrt((step * step).mean())\n",
    "        let factor = min(r1 / r2, Float(10.0))\n",
    "        param -= config[LearningRate()] * factor * step\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebookToScript(fname: (Path.cwd / \"09_optimizer.ipynb\").string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "2a01aca7ab574e84a95eb9a9b362d435",
   "lastKernelId": "f48b2e4b-5a71-4fca-b00e-37803f6746af"
  },
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
