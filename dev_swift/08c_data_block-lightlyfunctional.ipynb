{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data block foundations, in Swifty/functional style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages:\n",
      "\t.package(path: \"/home/ubuntu/fastai_docs/dev_swift/FastaiNotebook_07_batchnorm\")\n",
      "\t\tFastaiNotebook_07_batchnorm\n",
      "\t.package(path: \"/home/ubuntu/fastai_docs/dev_swift/SwiftCV\")\n",
      "\t\tSwiftCV\n",
      "With SwiftPM flags: []\n",
      "Working in: /tmp/tmpfrw_ivup/swift-install\n",
      "Updating https://github.com/mxcl/Path.swift\n",
      "Updating https://github.com/JustHTTP/Just\n",
      "Updating https://github.com/latenitesoft/NotebookExport\n",
      "Completed resolution in 3.70s\n",
      "Compile COpenCV imgcodecs.cpp\n",
      "Compile COpenCV imgproc.cpp\n",
      "Compile COpenCV version.cpp\n",
      "Compile COpenCV core.cpp\n",
      "Compile Swift Module 'SwiftCV' (4 sources)\n",
      "Compile Swift Module 'jupyterInstalledPackages' (1 sources)\n",
      "Linking ./.build/x86_64-unknown-linux/debug/libjupyterInstalledPackages.so\n",
      "Initializing Swift...\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "%install-location $cwd/swift-install\n",
    "%install '.package(path: \"$cwd/FastaiNotebook_07_batchnorm\")' FastaiNotebook_07_batchnorm\n",
    "%install '.package(path: \"$cwd/SwiftCV\")' SwiftCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Path\n",
    "import TensorFlow\n",
    "import Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import FastaiNotebook_07_batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('inline', 'module://ipykernel.pylab.backend_inline')\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%include \"EnableIPythonDisplay.swift\"\n",
    "IPythonDisplay.shell.enable_matplotlib(\"inline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataBlock-like manipulation in a lightweight functional, Swifty style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataBlock API in Python is designed to help with the routine data manipulations involved in modelling: downloading data, loading it given an understanding of its layout on the filesystem, processing it, and feeding it into an ML framework like fastai. This is a data pipeline. How do we do this in Swift?\n",
    "\n",
    "One approach is to build a set of types (structs, protocols, etc.) which represent various stages of this pipeline. By making the types generic, we could build a library that handled data for many kinds of models. However, it is sometimes a good rule of thumb, before writing generic types, to start by writing concrete types and then to notice what to abstract into a generic later. And another good rule of thumb, before writing concrete types, is to write no types at all, and to see how far you can get with a more primitive tool for composition: functions.\n",
    "\n",
    "This notebook shows how to perform DataBlock-like operations using a _lightweight functional style_. This means, first, to rely as much as possible on _pure_ functions -- that is, functions which do nothing but return outputs based on their inputs, and which don't mutate values anywhere. Second, in particular, it means to use Swift's support for _higher-order functions_ (functions which take functions, like `map`, `filter`, `reduce`, and `compose`). Finally, this example relies on _tuples_. Like structs, tuples can have named, typed properties. Unlike structs, you don't need to name them. They can be a fast, ad-hoc way to explore the data types that you actually need, without being distracted by considering what's a method, an initializer, etc.,\n",
    "\n",
    "Swift has excellent, understated support for a such a style. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "First things first, we need to download Imagenette and untar it. What follows is very close to what we did for MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public let dataPath = Path.home/\".fastai\"/\"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public func downloadImagenette(path: Path = dataPath, sz:String=\"-160\") -> Path {\n",
    "    let url = \"https://s3.amazonaws.com/fast-ai-imageclas/imagenette\\(sz).tgz\"\n",
    "    let fname = \"imagenette\\(sz)\"\n",
    "    let file = path/fname\n",
    "    try! path.mkdir(.p)\n",
    "    if !file.exists {\n",
    "        downloadFile(url, dest:(path/\"\\(fname).tgz\").string)\n",
    "        _ = \"/bin/tar\".shell(\"-xzf\", (path/\"\\(fname).tgz\").string, \"-C\", path.string)\n",
    "    }\n",
    "    return file\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Imagenette configurations\n",
    "\n",
    "Here is what we know ahead of time about how imagenette data is laid out on disk:\n",
    "\n",
    "```\n",
    ".\n",
    "└── data                                           # <-- this is the fastai data root path\n",
    "    ├── imagenette-160                             # <-- this is the imagenette dataset path\n",
    "    │   ├── train                                  # <-- the train/ and val/ dirs are our two segments\n",
    "    │   │   ├── n01440764                          # <-- this is an image category _label_\n",
    "    │   │   │   ├── n01440764_10026.JPEG           # <-- this is an image (a _sample_) with that label\n",
    "    │   │   │   ├── n01440764_10027.JPEG\n",
    "    │   │   │   ├── n01440764_10042.JPEG\n",
    "   ...\n",
    "    │   ├── val\n",
    "    │       └── n03888257\n",
    "    │           ├── ILSVRC2012_val_00001440.JPEG\n",
    "    │           ├── ILSVRC2012_val_00002508.JPEG\n",
    "   ...  \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "We will define one type, an `enum`, to capture this information.\n",
    "\n",
    "This \"empty\" `enum` will serve only as a namespace, a grouping, for pure functions representing this information. By putting this information into one type, our code is more modular: it more clearly distinguishes facts about _this dataset_, from _general purpose data manipulators_, from _computations for this analysis_.\n",
    "\n",
    "Here's our Imagenette configuration type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// export\n",
    "enum ImageNette\n",
    "{\n",
    "  /// Downloads imagenette given the fastai data, and returns its \"dataset root\"\n",
    "  static func download() -> Path { return downloadImagenette() }\n",
    "\n",
    "  /// Extensions of paths which represent imagenette samples (i.e., items)\n",
    "  static var sampleExtensions:[String] = [\"jpeg\",\"jpg\"]\n",
    "\n",
    "  // Returns whether an image is in the training set (vs validation set), based on its path\n",
    "  static func isTraining(_ p:Path) -> Bool {\n",
    "    return p.parent.parent.basename() == \"train\"\n",
    "  }\n",
    "\n",
    "  /// Returns an image's label given the image's path\n",
    "  static func labelOf(_ p:Path) -> String { return p.parent.basename() }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Imagenette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var imageNettePath = ImageNette.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After download, the `imageNettePath` is the first _value_, and the remaining steps of analysis can all be seen as applying functions which successively compute new values from past values.\n",
    "\n",
    "For instance, this path and the allowed files extensions are the _input_ to the function `collectFilePaths(under:filteringToExtensions)` which _outputs_ an array of all samples in the dataet. (This is like `fetchFiles` but we rename it here to to emphasize the conventional functional operation of \"filtering\" and to reflect that it does not actually fetch files over the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/// returns a list of files under `path` with the specified extensions\n",
    "func collectFilePaths(under path:Path,\n",
    "                      filteringToExtensions extensions:[String]) -> [Path] {\n",
    "    var res: [Path] = []\n",
    "    for p in try! path.ls(){\n",
    "        if p.kind == .directory { \n",
    "            res += collectFilePaths(under: p.path, filteringToExtensions: extensions)\n",
    "        } else if extensions.contains(p.path.extension.lowercased()) {\n",
    "            res.append(p.path)\n",
    "        }\n",
    "    }\n",
    "    return res\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute the next value, the array of all paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var allPaths = collectFilePaths(under: imageNettePath, filteringToExtensions:ImageNette.sampleExtensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at a random element, compared to the imagenette root, it has the filesystem layout structure we expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "▿ 2 elements\n",
       "  - .0 : \"/home/alexis/.fastai/data/imagenette-160\"\n",
       "  - .1 : \"/home/alexis/.fastai/data/imagenette-160/train/n03425413/n03425413_17114.JPEG\"\n"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(imageNettePath.string, allPaths.randomElement()!.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us verify that our configurations functions correctly encode the segment (train or val) and the label of an arbitrary item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func describeSample(_ path:Path) \n",
    "{\n",
    "    let isTraining = ImageNette.isTraining(path)\n",
    "    let label = ImageNette.labelOf(path)\n",
    "    print(\"\"\"\n",
    "          path: \\(path.string)\n",
    "          training?:  \\(isTraining)\n",
    "          label: \\(label)\n",
    "          \"\"\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: /home/alexis/.fastai/data/imagenette-160/train/n03888257/n03888257_36918.JPEG\r\n",
      "training?:  true\r\n",
      "label: n03888257\r\n"
     ]
    }
   ],
   "source": [
    "describeSample(allPaths.randomElement()!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our functions for _path->isTraining_ and _path->label_ are working as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to split our samples into a training and validation sets. Since this is so routine we define a standard function that does so.\n",
    "\n",
    "It is enough to take an array and returns a named tuple of two arrays, one for training and one for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// export\n",
    "\n",
    "/// takes a [T] of items, and returns a tuple (train:[T],val:[T]) items\n",
    "func partitionIntoTrainVal<T>(_ items:[T],isTrain:((T)->Bool)) -> (train:[T],val:[T])\n",
    "{\n",
    "  var result = items \n",
    "  let pivot = result.partition(by: isTrain)\n",
    "  let train = Array(result[pivot...])\n",
    "  let val = Array(result[..<pivot])\n",
    "  return (train:train,val:val)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pass the `ImageNette.isTraining` test function into the partitioner directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var samples = partitionIntoTrainVal(allPaths, isTrain:ImageNette.isTraining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And verify that it works as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: /home/alexis/.fastai/data/imagenette-160/val/n03028079/ILSVRC2012_val_00039506.JPEG\r\n",
      "training?:  false\r\n",
      "label: n03028079\r\n"
     ]
    }
   ],
   "source": [
    "describeSample(samples.val.randomElement()!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: /home/alexis/.fastai/data/imagenette-160/train/n01440764/n01440764_14176.JPEG\r\n",
      "training?:  true\r\n",
      "label: n01440764\r\n"
     ]
    }
   ],
   "source": [
    "describeSample(samples.train.randomElement()!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the data\n",
    "\n",
    "We process the data by taking all training labels, uniquing them, sorting them, and then defining an integer to represent the label.\n",
    "\n",
    "Those numerical labels let us define two functions, a function for label->number and the inverse function number->label.\n",
    "\n",
    "But notable point is that the process that produces those functions _is also a function_: the input is a list of training labels, and the output is the label<->number bidirectional mappings.\n",
    "\n",
    "That function which creates the bidirectional mapping is just the initializer of the String<->Int mapper we define below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// export\n",
    "/// Defines bidirectional maps from String <-> Int32, initialized from a collection of Strings\n",
    "public struct StringIntMapper {\n",
    "  private(set) public var labelMap:[String]\n",
    "  private(set) public var inverseLabelMap:[String:Int32]\n",
    "  public init<S:Sequence>(labels ls:S) where S.Element == String {\n",
    "    labelMap = Array(Set(ls)).sorted()\n",
    "    inverseLabelMap = Dictionary(uniqueKeysWithValues:\n",
    "      labelMap.enumerated().map({ ($0.element, Int32($0.offset)) }))\n",
    "  }\n",
    "  public func labelToInt32(_ label:String) -> Int32 { return inverseLabelMap[label]! }\n",
    "  public func int32ToLabel(_ labelIndex:Int32) -> String { return labelMap[Int(labelIndex)] }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create a labelNumber mapper from the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var trainLabels = samples.train.map(ImageNette.labelOf)\n",
    "var labelMapper = StringIntMapper(labels: trainLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labelMapper now supplies the two bidirectional functions. We can verify they have the required inverse relationship:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = n03417042\r\n",
      "number = 6\r\n",
      "label = n03417042\r\n"
     ]
    }
   ],
   "source": [
    "var randomLabel = labelMapper.labelMap.randomElement()!\n",
    "print(\"label = \\(randomLabel)\")\n",
    "var numericalizedLabel = labelMapper.labelToInt32(randomLabel)\n",
    "print(\"number = \\(numericalizedLabel)\")\n",
    "var labelFromNumber = labelMapper.int32ToLabel(numericalizedLabel)\n",
    "print(\"label = \\(labelFromNumber)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are in a position to give the data numerical labels.\n",
    "\n",
    "Now in order to map from a sample item (a `Path`), to a numerical label (an `Int32)`, we just compose our Path->label function with a label->int function. Curiously, Swift does not define its own compose function, so we define `compose` ourselves and use it to create our new function as a composition explicitly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// export\n",
    "/// g(f(x)) == (compose(g,f))(x)\n",
    "func compose<A,B,C>(_ g: @escaping (B) -> C,\n",
    "                    _ f: @escaping (A) -> B) -> ((A) -> C) {\n",
    "  return { (a:A) -> C in\n",
    "    return g(f(a))\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Define a function which map a raw sample (Path) to a numericalized label (Int32)\n",
    "var pathToNumericalizedLabel = compose(labelMapper.labelToInt32,ImageNette.labelOf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can, if we wish, compute numericalized labels over ll the training and validation items:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var trainNumLabels = samples.train.map(pathToNumericalizedLabel)\n",
    "var valNumLabels = samples.val.map(pathToNumericalizedLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've gotten pretty far just using mostly just variables, functions, and function composition. But one downside is that our results are now scattered over a few different variables, `samples`, `trainNumLabels`, `valNumLabels`. If we wanted to collect these values into one structure for convenience, we could even use a named tuple for this as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typealias SplitLabeledDataResults = (\n",
    "  mapper: StringIntMapper,\n",
    "  train:(\n",
    "    items:[Path],\n",
    "    labels:[Int32]),\n",
    "  val:(\n",
    "    items:[Path],\n",
    "    labels:[Int32])\n",
    ")\n",
    "var results:SplitLabeledDataResults = (mapper: labelMapper,\n",
    "                       train:(samples.train,trainNumLabels),\n",
    "                       val:(samples.val,valNumLabels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now, if we wish, define a single function that reproduces all our calculations, starting with the first value, the array of all paths. The sequence of function calls, each using inputs from the previous function, and returning a constant, value-semantic type, is a functional style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func splitLabeledData(paths:[Path]) -> SplitLabeledDataResults\n",
    "{\n",
    "    let samples = partitionIntoTrainVal(paths, isTrain:ImageNette.isTraining)\n",
    "    let trainLabels = samples.train.map(ImageNette.labelOf)\n",
    "    let labelMapper = StringIntMapper(labels:trainLabels)\n",
    "    let pathToNumericalizedLabel = compose(labelMapper.labelToInt32,ImageNette.labelOf)\n",
    "    let results:SplitLabeledDataResults = (mapper:labelMapper,\n",
    "                   train:(samples.train,samples.train.map(pathToNumericalizedLabel)),\n",
    "                   val:(samples.val,samples.val.map(pathToNumericalizedLabel)))\n",
    "    return results\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this is the output shape we find convenient, we would define a custom struct instead of relying on nested tuples.\n",
    "\n",
    "But starting with tuples makes it easier to see the pure functions at work, which might have been obscured if we had started by thinking of functions as methods that \"belong\" to one type or another. Some functions want to be free!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### chunking, and transforming into Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible next steps:\n",
    "\n",
    "- to go from `SplitLabeledDataResults` to `DataBatch`.\n",
    "- move transformation, shuffling, and batching into functional pipeline operations, between simple structs.\n",
    "- probably greatly simplifyng DataBunch and FADataset\n",
    "- remove unnecessary generics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// // export\n",
    "// public func pathsToTensor(_ paths: [Path]) -> StringTensor { return StringTensor(paths.map{ $0.string })}\n",
    "// public func numlabelsToTensor(_ numlabels: [Int32]) -> Tensor<Int32> { return Tensor<Int32>(numlabels)}\n",
    "\n",
    "\n",
    "// func dataBatch(from sldr:SplitLabeledDataResults) -> DataBatch<TF, Tensor<Int32>>?\n",
    "// {\n",
    "//     var trainEl = LabeledElement(xb: pathsToTensor(sldr.train.items),\n",
    "//                    yb: numlabelsToTensor(sldr.train.labels))\n",
    "//     var valEl = LabeledElement(xb: pathsToTensor(sldr.val.items),\n",
    "//                    yb: numlabelsToTensor(sldr.val.labels))\n",
    "\n",
    "//     let inputs:TF = \n",
    "//     let labels:Tensor<Int32> = \n",
    "//    var batch = DataBatch.init(xb:inputs, yb:labels)\n",
    "//     return nil\n",
    "//    return batch\n",
    "// }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
